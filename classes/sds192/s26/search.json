[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SDS 192: Introduction to Data Science",
    "section": "",
    "text": "This website is the central hub for all materials related to this iteration of SDS 192. Use the links on the right-side of the page to access particular content.\n\n\nSource: xkcd"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "SDS 192: Introduction to Data Science",
    "section": "",
    "text": "This website is the central hub for all materials related to this iteration of SDS 192. Use the links on the right-side of the page to access particular content.\n\n\nSource: xkcd"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "In this webpage, you will find the syllabus for this course (02). A .pdf version of this syllabus can be accessed here."
  },
  {
    "objectID": "syllabus.html#overview",
    "href": "syllabus.html#overview",
    "title": "Syllabus",
    "section": "Overview",
    "text": "Overview\n\nContactLocation/TimeDescriptionLearning OutcomesMaterials\n\n\n\n\n\n\n\nInstructor: Jericho Lawson\nEmail: jlawson01@smith.edu\nOffice Hours:\n\nMondays, 3-4pm\nFridays, 10am-12pm\nMcConnell 207\n\n\n\n\n\n\n\nMondays, 1:40 - 2:55pm in Sabin-Reed 301\nWednesdays & Fridays, 1:20 - 2:35pm in Sabin-Reed 301\n\n\n\nData science involves applying a set of strategies to transform a recorded set of values into something from which we can glean knowledge and insight. This course will introduce you to concepts and methods from the field of data science, along with how to apply them in R. You will learn how to acquire, clean, wrangle, and visualize data. You will also learn best practices in data science workflows, such as code documentation and version control. Issues in data ethics will be addressed throughout the course.\n\n\nBy the end of this course, students will be able to do the following:\n\nData visualization: Create informative and clean visuals through various types of plots. Appropriate statistics and metrics are displayed. Use of base R and advanced libraries to generate plots (i.e. ggplot2).\nData wrangling: Develop techniques to properly use data in a workflow, which includes the transformation of data, data cleaning, and data joining. Students will also gather data in appropriate and ethical manners.\nWorkflow: Practice common tasks to working through particular data science problems, such as data retrieval, R programming, GitHub, and light statistics.\nData ethics: Identify best practices and ethical dilemmas that stem from data science work. This includes contextual thinking, environmental concerns, and intellectual property. Students will also develop ethical ways to use generative AI.\n\n\n\n\nTextbooks\n\nBaumer, B. S., Kaplan, D. T., & Horton, N. J. (2024). Modern Data Science with R (3rd ed.). CRC Press. https://mdsr-book.github.io/mdsr3e/\n\nOptional:\n\nIsmay, C., Kim A. Y., & Valdivia A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). CRC Press. https://moderndive.com/v2/\nIrizarry, R. A. (2022). Introduction to Data Science: Data Analysis and Prediction Algorithms with R. CRC Press. https://rafalab.dfci.harvard.edu/dsbook-part-1/\n\n\n\nTechnology\n\nFor coding: R, RStudio\n\nFor downloading/installing: Instructions\n\nFor assignment turn-ins: GitHub\nFor discussion assignments: Perusall\n\nFor joining Perusall course: To join\n\nEnrollment code: LAWSON-2BX49\n\n\nFor course management: Moodle, but will be used seldomly\nFor course materials: This website\nFor discussions and announcements: Slack"
  },
  {
    "objectID": "syllabus.html#grading-and-expectations",
    "href": "syllabus.html#grading-and-expectations",
    "title": "Syllabus",
    "section": "Grading and Expectations",
    "text": "Grading and Expectations\n\nBreakdown\n\n\n\n\n\n\n\n\n\n\nFormative\n\n\nSummative\n\n\n\n\n\nReadings, Activities, Problems\n10%\n\nProjects (2)\n30%\n\n\nLabs\n30%\n\nExams (2)\n30%\n\n\n\nA traditional grading system will be used here. Cumulative numerical averages of 90-100 are guaranteed at least an A-, 80-89 at least a B-, and 70-79 at least a C-. The exact ranges for letter grades will ultimately be determined at the end of the course.\n\n\nMW Classes, Readings, Activties, and Exercises (10%)\nPrior to the upcoming week, readings will be assigned through Perusall that prepare you for material that will be explored thereafter. The readings on Perusall will involve:\n\nReading through the material\nWriting 2-4 annotations\nHighlighting one item you learned and one item that seems challenging\n\nThese annotations will allow me to identify which concepts to focus on in more detail during the week. Generally, these items will be due on Sundays at 11:59pm, with no acceptance of late work. Readings will be graded on completion.\nDuring Mondays and Wednesday classes, we will go through mini-lectures, activities, and demos. Classes will be experiential, meaning that you will have the opportunity to apply concepts from class to activities, exercises, and investigations. Students are expected to participate during lecture by asking questions and working with other students. Additionally, it is required that you bring your laptop to class. Class activities will be administered often during lecture, and you will have until the end of lecture to turn them in through your GitHub submission repository. These activities will be graded based on completion and/or correctness.\nOn occasion, a reading exercise may be assigned on Wednesday for you to complete. Similar to the activities, these will be turned in through your GitHub submission repository by Thursdays at 11:59pm. These exercises will be graded based on completion and correctness.\n\n\nFriday Classes and Labs (30%)\nFriday’s classes are dedicated exclusively to labs unless otherwise stated. In these labs, you will have the opportunity to compile (no pun intended) what you’ve learned and work on a experiential assignment that showcases those skills. This will involve strong usage of R and GitHub. In earlier weeks, we will get you all familiar with the technical programs along with the workflow.\nLabs in this course introduce a data science skill by walking you through exploratory analysis of a dataset documenting a socially-relevant issue (such as racial profiling in policing, affordable housing, and pollution). Labs will be started in class on Fridays and completed for homework by Wednesdays at 11:59pm. If you finish a lab early, you are encouraged to help your classmates. Labs will be graded on both completion and correctness. Note that at the end of each lab, there will be a prompt asking you to consider some of the ethical considerations of the data analysis you just completed. You must respond to this prompt in Slack to earn full credit on the lab.\nAll lab assignments will be submitted through your GitHub submission repository. You will submit assignments by pushing changes to template documents to a private GitHub repository. I will provide guidance on how to do this early in the semester.\n\n\nProjects (30% total)\nTwo projects will be assigned throughout the semester. The projects are designed to test your ability to successfully complete course objectives as described earlier. The following two projects, along with their tentative due dates, are seen below:\n\nProject #1: Data Visualizations and GitHub: due Wednesday, 3/4 at 11:59pm\n\nCreate meaningful, informative, and clear visualizations that communicate information from the data and real-world issue.\nConfigure an appropriate pipeline that funnels all relevant information, files, and summaries into a GitHub repository.\n\nProject #2: Workflow and Real-World Investigation: due Monday, 4/27 at 11:59pm\n\nComplete a detailed, attentive workflow of an investigation related to a real-world issue with appropriate data and context.\nPresent relevant information and code to various audiences in multiple formats, including a report, presentation, and demonstration.\n\n\nMore details to come in later weeks.\n\n\nExams (30% total)\nTwo exams will be administered during the course of the semester, which will include written and oral parts. The first exam will be administered in-class on Friday, 3/13, while the second exam will be administered during finals week as a self-scheduled exam. More details to come in later weeks."
  },
  {
    "objectID": "syllabus.html#policies",
    "href": "syllabus.html#policies",
    "title": "Syllabus",
    "section": "Policies",
    "text": "Policies\n\nPreparation and Attendance\nAs a four-credit course that meets 4.5 hours per week, Smith expects students to dedicate at least 7.5 hours per week towards the course outside of class. The assignments, readings, and assessments are designed with this target in mind. Expect to read through lecture notes, examples, articles, and forums outside of class along with the assignments.\nAttending class is imperative to your learning and taking part in an active community. Attendance will be taken for each class period. However, things come up and you may not have the capacity to attend. As such, you will be able to miss 3 classes with no penalty. After the third unexcused absence, your overall grade will drop by 1% for each class missed. Additional absences may be excused due to family/personal difficulties, sickness, or school or career-related activities; however, I will require some form of documentation for these absences. Please speak with your class dean or the Accessibility Resource Center so that we can get documentation of your need.\nDo make every effort to arrive to class on time. If you happen/plan to arrive more than 10 minutes late, please inform me ahead of time. Any unexplained tardiness will result in a marked absence. If you must miss a class entirely, you should contact a peer to discuss what was missed.\n\n\nExtensions\nYou will be granted 2 free late days to use for lab assignments, with a maximum of one day used on each lab assignment. Additionally, you will be granted 2 late days to use for final project submissions, with a maximum of two days used at a single time. No need to inform me that you intend to take these late days. Beyond this, late assignments will not be accepted without an accommodation from a class dean or from the ARC.\nNote that this policy does not apply to Perusall annotations, reading exercises, exams, or project checkpoints/proposals/presentations.\n\n\nAcademic Honesty\nAs a student at Smith College, the college expects all students to be honest and committed to the principles of academic and intellectual integrity in preparation and submission of all course work and examinations, as outlined by the Academic Integrity Board (AIB). The AIB provides an Academic Integrity Statement, which all students are expected to abide by. Any cases of academic dishonesty or plagiarism will be reported to the Academic Honor Board. Examples of these behaviors include:\n\nSubmitting work completed by another student as your own.\nCopying and pasting words from sources without quoting and citing the author.\nParaphrasing material from another source without citing the author.\nFailing to cite your sources correctly.\nFalsifying or misrepresenting information in submitted work.\nPaying another student or service to complete assignments for you.\nSubmitting work generated by artificially intelligent tools such as ChatGPT without permission or instruction to do so.\n\nYou are encouraged to discuss course material, including assignments, with your classmates. All work you turn in, however, must be your own. This includes both writing and code. Copying from other students, from books, or from websites (1) does nothing to help you learn how to program, (2) is easy for us to detect, and (3) has serious negative consequences.\n\n\nGenerative AI\nAs mentioned in the Academic Integrity Board, the professor for each course decides whether and how students are allowed to use generative AI in a given course. For this specific course, any use of generative AI to complete assignments or produce content for this course is prohibited, unless otherwise stated in the assignment itself.\nAs a foundational course, it is critical that you are able to think like a data scientist, which includes producing meaningful code, developing logical solutions to problem, and critiquing good results from the bad ones. While the use of generative AI can be beneficial at producing base-level code and providing insights, it comes at the detriment of your own critical thinking. The human element will be critical in succeeding in data science. If you don’t develop the skills to understand how the underlying code is composed/works, then you will not be prepared for this kind of work.\nProhibited forms of generative AI usage include but are not limited to:\n\nSummarizing course readings.\nDrafting, editing, and proofreading responses to written prompts on any assignment.\nComposing and/or formatting code and comments.\nAnswering lab, quiz, or exam questions.\nConducting analysis of any plots, methods, and results for any assignment.\n\nAny unauthorized use of generative artificial intelligence in this course will be considered a case of academic dishonesty/plagiarism and will be reported to the Academic Honor Board.\nCaveat: While the policy here is strict, do note that there will be assignments and lectures that go through the ethical and effective use of generative AI in data science as part of a unit. In these assignments, further directions will be given to showcase the use of generative AI. However, unless otherwise stated, generative AI should not be used in any assignment."
  },
  {
    "objectID": "syllabus.html#community-support",
    "href": "syllabus.html#community-support",
    "title": "Syllabus",
    "section": "Community & Support",
    "text": "Community & Support\n\nCode of Conduct\nAs the instructor for this course, I am committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor I have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students and the instructor are expected to adhere to this Code of Conduct in all settings for this course: seminars, office hours, and over Slack. This Code of Conduct is adapted from the Contributor Covenant, version 1.0.0, available here.\n\n\nPrinciples of Community\nWhether in a class, college, or neighborhood setting, achieving a warm community is essential to your well-being. In this class, I hope we can foster a collaborative and welcoming environment: one that celebrates successes, respects individual strengths and weaknesses, demonstrates compassion for each other’s struggles, and affirms diverse identities.\nTo establish this, consider the following:\n\nCheck-in with colleagues before starting collaborative work.\nConsider when to step up and when to step back in class discussions, creating space for others to contribute. Listening is just as important to community-building as speaking.\nAcknowledge what we do and don’t know, as well as how our colleagues experience the world.\nSupport colleagues that may be stepping outside of their comfort zone (i.e. presentations).\nAsk questions often in our Slack workspace. Help each other out by answering questions when you can.\nAdmit mistakes. They happen, and I will certainly make mistakes in class.\nUse pronouns. This provides a foundation to a safe, respectful classroom environment that creates a sense of trust. For information on pronouns and usage, please see the Office of Equity and Inclusion link here: Pronouns\n\n\n\nAccommodations\nIt is my goal for everyone to succeed in this course. If you have personal circumstances that may impact your experience of our classroom, I encourage you to contact the Accessibility Resource Center in College Hall 104 or at arc@smith.edu. The Center will generate a letter that indicates to me what kind of support you need and how I can make your classroom experience more accommodating. Once you have this letter, you are welcome to visit my office hours or email me to discuss ideas about how we can tailor the course accordingly. While you can request accommodations at any time, the sooner we start this conversation, the better. If you have concerns about the course that are not addressed through ARC, please contact me. At no point will I ask you to divulge details about your personal circumstances to me.\n\n\nStudent Well-Being\nCollege life is stressful, and life outside of college can be overwhelming. It is my position that attending to your physical and mental health and well-being should be a top priority. I will remind you of this often throughout the semester. I encourage you to schedule a time to talk with me if you are struggling with this course. If you, or anyone you know, is experiencing distress, there are numerous campus resources that can provide support via the Schacht Center.\nAdditional resources and support offered by the college are listed below:\n\nAccessibility Resource Center (ARC)\nSpinelli Center: Support for students doing quantitative work. Includes tutoring and resources.\n\nFor this class: Sun-Thurs, 7-9pm in Sabin-Reed 301.\nEmail qlctutor@smith.edu for specific request for help.\n\nCrisis Resources\nCounseling Services\nWellness Resources\nGender Identity and Expression\nDiscriminatory Harassment"
  },
  {
    "objectID": "syllabus.html#course-outline",
    "href": "syllabus.html#course-outline",
    "title": "Syllabus",
    "section": "Course Outline",
    "text": "Course Outline\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nCh.\nAssignments / Notes\n\n\n\n\n1\n1/26-30\nIntroduction to Data\n1\n\n\n\n2\n2/2-6\nIntro to R and Workflows\n1, B\n\n\n\n3\n2/9-13\nData Visualization\n2\n\n\n\n4\n2/16-20\nggplot2\n3\n\n\n\n5\n2/23-2/27\nData Wrangling\n4\n\n\n\n6\n3/2-3/6\nData Joining\n5\nProject #1 due: Wed, 3/4\n\n\n7\n3/9-13\nStatistics, Exam #1\n9\nExam #1: Fri, 3/13\n\n\n8\n3/16-20\nSpring Break!\n\nNo class all week long\n\n\n9\n3/23-27\nData Tidying\n6\n\n\n\n10\n3/30-4/3\nProgramming\n7\n\n\n\n11\n4/6-10\nEthics and Programming\n8, C\n\n\n\n12\n4/13-17\nSpatial Thinking\n17\n\n\n\n13\n4/20-24\nSpatial Thinking\n17\n\n\n\n14\n4/27-5/1\nAPIs and Review\n18\nProject #2 due: Mon, 4/27 \n\n\nFinals\n5/2-9\nFinals\nNA\nExam #2: self-scheduled (5/6-9) \n\n\n\n\nNote that the assignments and topics covered are tentatively scheduled and may be altered slightly as the quarter progresses. The instructor has the right to modify the syllabus if needed. If this occurs, students will be notified before the change occurs."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28Friday, 1/30\n\n\n\n\n\n\n\n\nNoteLecture: CANCELLED\n\n\n\nStay warm and enjoy the snow!\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Introductions\n\n\n\n\nSlides + Activity\nNote: Office hours will be held from 3-4pm today in McConnell 207. Feel free to stop by!\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Intro to Data\n\n\n\n\nSlides\nActivity\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\nReadings #1 (due Tuesday, 2/3 on Perusall at 11:59pm)"
  },
  {
    "objectID": "schedule.html#week-1-introduction-126---130",
    "href": "schedule.html#week-1-introduction-126---130",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28\n\n\nLecture #1: Introduction\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Tuesday, 1/27 at 8:59pm)\n\n\n\n\n\nLecture #2: Names and Values\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #1 (due Sunday, 2/1 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-2-data-structures-22---26",
    "href": "schedule.html#week-2-data-structures-22---26",
    "title": "Schedule",
    "section": "Week 2: Data Structures (2/2 - 2/6)",
    "text": "Week 2: Data Structures (2/2 - 2/6)\n\nMonday, 2/2Wednesday, 2/4\n\n\nLecture #3: Vectors\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\nLecture #4: Multi-Dimensional Data Structures\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #2 (due Sunday, 2/8 at 8:59pm)\nHW #1 (due Tuesday, 2/10 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-3-project-workflow-29---213",
    "href": "schedule.html#week-3-project-workflow-29---213",
    "title": "Schedule",
    "section": "Week 3: Project Workflow (2/9 - 2/13)",
    "text": "Week 3: Project Workflow (2/9 - 2/13)\n\nMonday, 2/9Wednesday, 2/11\n\n\nLecture #5: Projects\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\n\n\n\n\n\n\nImportantQuiz #1\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture #6: GitHub\n\n\n\n\nSlides\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #3 (due Sunday, 2/15 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-4-subsetting-and-control-flow-216---220",
    "href": "schedule.html#week-4-subsetting-and-control-flow-216---220",
    "title": "Schedule",
    "section": "Week 4: Subsetting and Control Flow (2/16 - 2/20)",
    "text": "Week 4: Subsetting and Control Flow (2/16 - 2/20)\n\nMonday, 2/16Wednesday, 2/18\n\n\nLecture #7: Subsetting\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #8: Control Flow\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #4 (due Sunday, 2/22 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-5-functions-and-apply-223---227",
    "href": "schedule.html#week-5-functions-and-apply-223---227",
    "title": "Schedule",
    "section": "Week 5: Functions and Apply (2/23 - 2/27)",
    "text": "Week 5: Functions and Apply (2/23 - 2/27)\n\nMonday, 2/23Wednesday, 2/25\n\n\nQuiz #2: Subsetting and Control Flow\nLecture #9: Functions\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #10: Apply and Map\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #5 (due Sunday, 3/1 at 8:59pm)\nHW #3 (due Tuesday, 3/3 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-6-packages-32---36",
    "href": "schedule.html#week-6-packages-32---36",
    "title": "Schedule",
    "section": "Week 6: Packages (3/2 - 3/6)",
    "text": "Week 6: Packages (3/2 - 3/6)\n\nMonday, 3/2Wednesday, 3/4\n\n\nLecture #11: Packages\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #12: Build a Package\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)"
  },
  {
    "objectID": "lectures/w1l1_intro.html#welcome",
    "href": "lectures/w1l1_intro.html#welcome",
    "title": "Introductions",
    "section": "Welcome!",
    "text": "Welcome!\n\n\n\n\n\n\n\n\n\nCourse: SDS 192, Sect. 02\nTimes:\n\nM, 1:40-2:55pm\nW/F, 1:20-2:35pm"
  },
  {
    "objectID": "lectures/w1l1_intro.html#welcome-1",
    "href": "lectures/w1l1_intro.html#welcome-1",
    "title": "Introductions",
    "section": "Welcome!",
    "text": "Welcome!\n\n\n\nInstructor: Jericho Lawson\n\nLocation: McConnell 207\n\nOffice Hours:\n\nM, 3-4pm\nF, 10am-12pm\n\nEmail: jlawson01@smith.edu"
  },
  {
    "objectID": "lectures/w1l1_intro.html#activity-data-science",
    "href": "lectures/w1l1_intro.html#activity-data-science",
    "title": "Lecture #1: Introductions",
    "section": "Activity: Data Science",
    "text": "Activity: Data Science\nForm groups of 2-3 with your peers near you. Complete the following tasks:\n\nIntroduce yourselves to each other! Mention your name, major, and one cool thing you did over the summer.\nOn a piece of paper, write the names of all group members.\nWrite down words, phrases, and ideas that come to mind when you hear “data science”."
  },
  {
    "objectID": "lectures/w1l1_intro.html#what-is-data-science-common-view",
    "href": "lectures/w1l1_intro.html#what-is-data-science-common-view",
    "title": "Introductions",
    "section": "What is data science? Common view:",
    "text": "What is data science? Common view:\n\n\n\nInterdisciplinary field combining computer science, mathematics/statistics, and domain expertise to extract meaningful information from unstructured data points"
  },
  {
    "objectID": "lectures/w1l1_intro.html#what-is-data-science-my-view",
    "href": "lectures/w1l1_intro.html#what-is-data-science-my-view",
    "title": "Introductions",
    "section": "What is data science? My view:",
    "text": "What is data science? My view:\n\n\n\nInterdisciplinary field combining computer science, mathematics/statistics, and domain expertise to extract meaningful information from unstructured data points\n Includes the human aspect: use of aesthetics, situational context, and communication to explain the data to the world"
  },
  {
    "objectID": "lectures/w1l1_intro.html#case-study-1-aclu-fights-discriminatory-housing",
    "href": "lectures/w1l1_intro.html#case-study-1-aclu-fights-discriminatory-housing",
    "title": "Introductions",
    "section": "Case Study 1: ACLU Fights Discriminatory Housing",
    "text": "Case Study 1: ACLU Fights Discriminatory Housing\n\n\n\nAmerican Civil Liberties Union employs data scientists to produce insights regarding discriminatory laws and practices\nFindings are presented in courts, legislatures, and public reports\nIn this study, they use public data to show that excluding people with criminal records from housing can be viewed as a violation of the US Fair Housing Act."
  },
  {
    "objectID": "lectures/w1l1_intro.html#case-study-2-epa-tracks-environmental-injustice",
    "href": "lectures/w1l1_intro.html#case-study-2-epa-tracks-environmental-injustice",
    "title": "Introductions",
    "section": "Case Study 2: EPA Tracks Environmental Injustice",
    "text": "Case Study 2: EPA Tracks Environmental Injustice\n\n\n\nEnvironmental Protection Agency hires data scientists to produce insights regarding environmental health risks\nFindings implicate environmental policies, funding allocations, and legal actions against states and industries\nThis tool, visualizes environmental and demographic indicators to highlight communities experiencing environmental injustices."
  },
  {
    "objectID": "lectures/w1l1_intro.html#case-study-3-geena-davis-institute-studies-gender-biases-in-films",
    "href": "lectures/w1l1_intro.html#case-study-3-geena-davis-institute-studies-gender-biases-in-films",
    "title": "Introductions",
    "section": "Case Study 3: Geena Davis Institute Studies Gender Biases in Films",
    "text": "Case Study 3: Geena Davis Institute Studies Gender Biases in Films\n\n\n\nGeena Davis Institute collaborated with University of Southern California’s Signal Analysis and Interpretation Laboratory (SAIL)\nDeveloped a machine learning tool to measure representation of diverse groups in films by studying screen time and speaking"
  },
  {
    "objectID": "lectures/w1l1_intro.html#topics-covered-in-this-course",
    "href": "lectures/w1l1_intro.html#topics-covered-in-this-course",
    "title": "Introductions",
    "section": "Topics covered in this course",
    "text": "Topics covered in this course\n\n\n\nData visualization\nData wrangling\nProgramming with data (via R)\nData retrieval\nData science infrastructures and workflows\nData science ethics\nMapping"
  },
  {
    "objectID": "lectures/w1l1_intro.html#learning-objectives",
    "href": "lectures/w1l1_intro.html#learning-objectives",
    "title": "Introductions",
    "section": "Learning objectives",
    "text": "Learning objectives\nData visualization\n\nCreate informative and clean visuals via base R, advanced libraries\nShow appropriate statistics and metrics for support\n\nData wrangling\n\nDevelop proper wrangling techniques, including data transformation, cleaning, and joining\nGather data in appropriate and ethical manners"
  },
  {
    "objectID": "lectures/w1l1_intro.html#learning-objectives-1",
    "href": "lectures/w1l1_intro.html#learning-objectives-1",
    "title": "Introductions",
    "section": "Learning objectives",
    "text": "Learning objectives\nWorkflow\n\nPractice retrieval, R programming, GitHub, and light statistics\n\nData ethics\n\nIdentify best practices and ethical dilemmas, including contextual thinking, environmental concerns, and intellectual property\nDevelop ethical ways to use generative AI"
  },
  {
    "objectID": "lectures/w1l1_intro.html#who-am-i",
    "href": "lectures/w1l1_intro.html#who-am-i",
    "title": "Introductions",
    "section": "Who am I?",
    "text": "Who am I?\nCall me Jericho, but if you prefer, Professor Lawson or Dr. Lawson is okay!\n\n\n\n\n\n\n\n\n\nLecturer of Statistical and Data Sciences\nResearch interests: variable selection, imaging, machine learning\nMy college journey:\n\nPh.D. in Applied Statistics from UC Riverside\nM.S. in Statistics from UC Riverside\nB.S. in Applied Mathematics; Statistics and Data Science from University of Arizona"
  },
  {
    "objectID": "lectures/w1l1_intro.html#who-am-i-1",
    "href": "lectures/w1l1_intro.html#who-am-i-1",
    "title": "Introductions",
    "section": "Who am I?",
    "text": "Who am I?\n\n\n\n\n\n\n\n\n\nFrom Arizona!!\n\nWill either hear me talk about the state or the Suns\n\nHiker, foodie, and explorer!"
  },
  {
    "objectID": "lectures/w1l1_intro.html#exercise",
    "href": "lectures/w1l1_intro.html#exercise",
    "title": "Introductions",
    "section": "Exercise",
    "text": "Exercise\nOn your feet! I’ll ask three questions about light-hearted pieces of information. For each question,\n\nGroup or order yourselves.\nPonder about what characteristics you see with the groupings/orderings."
  },
  {
    "objectID": "lectures/w1l1_intro.html#workflow",
    "href": "lectures/w1l1_intro.html#workflow",
    "title": "Introductions",
    "section": "Workflow",
    "text": "Workflow\n\nDetermine problem/issue\nCollect data\nExplore and clean the data\nModel the data\nCommunicate results\n\nQuestion? How was this done? Discuss amongst yourselves."
  },
  {
    "objectID": "lectures/w1l1_intro.html#tools",
    "href": "lectures/w1l1_intro.html#tools",
    "title": "Introductions",
    "section": "Tools",
    "text": "Tools\n\nDetermine problem/issue: Exploration of issues\nCollect data: From online source (e.g. scraping, csv file)\nExplore and clean the data: Use of R, wrangling\nModel the data: Statistics, regression\nCommunicate results: Plots, tables, writing, presentations"
  },
  {
    "objectID": "lectures/w1l1_intro.html#coding-agonizing-when-it-doesnt-work-satisfying-when-it-does",
    "href": "lectures/w1l1_intro.html#coding-agonizing-when-it-doesnt-work-satisfying-when-it-does",
    "title": "Introductions",
    "section": "Coding: agonizing when it doesn’t work, satisfying when it does",
    "text": "Coding: agonizing when it doesn’t work, satisfying when it does\n\nThink of code like a language.\nCoding can be incredibly frustrating.\nCoding has been exclusionary."
  },
  {
    "objectID": "lectures/w1l1_intro.html#prepping-for-this-class",
    "href": "lectures/w1l1_intro.html#prepping-for-this-class",
    "title": "Introductions",
    "section": "Prepping for this class",
    "text": "Prepping for this class\n\nNavigate the Moodle course website\nRead through the syllabus\nPerusall\nSlack"
  },
  {
    "objectID": "lectures/w1l1_intro.html#for-monday",
    "href": "lectures/w1l1_intro.html#for-monday",
    "title": "Introductions",
    "section": "For Monday",
    "text": "For Monday\n\nInstall Slack desktop and set notifications\nRead through article and make annotations on Perusall\nRead through Ch. 1-2 of textbook and syllabus\nTake reading/syllabus quiz on Moodle\nComplete the pre-course survey on Moodle\nBring charged laptop to class on Monday"
  },
  {
    "objectID": "lectures/w1l1_intro.html#section",
    "href": "lectures/w1l1_intro.html#section",
    "title": "Introductions",
    "section": "",
    "text": "Sources: NYT, Compadre DB, The Atlantic"
  },
  {
    "objectID": "lectures/w1l1_intro.html#warm-up-activity-data-science",
    "href": "lectures/w1l1_intro.html#warm-up-activity-data-science",
    "title": "Introductions",
    "section": "Warm-Up Activity: Data Science",
    "text": "Warm-Up Activity: Data Science\nForm groups of 2-3 with your peers near you. Complete the following tasks:\n\nIntroduce yourselves to each other! Mention your name, major, and one cool thing you did over winter break.\nOn a piece of paper, write the names of all group members.\nWrite down words, phrases, and ideas that come to mind when you hear “data science”."
  },
  {
    "objectID": "schedule.html#week-1-what-is-data-science-126---130",
    "href": "schedule.html#week-1-what-is-data-science-126---130",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28Friday, 1/30\n\n\n\n\n\n\n\n\nNoteLecture: CANCELLED\n\n\n\nStay warm and enjoy the snow!\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Introductions\n\n\n\n\nSlides + Activity\nNote: Office hours will be held from 3-4pm today in McConnell 207. Feel free to stop by!\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Intro to Data\n\n\n\n\nSlides\nActivity\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\nReadings #1 (due Tuesday, 2/3 on Perusall at 11:59pm)"
  },
  {
    "objectID": "schedule.html#week-2-what-is-r-and-github-22---26",
    "href": "schedule.html#week-2-what-is-r-and-github-22---26",
    "title": "Schedule",
    "section": "Week 2: What is R and GitHub? (2/2 - 2/6)",
    "text": "Week 2: What is R and GitHub? (2/2 - 2/6)\n\nMonday, 2/2Wednesday, 2/4Friday, 2/6\n\n\n\n\n\n\n\n\nNoteLecture: Intro to R\n\n\n\n\nSlides\nActivity\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #1 (due Tuesday, 2/3 on Perusall at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: R and GitHub\n\n\n\n\nSlides\nActivity\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReading Exercises #1 (due Thursday, 2/5 at 11:59pm in activities repo)\n\nExercises #1 and #3 from Appendix B in Modern Data Science with R\n\nReadings #2 (due Sunday, 2/8 at 11:59pm on Perusall)\n\n\n\n\n\n\n\n\n\n\n\nNoteLab #1: R and Understanding Datasets\n\n\n\n\nInstructions\nTemplate\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #2 (due Sunday, 2/8 on Perusall at 11:59pm)\nLab #1 (due Wednesday, 2/11 at 11:59pm)\n\nTemplate"
  },
  {
    "objectID": "schedule.html#week-3-data-visualization-the-basics-29---213",
    "href": "schedule.html#week-3-data-visualization-the-basics-29---213",
    "title": "Schedule",
    "section": "Week 3: Data Visualization, The Basics (2/9 - 2/13)",
    "text": "Week 3: Data Visualization, The Basics (2/9 - 2/13)\n\nMonday, 2/9Wednesday, 2/11Friday, 2/13\n\n\n\n\n\n\n\n\nNoteLecture: Data Visualization\n\n\n\n\nSlides\nActivity\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nLab #1 (due Wednesday, 2/11 at 11:59pm)\n\nTemplate\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Intro to ggplot\n\n\n\n\nSlides\nActivity\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nLab #1 (due Wednesday, 2/11 at 11:59pm)\n\nTemplate\n\nReading Exercises #2 (due Thursday, 2/12 at 11:59pm in activities repo)\n\nExercise #3 from Chapter 2 in Modern Data Science with R\n\nFind the two charts/graphs specifically from r/dataisbeautiful. Make sure to cite them in some fashion.\n\n\nReadings #3 (due Sunday, 2/15 at 11:59pm on Perusall)\n\n\n\n\n\n\n\n\n\n\n\nNoteLab #2: GitHub\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due"
  },
  {
    "objectID": "schedule.html#week-4-data-visualizations-ggplot-216---220",
    "href": "schedule.html#week-4-data-visualizations-ggplot-216---220",
    "title": "Schedule",
    "section": "Week 4: Data Visualizations, ggplot (2/16 - 2/20)",
    "text": "Week 4: Data Visualizations, ggplot (2/16 - 2/20)\n\nMonday, 2/16Wednesday, 2/18Friday, 2/20\n\n\nLecture #7: Types of Data Visualizations\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #8: Advanced ggplot2\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #4 (due Sunday, 2/22 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLab #3: Visualization Aesthetics"
  },
  {
    "objectID": "schedule.html#week-5-data-wrangling-223---227",
    "href": "schedule.html#week-5-data-wrangling-223---227",
    "title": "Schedule",
    "section": "Week 5: Data Wrangling (2/23 - 2/27)",
    "text": "Week 5: Data Wrangling (2/23 - 2/27)\n\nMonday, 2/23Wednesday, 2/25Friday, 2/27\n\n\nQuiz #2: Subsetting and Control Flow\nLecture #9: Intro to Data Wrangling\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #10: Data Wrangling\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #5 (due Sunday, 3/1 at 8:59pm)\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nLab #4: Plotting Frequencies and Distributions Project Time"
  },
  {
    "objectID": "schedule.html#week-6-data-joining-32---36",
    "href": "schedule.html#week-6-data-joining-32---36",
    "title": "Schedule",
    "section": "Week 6: Data Joining (3/2 - 3/6)",
    "text": "Week 6: Data Joining (3/2 - 3/6)\n\nMonday, 3/2Wednesday, 3/4Friday, 3/6\n\n\nLecture #11: Data Joining\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #12: Problem Solving\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #5: Data Wrangling (and Joining)"
  },
  {
    "objectID": "schedule.html#week-7-statistics-and-exam-1-39---313",
    "href": "schedule.html#week-7-statistics-and-exam-1-39---313",
    "title": "Schedule",
    "section": "Week 7: Statistics and Exam #1 (3/9 - 3/13)",
    "text": "Week 7: Statistics and Exam #1 (3/9 - 3/13)\n\nMonday, 3/9Wednesday, 3/11Friday, 3/13\n\n\nLecture #13: Statistics\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #14: Review\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nExam #1: In-Class"
  },
  {
    "objectID": "schedule.html#week-8-spring-break-316---319",
    "href": "schedule.html#week-8-spring-break-316---319",
    "title": "Schedule",
    "section": "Week 8: Spring Break! (3/16 - 3/19)",
    "text": "Week 8: Spring Break! (3/16 - 3/19)\n\nMonday, 3/16Wednesday, 3/18Friday, 3/20\n\n\nNo Class!\n\n\nNo Class!\n\n\nNo Class!"
  },
  {
    "objectID": "schedule.html#week-9-data-tidying-323---327",
    "href": "schedule.html#week-9-data-tidying-323---327",
    "title": "Schedule",
    "section": "Week 9: Data Tidying (3/23 - 3/27)",
    "text": "Week 9: Data Tidying (3/23 - 3/27)\n\nMonday, 3/23Wednesday, 3/25Friday, 3/27\n\n\nLecture #15: Data Tidying\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #16: Data Tidying, Part II\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #6: Data Tidying"
  },
  {
    "objectID": "schedule.html#week-10-programming-330---43",
    "href": "schedule.html#week-10-programming-330---43",
    "title": "Schedule",
    "section": "Week 10: Programming (3/30 - 4/3)",
    "text": "Week 10: Programming (3/30 - 4/3)\n\nMonday, 3/30Wednesday, 4/1Friday, 4/3\n\n\nLecture #17: Functions\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #18: Iteration and Functionals\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #7: Programming with Data"
  },
  {
    "objectID": "schedule.html#week-11-ethics-and-programming-46---410",
    "href": "schedule.html#week-11-ethics-and-programming-46---410",
    "title": "Schedule",
    "section": "Week 11: Ethics and Programming (4/6 - 4/10)",
    "text": "Week 11: Ethics and Programming (4/6 - 4/10)\n\nMonday, 4/6Wednesday, 4/8Friday, 4/10\n\n\nLecture #19: Data Ethics\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #20: Testing, Debugging, and AI\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #8: Algorithms"
  },
  {
    "objectID": "schedule.html#week-12-spatial-thinking-413---417",
    "href": "schedule.html#week-12-spatial-thinking-413---417",
    "title": "Schedule",
    "section": "Week 12: Spatial Thinking (4/13 - 4/17)",
    "text": "Week 12: Spatial Thinking (4/13 - 4/17)\n\nMonday, 4/13Wednesday, 4/15Friday, 4/17\n\n\nLecture #21: Spatial Thinking\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #22: Lying with Maps\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #9: Point Mapping"
  },
  {
    "objectID": "schedule.html#week-13-spatial-thinking-420---424",
    "href": "schedule.html#week-13-spatial-thinking-420---424",
    "title": "Schedule",
    "section": "Week 13: Spatial Thinking (4/20 - 4/24)",
    "text": "Week 13: Spatial Thinking (4/20 - 4/24)\n\nMonday, 4/20Wednesday, 4/22Friday, 4/24\n\n\nLecture #23: Project Time\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #24: Polygon Mapping\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #10: Polygon Mapping"
  },
  {
    "objectID": "schedule.html#week-14-presentations-apis-review-427---51",
    "href": "schedule.html#week-14-presentations-apis-review-427---51",
    "title": "Schedule",
    "section": "Week 14: Presentations, APIs, Review (4/27 - 5/1)",
    "text": "Week 14: Presentations, APIs, Review (4/27 - 5/1)\n\nMonday, 4/27Wednesday, 4/29Friday, 5/1\n\n\nProject #2 Presentations\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #25: APIs and Review\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLecture #26: Review"
  },
  {
    "objectID": "schedule.html#finals-52---59",
    "href": "schedule.html#finals-52---59",
    "title": "Schedule",
    "section": "Finals: (5/2 - 5/9)",
    "text": "Finals: (5/2 - 5/9)\n\nFinals Week\n\n\nGo do the final!"
  },
  {
    "objectID": "lectures/w1l1_intro.html#for-wednesday-and-beyond",
    "href": "lectures/w1l1_intro.html#for-wednesday-and-beyond",
    "title": "Introductions",
    "section": "For Wednesday and beyond",
    "text": "For Wednesday and beyond\n\nNavigate the course website\nRead through the syllabus\nComplete the pre-course survey and quiz\n\nDue Wednesday at 11:59pm, link on website under Week 1\n\nJoin the Slack, Perusall, and GitHub classroom sites\nRun through the tech setup\n\nR and RStudio"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Below you will find all resources from this course in a list format. This webpage will be updated throughout the entirety of the semester.\n\nSlidesLabsTextbooksPerusallDatasets\n\n\n\n1: Introductions\n2: Intro to Data\n3: Intro to R\n4: R and GitHub\n5: Intro to Data Visualization\n\n\n\n\n1: R and Understanding Datasets\n\nTemplate for Download\n\n2: GitHub\n3: Visualization Aesthetics\n4: Plotting Frequencies and Distributions\n5: Data Wrangling and Joining\n6: Data Tidying\n7: Programming with Data\n8: Generative AI\n9: Point Mapping\n10: Polygon Mapping\n\n\n\n\nModern Data Science\nModern Dive\nIntroduction to Data Science: Data Analysis and Prediction Algorithms with R\n\n\n\n\nAccess\n\n\n\n\nNBA, 2024 Season"
  },
  {
    "objectID": "syllabus-pdf.html",
    "href": "syllabus-pdf.html",
    "title": "Syllabus",
    "section": "",
    "text": "ContactLocation/TimeDescriptionLearning OutcomesMaterials\n\n\n\nInstructor: Jericho Lawson\nEmail: jlawson01@smith.edu\nOffice Hours:\n\nMondays, 3-4pm\nFridays, 10am-12pm\nMcConnell 207\n\n\n\n\n\nMondays, 1:40 - 2:55pm in Sabin-Reed 301\nWednesdays & Fridays, 1:20 - 2:35pm in Sabin-Reed 301\n\n\n\nData science involves applying a set of strategies to transform a recorded set of values into something from which we can glean knowledge and insight. This course will introduce you to concepts and methods from the field of data science, along with how to apply them in R. You will learn how to acquire, clean, wrangle, and visualize data. You will also learn best practices in data science workflows, such as code documentation and version control. Issues in data ethics will be addressed throughout the course.\n\n\nBy the end of this course, students will be able to do the following:\n\nData visualization: Create informative and clean visuals through various types of plots. Appropriate statistics and metrics are displayed. Use of base R and advanced libraries to generate plots (i.e. ggplot2).\nData wrangling: Develop techniques to properly use data in a workflow, which includes the transformation of data, data cleaning, and data joining. Students will also gather data in appropriate and ethical manners.\nWorkflow: Practice common tasks to working through particular data science problems, such as data retrieval, R programming, GitHub, and light statistics.\nData ethics: Identify best practices and ethical dilemmas that stem from data science work. This includes contextual thinking, environmental concerns, and intellectual property. Students will also develop ethical ways to use generative AI.\n\n\n\n\n\n\nBaumer, B. S., Kaplan, D. T., & Horton, N. J. (2024). Modern Data Science with R (3rd ed.). CRC Press. https://mdsr-book.github.io/mdsr3e/\n\nOptional:\n\nIsmay, C., Kim A. Y., & Valdivia A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). CRC Press. https://moderndive.com/v2/\nIrizarry, R. A. (2022). Introduction to Data Science: Data Analysis and Prediction Algorithms with R. CRC Press. https://rafalab.dfci.harvard.edu/dsbook-part-1/\n\n\n\n\n\nFor coding: R, RStudio\n\nFor downloading/installing: Instructions\n\nFor assignment turn-ins: GitHub\nFor discussion assignments: Perusall\n\nFor joining Perusall course: To join\n\nEnrollment code: LAWSON-2BX49\n\n\nFor course management: Moodle, but will be used seldomly\nFor course materials: This website\nFor discussions and announcements: Slack"
  },
  {
    "objectID": "syllabus-pdf.html#overview",
    "href": "syllabus-pdf.html#overview",
    "title": "Syllabus",
    "section": "",
    "text": "ContactLocation/TimeDescriptionLearning OutcomesMaterials\n\n\n\nInstructor: Jericho Lawson\nEmail: jlawson01@smith.edu\nOffice Hours:\n\nMondays, 3-4pm\nFridays, 10am-12pm\nMcConnell 207\n\n\n\n\n\nMondays, 1:40 - 2:55pm in Sabin-Reed 301\nWednesdays & Fridays, 1:20 - 2:35pm in Sabin-Reed 301\n\n\n\nData science involves applying a set of strategies to transform a recorded set of values into something from which we can glean knowledge and insight. This course will introduce you to concepts and methods from the field of data science, along with how to apply them in R. You will learn how to acquire, clean, wrangle, and visualize data. You will also learn best practices in data science workflows, such as code documentation and version control. Issues in data ethics will be addressed throughout the course.\n\n\nBy the end of this course, students will be able to do the following:\n\nData visualization: Create informative and clean visuals through various types of plots. Appropriate statistics and metrics are displayed. Use of base R and advanced libraries to generate plots (i.e. ggplot2).\nData wrangling: Develop techniques to properly use data in a workflow, which includes the transformation of data, data cleaning, and data joining. Students will also gather data in appropriate and ethical manners.\nWorkflow: Practice common tasks to working through particular data science problems, such as data retrieval, R programming, GitHub, and light statistics.\nData ethics: Identify best practices and ethical dilemmas that stem from data science work. This includes contextual thinking, environmental concerns, and intellectual property. Students will also develop ethical ways to use generative AI.\n\n\n\n\n\n\nBaumer, B. S., Kaplan, D. T., & Horton, N. J. (2024). Modern Data Science with R (3rd ed.). CRC Press. https://mdsr-book.github.io/mdsr3e/\n\nOptional:\n\nIsmay, C., Kim A. Y., & Valdivia A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). CRC Press. https://moderndive.com/v2/\nIrizarry, R. A. (2022). Introduction to Data Science: Data Analysis and Prediction Algorithms with R. CRC Press. https://rafalab.dfci.harvard.edu/dsbook-part-1/\n\n\n\n\n\nFor coding: R, RStudio\n\nFor downloading/installing: Instructions\n\nFor assignment turn-ins: GitHub\nFor discussion assignments: Perusall\n\nFor joining Perusall course: To join\n\nEnrollment code: LAWSON-2BX49\n\n\nFor course management: Moodle, but will be used seldomly\nFor course materials: This website\nFor discussions and announcements: Slack"
  },
  {
    "objectID": "syllabus-pdf.html#grading-and-expectations",
    "href": "syllabus-pdf.html#grading-and-expectations",
    "title": "Syllabus",
    "section": "Grading and Expectations",
    "text": "Grading and Expectations\n\nBreakdown\n\n\n\n\n\n\n\n\n\n\nFormative\n\n\nSummative\n\n\n\n\n\nReadings, Activities, Problems\n10%\n\nProjects (2)\n30%\n\n\nLabs\n30%\n\nExams (2)\n30%\n\n\n\nA traditional grading system will be used here. Cumulative numerical averages of 90-100 are guaranteed at least an A-, 80-89 at least a B-, and 70-79 at least a C-. The exact ranges for letter grades will ultimately be determined at the end of the course.\n\n\nMW Classes, Readings, Activties, and Exercises (10%)\nPrior to the upcoming week, readings will be assigned through Perusall that prepare you for material that will be explored thereafter. The readings on Perusall will involve:\n\nReading through the material\nWriting 2-4 annotations\nHighlighting one item you learned and one item that seems challenging\n\nThese annotations will allow me to identify which concepts to focus on in more detail during the week. Generally, these items will be due on Sundays at 11:59pm, with no acceptance of late work. Readings will be graded on completion.\nDuring Mondays and Wednesday classes, we will go through mini-lectures, activities, and demos. Classes will be experiential, meaning that you will have the opportunity to apply concepts from class to activities, exercises, and investigations. Students are expected to participate during lecture by asking questions and working with other students. Additionally, it is required that you bring your laptop to class. Class activities will be administered often during lecture, and you will have until the end of lecture to turn them in through your GitHub submission repository. These activities will be graded based on completion and/or correctness.\nOn occasion, a reading exercise may be assigned on Wednesday for you to complete. Similar to the activities, these will be turned in through your GitHub submission repository by Thursdays at 11:59pm. These exercises will be graded based on completion and correctness.\n\n\nFriday Classes and Labs (30%)\nFriday’s classes are dedicated exclusively to labs unless otherwise stated. In these labs, you will have the opportunity to compile (no pun intended) what you’ve learned and work on a experiential assignment that showcases those skills. This will involve strong usage of R and GitHub. In earlier weeks, we will get you all familiar with the technical programs along with the workflow.\nLabs in this course introduce a data science skill by walking you through exploratory analysis of a dataset documenting a socially-relevant issue (such as racial profiling in policing, affordable housing, and pollution). Labs will be started in class on Fridays and completed for homework by Wednesdays at 11:59pm. If you finish a lab early, you are encouraged to help your classmates. Labs will be graded on both completion and correctness. Note that at the end of each lab, there will be a prompt asking you to consider some of the ethical considerations of the data analysis you just completed. You must respond to this prompt in Slack to earn full credit on the lab.\nAll lab assignments will be submitted through your GitHub submission repository. You will submit assignments by pushing changes to template documents to a private GitHub repository. I will provide guidance on how to do this early in the semester.\n\n\nProjects (30% total)\nTwo projects will be assigned throughout the semester. The projects are designed to test your ability to successfully complete course objectives as described earlier. The following two projects, along with their tentative due dates, are seen below:\n\nProject #1: Data Visualizations and GitHub: due Wednesday, 3/4 at 11:59pm\n\nCreate meaningful, informative, and clear visualizations that communicate information from the data and real-world issue.\nConfigure an appropriate pipeline that funnels all relevant information, files, and summaries into a GitHub repository.\n\nProject #2: Workflow and Real-World Investigation: due Monday, 4/27 at 11:59pm\n\nComplete a detailed, attentive workflow of an investigation related to a real-world issue with appropriate data and context.\nPresent relevant information and code to various audiences in multiple formats, including a report, presentation, and demonstration.\n\n\nMore details to come in later weeks.\n\n\nExams (30% total)\nTwo exams will be administered during the course of the semester, which will include written and oral parts. The first exam will be administered in-class on Friday, 3/13, while the second exam will be administered during finals week as a self-scheduled exam. More details to come in later weeks."
  },
  {
    "objectID": "syllabus-pdf.html#policies",
    "href": "syllabus-pdf.html#policies",
    "title": "Syllabus",
    "section": "Policies",
    "text": "Policies\n\nPreparation and Attendance\nAs a four-credit course that meets 4.5 hours per week, Smith expects students to dedicate at least 7.5 hours per week towards the course outside of class. The assignments, readings, and assessments are designed with this target in mind. Expect to read through lecture notes, examples, articles, and forums outside of class along with the assignments.\nAttending class is imperative to your learning and taking part in an active community. Attendance will be taken for each class period. However, things come up and you may not have the capacity to attend. As such, you will be able to miss 3 classes with no penalty. After the third unexcused absence, your overall grade will drop by 1% for each class missed. Additional absences may be excused due to family/personal difficulties, sickness, or school or career-related activities; however, I will require some form of documentation for these absences. Please speak with your class dean or the Accessibility Resource Center so that we can get documentation of your need.\nDo make every effort to arrive to class on time. If you happen/plan to arrive more than 10 minutes late, please inform me ahead of time. Any unexplained tardiness will result in a marked absence. If you must miss a class entirely, you should contact a peer to discuss what was missed.\n\n\nExtensions\nYou will be granted 2 free late days to use for lab assignments, with a maximum of one day used on each lab assignment. Additionally, you will be granted 2 late days to use for final project submissions, with a maximum of two days used at a single time. No need to inform me that you intend to take these late days. Beyond this, late assignments will not be accepted without an accommodation from a class dean or from the ARC.\nNote that this policy does not apply to Perusall annotations, reading exercises, exams, or project checkpoints/proposals/presentations.\n\n\nAcademic Honesty\nAs a student at Smith College, the college expects all students to be honest and committed to the principles of academic and intellectual integrity in preparation and submission of all course work and examinations, as outlined by the Academic Integrity Board (AIB). The AIB provides an Academic Integrity Statement, which all students are expected to abide by. Any cases of academic dishonesty or plagiarism will be reported to the Academic Honor Board. Examples of these behaviors include:\n\nSubmitting work completed by another student as your own.\nCopying and pasting words from sources without quoting and citing the author.\nParaphrasing material from another source without citing the author.\nFailing to cite your sources correctly.\nFalsifying or misrepresenting information in submitted work.\nPaying another student or service to complete assignments for you.\nSubmitting work generated by artificially intelligent tools such as ChatGPT without permission or instruction to do so.\n\nYou are encouraged to discuss course material, including assignments, with your classmates. All work you turn in, however, must be your own. This includes both writing and code. Copying from other students, from books, or from websites (1) does nothing to help you learn how to program, (2) is easy for us to detect, and (3) has serious negative consequences.\n\n\nGenerative AI\nAs mentioned in the Academic Integrity Board, the professor for each course decides whether and how students are allowed to use generative AI in a given course. For this specific course, any use of generative AI to complete assignments or produce content for this course is prohibited, unless otherwise stated in the assignment itself.\nAs a foundational course, it is critical that you are able to think like a data scientist, which includes producing meaningful code, developing logical solutions to problem, and critiquing good results from the bad ones. While the use of generative AI can be beneficial at producing base-level code and providing insights, it comes at the detriment of your own critical thinking. The human element will be critical in succeeding in data science. If you don’t develop the skills to understand how the underlying code is composed/works, then you will not be prepared for this kind of work.\nProhibited forms of generative AI usage include but are not limited to:\n\nSummarizing course readings.\nDrafting, editing, and proofreading responses to written prompts on any assignment.\nComposing and/or formatting code and comments.\nAnswering lab, quiz, or exam questions.\nConducting analysis of any plots, methods, and results for any assignment.\n\nAny unauthorized use of generative artificial intelligence in this course will be considered a case of academic dishonesty/plagiarism and will be reported to the Academic Honor Board.\nCaveat: While the policy here is strict, do note that there will be assignments and lectures that go through the ethical and effective use of generative AI in data science as part of a unit. In these assignments, further directions will be given to showcase the use of generative AI. However, unless otherwise stated, generative AI should not be used in any assignment."
  },
  {
    "objectID": "syllabus-pdf.html#community-support",
    "href": "syllabus-pdf.html#community-support",
    "title": "Syllabus",
    "section": "Community & Support",
    "text": "Community & Support\n\nCode of Conduct\nAs the instructor for this course, I am committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor I have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students and the instructor are expected to adhere to this Code of Conduct in all settings for this course: seminars, office hours, and over Slack. This Code of Conduct is adapted from the Contributor Covenant, version 1.0.0, available here.\n\n\nPrinciples of Community\nWhether in a class, college, or neighborhood setting, achieving a warm community is essential to your well-being. In this class, I hope we can foster a collaborative and welcoming environment: one that celebrates successes, respects individual strengths and weaknesses, demonstrates compassion for each other’s struggles, and affirms diverse identities.\nTo establish this, consider the following:\n\nCheck-in with colleagues before starting collaborative work.\nConsider when to step up and when to step back in class discussions, creating space for others to contribute. Listening is just as important to community-building as speaking.\nAcknowledge what we do and don’t know, as well as how our colleagues experience the world.\nSupport colleagues that may be stepping outside of their comfort zone (i.e. presentations).\nAsk questions often in our Slack workspace. Help each other out by answering questions when you can.\nAdmit mistakes. They happen, and I will certainly make mistakes in class.\nUse pronouns. This provides a foundation to a safe, respectful classroom environment that creates a sense of trust. For information on pronouns and usage, please see the Office of Equity and Inclusion link here: Pronouns\n\n\n\nAccommodations\nIt is my goal for everyone to succeed in this course. If you have personal circumstances that may impact your experience of our classroom, I encourage you to contact the Accessibility Resource Center in College Hall 104 or at arc@smith.edu. The Center will generate a letter that indicates to me what kind of support you need and how I can make your classroom experience more accommodating. Once you have this letter, you are welcome to visit my office hours or email me to discuss ideas about how we can tailor the course accordingly. While you can request accommodations at any time, the sooner we start this conversation, the better. If you have concerns about the course that are not addressed through ARC, please contact me. At no point will I ask you to divulge details about your personal circumstances to me.\n\n\nStudent Well-Being\nCollege life is stressful, and life outside of college can be overwhelming. It is my position that attending to your physical and mental health and well-being should be a top priority. I will remind you of this often throughout the semester. I encourage you to schedule a time to talk with me if you are struggling with this course. If you, or anyone you know, is experiencing distress, there are numerous campus resources that can provide support via the Schacht Center.\nAdditional resources and support offered by the college are listed below:\n\nAccessibility Resource Center (ARC)\nSpinelli Center: Support for students doing quantitative work. Includes tutoring and resources.\n\nFor this class: Sun-Thurs, 7-9pm in Sabin-Reed 301.\nEmail qlctutor@smith.edu for specific request for help.\n\nCrisis Resources\nCounseling Services\nWellness Resources\nGender Identity and Expression\nDiscriminatory Harassment"
  },
  {
    "objectID": "syllabus-pdf.html#course-outline",
    "href": "syllabus-pdf.html#course-outline",
    "title": "Syllabus",
    "section": "Course Outline",
    "text": "Course Outline\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nCh.\nAssignments / Notes\n\n\n\n\n1\n1/26-30\nIntroduction to Data\n1\n\n\n\n2\n2/2-6\nIntro to R and Workflows\n1, B\n\n\n\n3\n2/9-13\nData Visualization\n2\n\n\n\n4\n2/16-20\nggplot2\n3\n\n\n\n5\n2/23-2/27\nData Wrangling\n4\n\n\n\n6\n3/2-3/6\nData Joining\n5\nProject #1 due: Wed, 3/4\n\n\n7\n3/9-13\nStatistics, Exam #1\n9\nExam #1: Fri, 3/13\n\n\n8\n3/16-20\nSpring Break!\n\nNo class all week long\n\n\n9\n3/23-27\nData Tidying\n6\n\n\n\n10\n3/30-4/3\nProgramming\n7\n\n\n\n11\n4/6-10\nEthics and Programming\n8, C\n\n\n\n12\n4/13-17\nSpatial Thinking\n17\n\n\n\n13\n4/20-24\nSpatial Thinking\n17\n\n\n\n14\n4/27-5/1\nAPIs and Review\n18\n Project #2 due: Mon, 4/27 \n\n\nFinals\n5/2-9\nFinals\nNA\nExam #2: self-scheduled (5/6-9) \n\n\n\n\nNote that the assignments and topics covered are tentatively scheduled and may be altered slightly as the quarter progresses. The instructor has the right to modify the syllabus if needed. If this occurs, students will be notified before the change occurs."
  },
  {
    "objectID": "resources/tech-setup.html",
    "href": "resources/tech-setup.html",
    "title": "Tech Setup (2 pts)",
    "section": "",
    "text": "WarningWarning\n\n\n\nUpdates to this document are indicated in red."
  },
  {
    "objectID": "resources/tech-setup.html#introduction",
    "href": "resources/tech-setup.html#introduction",
    "title": "Tech Setup (2 pts)",
    "section": "Introduction",
    "text": "Introduction\nYou will be setting up all software and applications that are needed to complete and submit assignments of various forms in SDS 192. We will set up the following tools in this setup:\n\nSlack\nPerusall\nR/RStudio\nGitHub Classroom\n\n\n\n\n\n\n\nTip\n\n\n\nAs you get everything set up, if you run into any hiccups along the way, there are many ways to get help:\n\nAsk questions in Slack. There will be a #techissues channel dedicated for this purpose.\n\nMake sure to be specific in your issue. Indicate which step you are stuck on and include any screenshots.\n\nFeel free to DM me on Slack or via email. With some more complex issues, I can provide some guidance.\nAsk about these issues in student hours or at the Spinelli Center."
  },
  {
    "objectID": "resources/tech-setup.html#slack",
    "href": "resources/tech-setup.html#slack",
    "title": "Tech Setup (2 pts)",
    "section": "Slack",
    "text": "Slack\nSlack will be used as a discussion forum, in which you can ask and answer clarifying questions to the whole class, provide perspectives on situations discussed in lab assignments, and find out announcements about the class on a day-to-day basis.\nIf you run into hiccups with this part, Smith’s ITS department has some quick hints here.\nNonetheless, to set up Slack, you will do the following:\n\nAccept the Slack invitation via email from this course. Follow the directions in order to get into the course.\nYou will see some of the following channels below. Go to the #general channel, go to my “Welcome” post, and reply to the thread with a random fact of your choice.\n\n\n\n\n\n\n\nOptional, but recommended: Turn on notifications from this workspace (this should already be toggled, but double-check to be sure.) Also, you may be encouraged to download and install Slack on your laptops and phones."
  },
  {
    "objectID": "resources/tech-setup.html#perusall",
    "href": "resources/tech-setup.html#perusall",
    "title": "Tech Setup (2 pts)",
    "section": "Perusall",
    "text": "Perusall\nPerusall will be used for all reading assignments, in which you will annotate and comment on particular items from weekly readings.\nTo set up Perusall, you will do the following:\n1. Click on the following link to access Perusall: link\n\nYou may need to log-in to your Smith account in order to access this.\n\nNote: Let me know if you are having difficulties accessing Perusall throughout the semester."
  },
  {
    "objectID": "resources/tech-setup.html#r-and-rstudio",
    "href": "resources/tech-setup.html#r-and-rstudio",
    "title": "Tech Setup (2 pts)",
    "section": "R and RStudio",
    "text": "R and RStudio\nR and RStudio will collectively make up the coding tools we will use to run through data science examples and assignments. R is the coding language that many statisticians and data scientists use to generate data visualizations, complete data wrangling, and run analyses. RStudio is the application that we use to interact with R, formally known as an IDE (i.e. Integrated Development Environment). We will use RStudio particularly when writing R code and walking through problems.\nWe will need to download and install R and RStudio onto our laptops. If you are running a web-based operating system (e.g. ChromeOS), you will have to use Posit Cloud to run R. Instructions to use Posit Cloud can be seen at the bottom of this section.\nFor everyone else (e.g. Windows, Mac, Linux), you will download and install R and RStudio using these instructions:\n\nGo to the following link here.\nInstall R first by clicking on “Download and Install R”, which can be found on the left side of the page.\nYou will be redirected to https://cran.rstudio.com/.\n\nWindows: Click on the link to “Download R for Windows”, choose “install R for the first time”, then choose “Download R 4.5.2 for Windows”.\nMacOS: Click “Download R for (Mac) OS X”. Download the install package for version R-4.5.2. Read the information carefully to determine which of the two versions to download.\nLinux: Click on the link to “Download R for Linux”. You will need to choose the version of Linux that corresponds to your installation. Versions are available for Debian, RedHat, SUSE, and Ubuntu.\n\nOnce the R file has been downloaded, please install R by opening the file. Follow all prompts as necessary, keeping things as defaulted as possible.\nGo back to the Posit webpage and follow step 2 on the page by clicking “Download RStudio Desktop for ____”. Once downloaded, install RStudio by opening the file. Follow all prompts as necessary.\n\nFor those using Posit Cloud:\n\nClick the Login button located at the top-right corner of the screen.\nSign-in using either Google or GitHub.\n\nIf you have trouble installing and downloading R/RStudio, we will have some time at the beginning of the first lab to walk through any issues you all have."
  },
  {
    "objectID": "resources/tech-setup.html#git-github-and-github-classroom",
    "href": "resources/tech-setup.html#git-github-and-github-classroom",
    "title": "Tech Setup (2 pts)",
    "section": "git, GitHub, and GitHub Classroom",
    "text": "git, GitHub, and GitHub Classroom\nWe will be using git commands, GitHub, and GitHub classroom to collaborate with others on coding and projects, submit coding-relative activities and assignments, and get familiar with data science workflows.\nTo differentiate between the terms, when referring to “git”, this refers to the software and commands associated with tracking changes in files during software development. The actions “push”, “pull”, “commit”, and others will pop up and we will discuss these in detail throughout the semester. GitHub refers to the application that utilizes the git system to aid in these processes. GitHub Classroom is a special use of GitHub that will allow for specific repositories to be linked to our classroom.\nA few actions need to happen to set these items up, which you’ll see in the subsections below.\n\nSetting Up Your R Environment\nIf you have any troubles, you can use the Happy Git with R textbook for assistance.\n\nGo to GitHub and create a GitHub account, preferably with your smith.edu account. Setup account details.\nOpen RStudio on your laptop.\nCheck to ensure you have git installed by opening RStudio and clicking on Tools &gt; Global Options &gt; Git/SVN tab. Check the top of the pane for a field for the Git executable. It should say something like: “/usr/bin/git” or “C:/Program Files/Git/”. If it says “(Not Found)” git is not installed.\nIn the R console (bottom-left corner), you will input and hit Enter for each of these lines of code (replace what it is in the quotations with your info):\n\n\ninstall.packages(\"usethis\")\nlibrary(usethis)\nuse_git_config(user.name = \"PUT GITHUB USERNAME HERE\", user.email = \"PUT GITHUB EMAIL HERE\")\n\n\nPut the following line of code in the console:\n\n\ncreate_github_token()\n\nDefine a name for the token and set the expiration date to be 150 days from today’s date. Leave all other settings the same and generate the token.\nOnce done, please save the token in some fashion. You will not see this token again once you leave the webpage.\n\nReturn to RStudio and run the following lines of code in the console:\n\n\nlibrary(gitcreds)\ngitcreds_set()\n\nWhen prompted for the token, paste the token you created into the console and hit Enter.\nIf you are needing additional assistance, please use the following videos:\n\nConfiguring git\nPersonal Access Token (PAT)\nStoring PAT\n\n\n\nSetting Up GitHub Classroom and Future Repositories\nYour current and future RStudio environments are now linked to your GitHub account, providing you access to repositories on GitHub itself. With this in mind, we can now replicate repositories from GitHub in a process called cloning.\n\nUse the following link below to access the test repository from GitHub Classroom:\n\nhttps://classroom.github.com/a/_arMNRWC\n\n\nYou will go through all necessary prompts. Feel free to use this video as a resource: https://www.youtube.com/watch?v=lsQ48kn-uD0\n7a. You may run into issues with having access to your repository, such as seeing this prompt:\n\nIf you see this prompt, then do the following:\n\nGo back to GitHub and click on the Notifications button located at the top-right corner of the screen.\nFind the invite notification and accept that invitation.\n\nThis should take you to your repo, and you continue on with the setup. If you cannot access the invite still, please message or email me about it.\n\nCopy the URL for your SDS 192 Lab GitHub repo. It should look like the following link:\n\nhttps://github.com/sds192lawson/tech-setup-repository-YOUR_USERNAME\n\nGo back to RStudio. At the top-left corner, click on File &gt; New Project &gt; Version Control &gt; git.\n\nPaste the URL into the first field, type a simple name for the folder in the second field, and choose an appropriate directory on your computer to house the repository. Then, click Create Project.\n\nInstall the rmarkdown package in RStudio by entering the following lines of code in the console.\n\n\ninstall.packages(\"rmarkdown\")\nlibrary(rmarkdown)\n\n\nOn the initial install, the Files tab will be in the lower right hand corner of RStudio. Open practice.qmd, and then follow the prompts in that file. Click Save.\nWe will now pull, commit, and push changes to the remote repository on GitHub. To do so, go to the Git tab on the top-right corner. From there,\n\nClick on the blue downward arrow, which pulls updates from the remote repository. This ensures we have the most recent updates.\nClick on the stacked checkmark in the same area, which will allow you to commit changes to the remote repository. Stage each file in the left column by clicking on the checkbox and add a message in the right column that briefly specifies what changes you’ve made to the repository. Click Commit thereafter.\nClick on the green upward area, which pushes updates to the remote repository. A window will pop up, showing the status of the push. If successful, you should see those updated files in your GitHub repository. You can use the URL from step 8 to verify.\n\nRepeat steps 7-9 twice, each for the following two repositories you will use for lecture activities and lab assignments respectively:\n\nActivities Repo: https://classroom.github.com/a/V5LWa0K6\nLab Repo: https://classroom.github.com/a/vO0Mut-V\n\n\nIf you are needing additional assistance, please use the following videos:\n\nConfiguring RStudio Projects\nCommitting Files\nPushing Files"
  },
  {
    "objectID": "labs/lab1/index.html",
    "href": "labs/lab1/index.html",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "",
    "text": "This lab is two-fold: to get familiar with R and RStudio and to understand the context and parts of a dataset by referencing and interpreting data dictionaries and technical data documentation.\n\n\n\nNavigate through the main functionality of RStudio, including scripts, the environment, and using the help tab\nRead a data dictionary\nReference data documentation\nIdentify unique observations in a dataset\nUnderstand different variable types\nLook up value codes and recode a variable\nDetermine the number of missing values in a variable and why they are missing\n\n\n\n\n\nRectangular Datasets\n\ndatasets in which all rows are the same length, and all columns are the same length\n\nObservations\n\nrows in a dataset; represent discrete entities we observe in the world\n\nVariables\n\ncolumns in a dataset; describe something about an observation\n\nVector\n\none-dimensional set of values that are all of the same type\n\nData Frame\n\na list of vectors of equal lengths; typically organizes data into a two-dimensional table composed of columns (the vectors) and rows\n\nUnique Key\n\nvariable (column) in the dataset that can be used to uniquely identify each row\n\nNominal categorical variables\n\nvariables that identify something else; sometimes, numbers are considered nominal categorical variables (e.g. zip code)\n\nOrdinal categorical variables\n\ncategorical variables that can be ranked or placed in a particular order (e.g. High, Medium, Low)\n\nDiscrete numeric variables\n\nnumeric variables that represent something that is countable (e.g. the number of students in a classroom, the number pages in a book)\n\nContinuous numeric variables are variables\n\nvariables in which it is always possible to measure the value more precisely (e.g. time can be measured with infinite amount of specificity - hours &gt; minutes &gt; seconds &gt; milliseconds &gt; microseconds &gt; nanoseconds …)"
  },
  {
    "objectID": "labs/lab1/index.html#introduction",
    "href": "labs/lab1/index.html#introduction",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "",
    "text": "This lab is two-fold: to get familiar with R and RStudio and to understand the context and parts of a dataset by referencing and interpreting data dictionaries and technical data documentation.\n\n\n\nNavigate through the main functionality of RStudio, including scripts, the environment, and using the help tab\nRead a data dictionary\nReference data documentation\nIdentify unique observations in a dataset\nUnderstand different variable types\nLook up value codes and recode a variable\nDetermine the number of missing values in a variable and why they are missing\n\n\n\n\n\nRectangular Datasets\n\ndatasets in which all rows are the same length, and all columns are the same length\n\nObservations\n\nrows in a dataset; represent discrete entities we observe in the world\n\nVariables\n\ncolumns in a dataset; describe something about an observation\n\nVector\n\none-dimensional set of values that are all of the same type\n\nData Frame\n\na list of vectors of equal lengths; typically organizes data into a two-dimensional table composed of columns (the vectors) and rows\n\nUnique Key\n\nvariable (column) in the dataset that can be used to uniquely identify each row\n\nNominal categorical variables\n\nvariables that identify something else; sometimes, numbers are considered nominal categorical variables (e.g. zip code)\n\nOrdinal categorical variables\n\ncategorical variables that can be ranked or placed in a particular order (e.g. High, Medium, Low)\n\nDiscrete numeric variables\n\nnumeric variables that represent something that is countable (e.g. the number of students in a classroom, the number pages in a book)\n\nContinuous numeric variables are variables\n\nvariables in which it is always possible to measure the value more precisely (e.g. time can be measured with infinite amount of specificity - hours &gt; minutes &gt; seconds &gt; milliseconds &gt; microseconds &gt; nanoseconds …)"
  },
  {
    "objectID": "labs/lab1/index.html#getting-familiar-with-r-and-rstudio",
    "href": "labs/lab1/index.html#getting-familiar-with-r-and-rstudio",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Getting Familiar with R and RStudio",
    "text": "Getting Familiar with R and RStudio\nAs discussed in the Tech Setup assignment, R is the coding language we will be using to generate plots, data wrangle, and accomplish other data science tasks. The interface we will use is RStudio.\nFor each and every lab, we will be using the lab repository you created when completing the Tech Setup assignment. On the SDS 192 website, you will find the following for each lab:\n\nLab instructions (via web)\nLab template (via .qmd)\n\nDownload the .qmd file and place that file into your lab repository. From there, open RStudio, open the lab repository project by going to File &gt; Recent Projects &gt; lab-repo. Then, open this template file up in RStudio by going to File &gt; Open File and locating the file in your repository.\nYou will see the file open up in the top-left corner of the RStudio window. You will edit the code in this file particularly.\nLet’s talk about each of the four sections you’re seeing in the RStudio window. Approximately, you will see the following:\n\n\nTop-left: This will show any files you are working on. You will use this section primarily to add code and prose to the lab templates. The templates are .qmd files, meaning you will see gray chunks that contain R code and white space that contains prose. R code should only go in gray chunks, while any written text should be in whitespace. We’ll expand upon this in later labs. Some things to note:\n\nTo create new gray chunks: Ctrl + Opt + I on keyboard\nTo run whole chunks: Hit the green “Play” button at the top-right corner of the gray chunk\nAll copy/paste and save commands are similar to what’d you see in something like Word.\n\nBottom-left: This area houses the console and terminal. I tend to use the console for single-line commands to test out code. We will not use this area too much.\nTop-right: This area houses various features, including our Environment and Git. The environment shows you which items are stored on your computer when using R and RStudio. The Git tab will be where you update items in your repository, which was mentioned in the Tech Setup assignment.\nBottom-left: This area house other features, most importantly the Files, Plots, and Help tabs. I encourage you to play around with these tabs to see their functionality. In the image above, I have it set to the Help tab; this is useful when trying to learn certain functionality of commands in R, such as the min() function.\n\nIt’s a lot to comprehend initially, so take it in stride as you work through lecture activities and lab assignments."
  },
  {
    "objectID": "labs/lab1/index.html#scorecard-dataset",
    "href": "labs/lab1/index.html#scorecard-dataset",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Scorecard Dataset",
    "text": "Scorecard Dataset\nIn his 2013 State of the Union Address, President Barack Obama announced his plans to create a “college scorecard” that would allow prospective students and parents to compare schools in terms of cost, offerings, diversity, completion rates, and post-graduate earnings. This data was first published in 2015 and since has undergone several improvements and revisions.\nThe College Scorecard dataset is massive. It includes information about over 6500 institutions in the U.S., and has more than 3000 columns documenting information about those institutions. I chose this dataset for this lab because, if you can learn to read this data dictionary, you will be leaps and bounds ahead of the game in learning to read other data dictionaries. (It’s also just a super cool dataset, and hint, hint: you will get a chance to dive into it in much more detail in a few weeks). While the full data is available online, we are only going to work with a small subset of the data today."
  },
  {
    "objectID": "labs/lab1/index.html#setting-up-your-environment",
    "href": "labs/lab1/index.html#setting-up-your-environment",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Setting Up Your Environment",
    "text": "Setting Up Your Environment\n\nInstall the RScorecard package by entering the following into your Console: install.packages(\"rscorecard\")\nCreate a Scorecard API Key at this link. Shortly after you fill out the form, you will be emailed a key. Copy that key into the code chunk below, replacing “Sys.getenv(”SCORECARD_KEY”)” in sc_key(Sys.getenv(\"SCORECARD_KEY\")). Be sure to wrap the key in quotation marks.\nDownload the Scorecard Data Dictionary and Technical Documentation for Institution-Level Data Files here.\nRun the code below to the import 2022 Scorecard data for Massachusetts into R. Call me over if you get an error.\n\n\nlibrary(tidyverse)\nlibrary(rscorecard)\nsc_key(\"O3j1bLwY61hWtl6y3krgWpWhBQufxaIRw7tHIJOu\") # Replace with your own token!!\n\nscorecard &lt;- sc_init() |&gt;\n  sc_year(2022) |&gt;                 #Note how we are looking at only 2024 data here!\n  sc_filter(stabbr == \"MA\") |&gt;     #Note how we are looking at only Massachusetts data here!\n  sc_select(unitid, instnm, city, highdeg, control, ugds, adm_rate, costt4_a, costt4_p, pcip27, pctfloan, admcon7, wdraw_orig_yr2_rt, cdr3) |&gt;\n  sc_get()"
  },
  {
    "objectID": "labs/lab1/index.html#glimpsing-the-data",
    "href": "labs/lab1/index.html#glimpsing-the-data",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Glimpsing the Data",
    "text": "Glimpsing the Data\nWhen working with very large datasets, we need tools to help us get a sense of the dataset without having to load the entire data frame. For instance, we can view the first 6 rows of the dataset by calling head().\n\nhead(scorecard)\n\n# A tibble: 6 × 15\n  unitid instnm    city  highdeg control  ugds adm_rate costt4_a costt4_p pcip27\n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 164368 Hult Int… Camb…       4       2   682   0.477     74000       NA  0    \n2 164447 American… Spri…       4       2  1142   0.894     53236       NA  0    \n3 164465 Amherst … Amhe…       3       2  1898   0.0726    80060       NA  0.095\n4 164492 Anna Mar… Paxt…       4       2   991   0.947     55594       NA  0    \n5 164535 Assabet … Marl…       1       1    54   0.474        NA    42983  0    \n6 164562 Assumpti… Worc…       4       2  1676   0.823     60262       NA  0.015\n# ℹ 5 more variables: pctfloan &lt;dbl&gt;, admcon7 &lt;int&gt;, wdraw_orig_yr2_rt &lt;lgl&gt;,\n#   cdr3 &lt;dbl&gt;, year &lt;dbl&gt;\n\n\nstr() provides a great deal of information about the observations in the data frame, including the number of variables, the number of observations, the column names, their data types, and a list of observations.\n\nstr(scorecard)\n\ntibble [147 × 15] (S3: tbl_df/tbl/data.frame)\n $ unitid           : int [1:147] 164368 164447 164465 164492 164535 164562 164580 164599 164614 164632 ...\n $ instnm           : chr [1:147] \"Hult International Business School\" \"American International College\" \"Amherst College\" \"Anna Maria College\" ...\n $ city             : chr [1:147] \"Cambridge\" \"Springfield\" \"Amherst\" \"Paxton\" ...\n $ highdeg          : int [1:147] 4 4 3 4 1 4 4 1 3 4 ...\n $ control          : int [1:147] 2 2 2 2 1 2 2 3 2 2 ...\n $ ugds             : int [1:147] 682 1142 1898 991 54 1676 2709 26 39 1263 ...\n $ adm_rate         : num [1:147] 0.4774 0.8936 0.0726 0.9466 0.4737 ...\n $ costt4_a         : int [1:147] 74000 53236 80060 55594 NA 60262 76360 NA 26691 46775 ...\n $ costt4_p         : int [1:147] NA NA NA NA 42983 NA NA NA NA NA ...\n $ pcip27           : num [1:147] 0 0 0.095 0 0 0.015 0 0 0 0 ...\n $ pctfloan         : num [1:147] 0.0956 0.8012 0.1123 0.6997 0.54 ...\n $ admcon7          : int [1:147] 3 5 5 3 3 5 5 NA 5 5 ...\n $ wdraw_orig_yr2_rt: logi [1:147] NA NA NA NA NA NA ...\n $ cdr3             : num [1:147] 0 0 0 0 0 0 0 0.029 0.017 0 ...\n $ year             : num [1:147] 2022 2022 2022 2022 2022 ...\n\n\nYou can also click on the name of your data frame in your Environment panel in RStudio, and it will open a new tab in RStudio that displays the data in a tabular format. Try clicking on scorecard in your Environment panel.\n\n\n\n\n\n\nTipTip\n\n\n\nThis is the same as calling View(scorecard) in your Console."
  },
  {
    "objectID": "labs/lab1/index.html#getting-to-know-the-dataset",
    "href": "labs/lab1/index.html#getting-to-know-the-dataset",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Getting to Know the Dataset",
    "text": "Getting to Know the Dataset\n\nObservations (Rows)\nIn starting our data analysis, we need to have a good sense of what each observation in our dataset refers to - or its observational unit. Think of it this way. If you were to count the number rows in your dataset, what would that number refer to? A unique key is a variable (or set of variables) that uniquely identifies an observation in the dataset. Think of a unique key as a unique way to identify a row and all of the values in it. There should never be more than one row in the dataset with the same unique key. A unique key tells us what each row in the dataset refers to.\n\n\n\n\n\n\nImportantQuestion 1 (5 pts)\n\n\n\nSee if you can identify a unique key for this dataset. Write some lines of code to determine whether the column you’ve identified can act as unique key for the data. Hint: You need to check whether the values in the column ever repeat.\n\n# Write code to calculate number of rows in scorecard\n\n# Write code to calculate the number of unique values in the column you've identified as a unique key \n\n# Do these numbers match?\n\n\n\nAnytime we count something in the world, we are not only engaging in a process of tabulation; we are also engaging in a process of defining. If I count the number of students in a class, I first have to define what counts as a student. If someone is auditing the class, do they count? If I, as the instructor, am learning from my students, do I count myself as a student? As I make decisions about how I’m going to define “student,” those decisions impact the numbers that I produce. When I change my definition of “student,” how I go about tabulating students also changes. Thus, as we prepare to count observations in a dataset, it is important to know how those observations are defined.\n\n\n\n\n\n\nImportantQuestion 2 (5 pts)\n\n\n\nAt this point, you’ve probably figured out that each row in this dataset is a higher education institution. However, there are many different ways that we can define higher education institutions, and that will impact what gets included and excluded in our data. Referencing the Technical Documentation, locate a definition for the unit of observation in this dataset. What institutions are included, and what institutions are excluded? Summarize a definition below.\n\n\n\n\nVariables (Columns)\nNote the column names for this dataframe, and the kinds of values that appear in those columns. Some of them (like city and year) might make sense to you immediately. Others (like pcip27 and highdeg) might be much more confusing. To figure out what we are looking at, we are going to need to refer to the dataset’s data dictionary.\nOpen the data dictionary you downloaded in an earlier step. It will open as an Excel file. Click on the tab labeled “Institution_Data_Dictionary”. There are thousands of variables in this dataset, falling into the broader categories of school, completion, admissions, cost, etc. Note how the file is organized, and specifically draw your attention to:\n\nColumn 1 (NAME OF DATA ELEMENT): This is a long description of the variable and gives you clues as to what is represented in it.\nColumn 6 (VARIABLE NAME): This is the column name for the variable. This is how you will reference the variable in R.\nColumn 7 (VALUE): These are the possible values for that variable. Note that for many categorical variables, the values are numbers. We are going to have to associate the numbers with their corresponding labels.\nColumn 8 (LABEL): These are the labels associated with the values recorded for the variable.\nColumn 11 (NOTES): This provides notes about the variable, including whether it is currently in use and what missing values indicate.\n\n\n\n\n\n\n\nImportantQuestion 3 (5 pts)\n\n\n\nFor each of the variable names in the scorecard data frame, look up the associated name in the data dictionary. You will need to search for the variable name in the sixth column of the data dictionary (I recommend using Ctrl-F to quickly locate the variable name in the spreadsheet.) Once you’ve found the variable name, reference column 1 to determine what this variable means, and reference columns 7 and 8 to see what possible values will appear in that column.\nIdentify one nominal variable, one ordinal variable, one discrete variable, and one continuous variable in scorecard and list their variable names below. Then uncomment the lines below and use the typeof() function to see how R determined their data types. Did any surprise you?\n\n#typeof(scorecard$_____)\n#typeof(scorecard$_____)\n#typeof(scorecard$_____)\n#typeof(scorecard$_____)\n\n\n\n\n\nValues (Cells)\nYou may have noticed that several categorical variables are coded as numbers in the imported dataset. For instance, look at the column control which designates the institution’s ownership. Running the code below, we see that the distinct values in that column are 1, 2, and 3.\n\nunique(scorecard$control)\n\n[1] 2 1 3\n\n\nWhen we reference that column in the data dictionary (row 27), we see that a 1 in that column designates that the institution is Public, a 2 that the institution is Private nonprofit, and a 3 that the institution is Private for-profit. While I can always look that up, sometimes it is helpful to have that information in our dataset. For instance, let’s say I create a bar plot that’s supposed to show how many higher education institutions have each type of ownership in MA (which you will learn how to do soon!). The plot can be confusing when control is a series of numbers.\n\nggplot(scorecard, aes(x = control)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWith this in mind, sometimes it can be helpful to recode the values in a column. Recoding data involves replacing the values in a vector according to criteria that we provide. Remember how all columns in a data frame are technically vectors? We can use the recode() function to recode all of the values in the control vector. We are going to store the recoded values in a new column in our dataset called control_text. Check out the code below to see how we do this. Reference the help pages for recode (i.e. ?recode) to help you interpret the code.\n\nscorecard$control_text &lt;-\n  recode(\n    scorecard$control, \n    \"1\" = \"Public\", \n    \"2\" = \"Private nonprofit\", \n    \"3\" = \"Private for-profit\",\n    .default = NA_character_\n  )\n\nCheck out our barplot now!\n\nggplot(scorecard, aes(x = control_text)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantQuestion 4 (5 pts)\n\n\n\nWrite code below to recode the admcon7 variable and store the results in a new variable in scorecard called admcon7_text. You’ll need to look up the values in the data dictionary. If you’ve done this correctly, running this code should produce a barplot that displays multiple bars.\n\nscorecard$admcon7_text &lt;-\n  recode(\n    scorecard$admcon7, \n    #Fill replacements here\n    .default = NA_character_\n  )\n\nggplot(scorecard, aes(x = admcon7_text)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\nMissing Values\nWhen we have missing values in a rectangular dataset, we have to provide a placeholder for the missing value in order for the dataset to remain rectangular. If we just skipped the value, then our dataset wouldn’t necessarily have rows of all equal lengths and columns of all equal lengths. In R, NA serves as that placeholder. Before we start analyzing data, it can be important to note how many NA values we have in a column so that we can determine if the data is representative.\nThe function is.na() checks whether a value is an NA value and returns TRUE if it is and FALSE if it isn’t. Providing a vector to is.na() will check this for every value in the vector and return a logical vector indicating TRUE/FALSE for every original value in the vector.\n\nis.na(scorecard$wdraw_orig_yr2_rt)\n\n  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [76] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [91] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[106] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[121] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[136] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nWhen we sum() across a logical vector, R will calculate the number of TRUE values in the vector.\n\nsum(is.na(scorecard$wdraw_orig_yr2_rt))\n\n[1] 147\n\n# Note that this is the same as:\n\nscorecard$wdraw_orig_yr2_rt |&gt; is.na() |&gt; sum()\n\n[1] 147\n\n\n\n\n\n\n\n\nImportantQuestion 5 (5 pts)\n\n\n\nIn a code chunk below, calculate the number of missing values in both the costt4_a and the costt4_p columns. Reference the NOTES column in the data dictionary to determine why there are so many NA values in these columns. Add a comment to the code chunk below, explaining the reason for missing values in these columns.\n\n# Write code here\n\n# Add comment here\n\n\n\n\n\n\n\n\n\nImportantQuestion 6 (5 pts)\n\n\n\nReferencing the College Scorecard data documentation, see if you can determine which students are included in calculations of earnings and debt. How might the data’s coverage bias the values that get reported? What might be the social consequences of these biases? Share your ideas on our discussions Slack channel."
  },
  {
    "objectID": "labs/lab1/index.html#submission",
    "href": "labs/lab1/index.html#submission",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Submission",
    "text": "Submission\n\nWhen you are done, save your .qmd file in RStudio in your lab-repo project.\nStage, commit, and push your file in the Git pane. Refer to steps from the Tech Setup assignment for assistance.\nNavigate back to GitHub and click on the .qmd files to make sure you see your changes to the files there. If you don’t see the changes there, I won’t see them either!"
  },
  {
    "objectID": "lectures/w1l2_data.html#reminders",
    "href": "lectures/w1l2_data.html#reminders",
    "title": "Datasets",
    "section": "Reminders",
    "text": "Reminders\n\nTech setup\n\nComponents due tonight at 11:59pm\nImportant to do before next Friday’s first lab"
  },
  {
    "objectID": "lectures/w1l2_data.html#from-survey",
    "href": "lectures/w1l2_data.html#from-survey",
    "title": "Datasets",
    "section": "From Survey",
    "text": "From Survey\n\nSolid prior experience with plots and summary statistics\n\nFocus on doing these in R\nFocus on data issues and ethics\n\nLots of practice in RStudio in class\n\nDemos and time in class to work with R"
  },
  {
    "objectID": "lectures/w1l2_data.html#from-survey-1",
    "href": "lectures/w1l2_data.html#from-survey-1",
    "title": "Datasets",
    "section": "From Survey",
    "text": "From Survey\n\nLooking forward to…\n\nCoding in R, the “what” in data science\n\nNot looking forward to…\n\nCoding, GitHub, projects\n\nHoping to get out of course…\n\nEDA, coding, real-world applications/interests"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset",
    "href": "lectures/w1l2_data.html#what-is-a-dataset",
    "title": "Datasets",
    "section": "What is a dataset?",
    "text": "What is a dataset?\n\nSource: CA Housing Data"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset-1",
    "href": "lectures/w1l2_data.html#what-is-a-dataset-1",
    "title": "Datasets",
    "section": "What is a dataset?",
    "text": "What is a dataset?\n\nCollection of data points organized into a structured format\nIn this course, we will mainly work with datasets that are structured in a two-dimensional format\n\nThese are referred to as rectangular datasets"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset-cont.",
    "href": "lectures/w1l2_data.html#what-is-a-dataset-cont.",
    "title": "Datasets",
    "section": "What is a dataset? (cont.)",
    "text": "What is a dataset? (cont.)\n\nRectangular datasets are organized into a series of rows and columns; ideally:\n\nWe refer to rows as observations\nWe refer to columns as variables"
  },
  {
    "objectID": "lectures/w1l2_data.html#collecting-and-organizing-data",
    "href": "lectures/w1l2_data.html#collecting-and-organizing-data",
    "title": "Datasets",
    "section": "Collecting and Organizing Data",
    "text": "Collecting and Organizing Data\n\nInvolves a research question we’re trying to answer\n\ne.g. What factors are contributing to a decrease in a bird species?\nExperimental vs. observational"
  },
  {
    "objectID": "lectures/w1l2_data.html#observations-vs.-variables-vs.-values",
    "href": "lectures/w1l2_data.html#observations-vs.-variables-vs.-values",
    "title": "Datasets",
    "section": "Observations vs. Variables vs. Values",
    "text": "Observations vs. Variables vs. Values\n\nGrolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/.\nObservationsVariablesValues\n\n\n\nObservations refer to individual units or cases of the data being collected.\n\nIf I was collecting data about each student in this course, one student would be an observation.\nIf I was collecting census data and aggregating it at the county level, one county would be an observation.\n\n\n\n\n\nVariables describe something about an observation.\n\nIf I was collecting data about each student in this course, ‘major’ might be one variable.\nIf I was collecting county-level census data, ‘population’ might be one variable.\nCan be categorical or numerical\n\n\n\n\n\nValues refer to the actual value associated with a variable for a given observation.\n\nIf I was collecting data about each student’s major in this course, one value might be SDS."
  },
  {
    "objectID": "lectures/w1l2_data.html#key-considerations-for-rectangular-datasets",
    "href": "lectures/w1l2_data.html#key-considerations-for-rectangular-datasets",
    "title": "Datasets",
    "section": "Key Considerations for Rectangular Datasets",
    "text": "Key Considerations for Rectangular Datasets\n\n\n\nAll rows in a rectangular dataset are of equal length.\nAll columns in a rectangular dataset are of equal length.\n\n\n\n\n\n\n\nUnderstanding Check\n\n\nLet’s say I have a rectangular dataset documenting student names and majors, and I was missing major information for one student. What would this look like in a rectangular dataset?\n\n\n\n\n\nGrolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "lectures/w1l2_data.html#how-do-i-find-out-more-information-about-a-dataset",
    "href": "lectures/w1l2_data.html#how-do-i-find-out-more-information-about-a-dataset",
    "title": "Datasets",
    "section": "How do I find out more information about a dataset?",
    "text": "How do I find out more information about a dataset?\n\nMetadata can be referred to as “data about data”\nMetadata provides important contextual information to help us interpret a dataset.\nThere are two types of metadata associated with datasets:\n\n\nAdministrativeDescriptive\n\n\n\nAdministrative metadata tells us how a dataset is managed and its provenance, or the history of how it came to be in its current form:\n\nWho created it?\nWhen was it created?\nWhen was it last updated?\nWho is permitted to use it?\n\n\n\n\n\nDescriptive metadata tells us information about the contents of a dataset:\n\nWhat does each row refer to?\nWhat does each column refer to?\nWhat values might appear in each cell?"
  },
  {
    "objectID": "lectures/w1l2_data.html#where-do-i-find-metadata-for-a-dataset",
    "href": "lectures/w1l2_data.html#where-do-i-find-metadata-for-a-dataset",
    "title": "Datasets",
    "section": "Where do I find metadata for a dataset?",
    "text": "Where do I find metadata for a dataset?\n\nOften times, metadata is recorded in a dataset codebook or data dictionary.\nThese documents provide definitions for the observations and variables in a dataset and tell you the accepted values for each variable.\nLet’s say that I have a dataset of student names, majors, and class years. A codebook or data dictionary might tell me that:\n\nEach row in the dataset refers to one student.\nThe ‘Class Year’ variable refers to “the year the student is expected to graduate.”\nPossible values for the ‘Major’ variable are Political Science, SDS, and Sociology."
  },
  {
    "objectID": "lectures/w1l2_data.html#types-of-variables",
    "href": "lectures/w1l2_data.html#types-of-variables",
    "title": "Datasets",
    "section": "Types of Variables",
    "text": "Types of Variables\nVariables can fall into one of two different types:\n\nCategorical: variable can be split into discrete groups/factors\n\nNominal: named or classified labels with no inherent order\nOrdinal: ordered labels\n\nNumerical: variable defined by a set of numbers\n\nDiscrete: countable\nContinuous: measured"
  },
  {
    "objectID": "lectures/w1l2_data.html#types-of-variables-cont.",
    "href": "lectures/w1l2_data.html#types-of-variables-cont.",
    "title": "Datasets",
    "section": "Types of Variables (cont.)",
    "text": "Types of Variables (cont.)\n\nQuestion: Provide examples of each of the four sub-types of different variables."
  },
  {
    "objectID": "lectures/w1l2_data.html#group-activity-to-turn-in",
    "href": "lectures/w1l2_data.html#group-activity-to-turn-in",
    "title": "Datasets",
    "section": "Group Activity (to turn-in)",
    "text": "Group Activity (to turn-in)\n\nNavigate to the “Activity” link in the schedule on the website\nWork in groups to answer the questions on a sheet of paper"
  },
  {
    "objectID": "lectures/w1l2_data.html#for-wednesday",
    "href": "lectures/w1l2_data.html#for-wednesday",
    "title": "Datasets",
    "section": "For Wednesday",
    "text": "For Wednesday\n\nWork on Tech Setup\nWork on Problem Solving lab (optional)\nWednesday’s class: Basics of R"
  },
  {
    "objectID": "lectures/w1l2_data.html#for-friday",
    "href": "lectures/w1l2_data.html#for-friday",
    "title": "Datasets",
    "section": "For Friday",
    "text": "For Friday\n\nWork on Tech Setup\nFriday’s class: Lab on R and Datasets"
  },
  {
    "objectID": "lectures/w1l2_act.html",
    "href": "lectures/w1l2_act.html",
    "title": "Class #2: Datasets",
    "section": "",
    "text": "Today, we are going to work with a dataset that documents cases where NYC Urban Park Rangers respond to requests for animal assistance, relocation, and/or rescue. If you are unfamiliar with what an Urban Park Ranger does, you may want to check out this video!\n\n\n\nNavigate to the NYC Urban Park Ranger Animal Condition Response dataset.\nNote the information listed in the “About this Dataset” section. This is administrative metadata.\nNote the attachment in this section with the file name: UrbanParkRangerAnimalConditionResponse_DataDictionary_20181107.xlsx. This contains descriptive metadata for this dataset.\nClick on the ‘Data’ tab at the top of the page. You can now see the data as a rectangular dataset.\nAnswer the following questions on a sheet of paper in groups of 3-4:\n\n\nWhat is the unit of observation in this dataset? In other words, what does each row signify? How do you know?\nHow frequently is this dataset updated? How do you know?\nWhat are the possible values for the Species Status variable in this dataset? How do you know?\nWhat is the value at index [3, 3] in this dataset? How do you know?\nIdentify the index of one missing value in this dataset. How do you know?\nIdentify one nominal variable, one ordinal variable, one discrete variable, and one continuous variable.\n\n\nAs a preview of what you will be able to do in a few weeks, here is a visualization of the most commons species for which services are requested in NYC!\n\n\nlibrary(tidyverse)\nnyc_urban_ranger &lt;- \n  read_csv(\"https://data.cityofnewyork.us/api/views/fuhs-xmg2/rows.csv\",\n           name_repair = make.names)\n\nnyc_urban_ranger %&gt;%\n  group_by(Species.Description) %&gt;%\n  summarize(Count = sum(X..of.Animals)) %&gt;%\n  top_n(10, Count) %&gt;%\n  ggplot(aes(x = reorder(Species.Description, Count), y = Count)) +\n  geom_col() +\n  coord_flip() +\n  labs(title=\"Top 10 Most Common Species for which NYC Urban Park Rangers Assistance is Requested, 2018-2021\", x = \"Species\", y = \"Count\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size=8))"
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "SDS 192: Introduction to Data Science",
    "section": "Announcements",
    "text": "Announcements\n\n1/25: No class on Monday the 26th due to the snowstorm. Stay warm!"
  },
  {
    "objectID": "lectures/w2l1_introR.html#last-time",
    "href": "lectures/w2l1_introR.html#last-time",
    "title": "R Fundamentals",
    "section": "Last Time",
    "text": "Last Time\n\nData fundamentals\n\nRectangular datasets\nObservations, variables, and values\nCategorical vs. discrete"
  },
  {
    "objectID": "lectures/w2l1_introR.html#today",
    "href": "lectures/w2l1_introR.html#today",
    "title": "R Fundamentals",
    "section": "Today",
    "text": "Today\n\nWelcome to R!\n\nInterface\nBasics\n\nCoding in R\n\n“hello world!”\nObjects and data structures\nOperators and functions"
  },
  {
    "objectID": "lectures/w2l1_introR.html#r-and-rstudio",
    "href": "lectures/w2l1_introR.html#r-and-rstudio",
    "title": "R Fundamentals",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is the coding language we are using for all things data science related\nRStudio is the interface (i.e. IDE) we are using to access R\nIf you haven’t installed both yet: follow these instructions here"
  },
  {
    "objectID": "lectures/w2l1_introR.html#rstudio-interface",
    "href": "lectures/w2l1_introR.html#rstudio-interface",
    "title": "R Fundamentals",
    "section": "RStudio Interface",
    "text": "RStudio Interface"
  },
  {
    "objectID": "lectures/w2l1_introR.html#rstudio-interface-cont.",
    "href": "lectures/w2l1_introR.html#rstudio-interface-cont.",
    "title": "R Fundamentals",
    "section": "RStudio Interface (cont.)",
    "text": "RStudio Interface (cont.)\n\n\n\nScript: top-left corner of screen; used to write in files\n\nQuarto (.qmd) files\n\nConsole: bottom-left corner; execute single-line commands\n\nGood for testing\n\n\n\n\nEnvironment: top-right corner; can see objects placed in memory\n\nData frames, values, etc.\n\nHelp/Plots/Viewer/etc.: bottom-right corner; used for supplemental tools\n\nCan see plots, look through help files, etc."
  },
  {
    "objectID": "lectures/w2l1_introR.html#a-classic-first-project-in-coding",
    "href": "lectures/w2l1_introR.html#a-classic-first-project-in-coding",
    "title": "R Fundamentals",
    "section": "A Classic First Project in Coding",
    "text": "A Classic First Project in Coding\n\nprint(\"Hello world!\")\n\n[1] \"Hello world!\""
  },
  {
    "objectID": "lectures/w2l1_introR.html#r-is-so-much-more-than-hello-world",
    "href": "lectures/w2l1_introR.html#r-is-so-much-more-than-hello-world",
    "title": "R Fundamentals",
    "section": "R is so much more than “Hello world!”",
    "text": "R is so much more than “Hello world!”\n\nCoding language for statisticians and data scientists\n\nPython, Julia are catching up\nTIOBE index\n\nData visualization, wrangling, and analysis\nSyntax – think of it like learning a new language!"
  },
  {
    "objectID": "lectures/w2l1_introR.html#structure",
    "href": "lectures/w2l1_introR.html#structure",
    "title": "R Fundamentals",
    "section": "Structure",
    "text": "Structure\n\nNouns: objects (mostly)\nVerbs: functions, operations\n\n\nlibrary(tidyverse)\nmtcars |&gt; select(mpg, hp)\n\n                     mpg  hp\nMazda RX4           21.0 110\nMazda RX4 Wag       21.0 110\nDatsun 710          22.8  93\nHornet 4 Drive      21.4 110\nHornet Sportabout   18.7 175\nValiant             18.1 105\nDuster 360          14.3 245\nMerc 240D           24.4  62\nMerc 230            22.8  95\nMerc 280            19.2 123\nMerc 280C           17.8 123\nMerc 450SE          16.4 180\nMerc 450SL          17.3 180\nMerc 450SLC         15.2 180\nCadillac Fleetwood  10.4 205\nLincoln Continental 10.4 215\nChrysler Imperial   14.7 230\nFiat 128            32.4  66\nHonda Civic         30.4  52\nToyota Corolla      33.9  65\nToyota Corona       21.5  97\nDodge Challenger    15.5 150\nAMC Javelin         15.2 150\nCamaro Z28          13.3 245\nPontiac Firebird    19.2 175\nFiat X1-9           27.3  66\nPorsche 914-2       26.0  91\nLotus Europa        30.4 113\nFord Pantera L      15.8 264\nFerrari Dino        19.7 175\nMaserati Bora       15.0 335\nVolvo 142E          21.4 109"
  },
  {
    "objectID": "lectures/w2l1_introR.html#values-vs.-vectors-vs.-data-frames",
    "href": "lectures/w2l1_introR.html#values-vs.-vectors-vs.-data-frames",
    "title": "R Fundamentals",
    "section": "Values vs. Vectors vs. Data Frames",
    "text": "Values vs. Vectors vs. Data Frames\n\nValuesVectorsData Frame\n\n\n\na single data point\nR understands values to be of a certain type:\n\ndouble: 3.29\ninteger: 3\ncharacter: “SDS 192”\nlogical: TRUE/FALSE\ndate-time: 1/23/84 01:23:01\n\n\n\n3.29 # double\n\n[1] 3.29\n\n3L # integer\n\n[1] 3\n\n\"SDS 192\" # character\n\n[1] \"SDS 192\"\n\nTRUE # logical\n\n[1] TRUE\n\nSys.Date() \n\n[1] \"2026-02-01\"\n\n\n\n\n\na 1-dimensional data object, listing a series of values\nall objects in a vector share the same type\nvector defined by listing entries (separated by commas) in the function c() (shorthand for concatenate/combine)\n\n\nc(1, 2, 3, 4)\n\n[1] 1 2 3 4\n\nc(\"Northampton\", \"Hadley\", \"Easthampton\", \"Amherst\")\n\n[1] \"Northampton\" \"Hadley\"      \"Easthampton\" \"Amherst\"    \n\n\n\n\n\na two-dimensional (rectangular) data object\nEvery column in a data frame is a vector\nColumn names act as a variable name for that vector (access via the $ accessor)\n\n\ndf\n\n  col1  col2 col3\n1    1  TRUE    a\n2    5 FALSE    b\n3    6  TRUE    c\n4    7  TRUE    d\n\ndf$col1\n\n[1] 1 5 6 7"
  },
  {
    "objectID": "lectures/w2l1_introR.html#assigning-objects-to-variable-names",
    "href": "lectures/w2l1_introR.html#assigning-objects-to-variable-names",
    "title": "R Fundamentals",
    "section": "Assigning Objects to Variable Names",
    "text": "Assigning Objects to Variable Names\n\n&lt;- symbol assigns a value to a variable\n\n= is okay, but not preferred\n\nStores object for future use\nVariable names should be short, descriptive, and snake-cased (lower-cased with words separated by underscores)\n\ne.g. urban_data for a dataset that refers to demographic data in a city\ne.g. test_scores for a vector of test scores from a particular class\nAvoid periods, use separator characters (_), and do not start variables with numbers"
  },
  {
    "objectID": "lectures/w2l1_introR.html#learning-check",
    "href": "lectures/w2l1_introR.html#learning-check",
    "title": "R Fundamentals",
    "section": "Learning Check",
    "text": "Learning Check\nWhat kind of object is this in R? What is its type?\n\ntemps &lt;- c(47.3, 55.6, 48.3)"
  },
  {
    "objectID": "lectures/w2l1_introR.html#learning-check-1",
    "href": "lectures/w2l1_introR.html#learning-check-1",
    "title": "R Fundamentals",
    "section": "Learning Check",
    "text": "Learning Check\nWhat would happen if I were to do the following in R?\n\nval &lt;- 34\nval &lt;- val + 1\n\n\nThis is called overwriting a variable."
  },
  {
    "objectID": "lectures/w2l1_introR.html#where-can-i-find-these-data-objects-in-r",
    "href": "lectures/w2l1_introR.html#where-can-i-find-these-data-objects-in-r",
    "title": "R Fundamentals",
    "section": "Where can I find these data objects in R?",
    "text": "Where can I find these data objects in R?\n\n\n\nObjects in R will be listed in the Environment tab in the upper right hand corner of RStudio.\nRemoving unnecessary objects from the environment can free up space!\n\n\nrm(temps)"
  },
  {
    "objectID": "lectures/w2l1_introR.html#other-data-structures",
    "href": "lectures/w2l1_introR.html#other-data-structures",
    "title": "R Fundamentals",
    "section": "Other Data Structures",
    "text": "Other Data Structures\n\nlist: used to store objects of various types\n\n\nlist(\"autumn\", c(2, 4, 6), TRUE, mtcars[1:2, 1:4])\n\n[[1]]\n[1] \"autumn\"\n\n[[2]]\n[1] 2 4 6\n\n[[3]]\n[1] TRUE\n\n[[4]]\n              mpg cyl disp  hp\nMazda RX4      21   6  160 110\nMazda RX4 Wag  21   6  160 110"
  },
  {
    "objectID": "lectures/w2l1_introR.html#other-data-structures-1",
    "href": "lectures/w2l1_introR.html#other-data-structures-1",
    "title": "R Fundamentals",
    "section": "Other Data Structures",
    "text": "Other Data Structures\n\nmatrix: 2D data structure used to store values of same type\n\nNot a list of vectors (e.g. data frame)\nUsed for matrix operations\n\n\n\nmatrix(c(1, 3, 7, 6), nrow = 2, ncol = 2, byrow = TRUE)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    7    6"
  },
  {
    "objectID": "lectures/w2l1_introR.html#activity-mathematical-operators",
    "href": "lectures/w2l1_introR.html#activity-mathematical-operators",
    "title": "R Fundamentals",
    "section": "Activity: Mathematical Operators",
    "text": "Activity: Mathematical Operators\n\nThink and write down all possible operations you would do inside an algebra class."
  },
  {
    "objectID": "lectures/w2l1_introR.html#operators-in-r",
    "href": "lectures/w2l1_introR.html#operators-in-r",
    "title": "R Fundamentals",
    "section": "Operators in R",
    "text": "Operators in R\n\nSymbols that communicate what operations to perform in R\nIncludes calculator symbols: +, -, *, /\n\n^ or ** for exponentiation\n%% for mod (remainder of a quotient of two numbers)\n\nIncludes relational symbols: &lt;, &lt;=, &gt;, &gt;=\n\n== for equivalence\n!= for non-equivalence\n\nIncludes logical symbols: & (AND), | (OR), ! (NOT)"
  },
  {
    "objectID": "lectures/w2l1_introR.html#what-is-a-function",
    "href": "lectures/w2l1_introR.html#what-is-a-function",
    "title": "R Fundamentals",
    "section": "What is a Function?",
    "text": "What is a Function?\n\nAn action done on an object to produce something\n\nInputs/arguments to outputs\ne.g. y = f(x)\ne.g. With $15, I bought a slice of pizza for $5. Now I have $10 left."
  },
  {
    "objectID": "lectures/w2l1_introR.html#structure-of-function",
    "href": "lectures/w2l1_introR.html#structure-of-function",
    "title": "R Fundamentals",
    "section": "Structure of Function",
    "text": "Structure of Function\n\nfunction_name &lt;- function(input1, ...){\n  # action to input\n  # return an output with return(__)\n}\n\n\nArguments: inputs needed to complete action\nActions: what is being done to return an output\nOutputs: the final product"
  },
  {
    "objectID": "lectures/w2l1_introR.html#example-of-function",
    "href": "lectures/w2l1_introR.html#example-of-function",
    "title": "R Fundamentals",
    "section": "Example of Function",
    "text": "Example of Function\n\npizza &lt;- function(money){\n  money &lt;- money - 5\n  return(money)\n}\npizza(15)\n\n[1] 10"
  },
  {
    "objectID": "lectures/w2l1_introR.html#finding-help",
    "href": "lectures/w2l1_introR.html#finding-help",
    "title": "R Fundamentals",
    "section": "Finding Help",
    "text": "Finding Help\n\nTyping ?FUNCTION_NAME in to the Console loads info about that function\n\n?round()\n\nWhat functions are required?\nWhat functions are optional?"
  },
  {
    "objectID": "lectures/w2l1_introR.html#learning-check-2",
    "href": "lectures/w2l1_introR.html#learning-check-2",
    "title": "R Fundamentals",
    "section": "Learning Check",
    "text": "Learning Check\nConvert the following variable name into something descriptive in snake case:\n\na &lt;- round(pi, digits = 2)\n\nRun the code in your Console. How can we find this variable in RStudio once we run this code?"
  },
  {
    "objectID": "lectures/w2l1_introR.html#helpful-value-operations",
    "href": "lectures/w2l1_introR.html#helpful-value-operations",
    "title": "R Fundamentals",
    "section": "Helpful Value Operations",
    "text": "Helpful Value Operations\n\nNumeric ValuesCharacter Values\n\n\nR can work just like a calculator!\n\na &lt;- 2\nb &lt;- 3\n\nsum(a,b)\n\n[1] 5\n\n\nWhy does this produce an error?\n\nc &lt;- \"3\"\nsum(c, c)\n\nError in `sum()`:\n! invalid 'type' (character) of argument\n\n\n\n\nR can concatenate strings!\n\nword1 &lt;- \"Harry\"\nword2 &lt;- \"Sally\"\npaste(\"When\", word1, \"Met\", word2, sep = \" \")\n\n[1] \"When Harry Met Sally\""
  },
  {
    "objectID": "lectures/w2l1_introR.html#helpful-vector-functions",
    "href": "lectures/w2l1_introR.html#helpful-vector-functions",
    "title": "R Fundamentals",
    "section": "Helpful Vector Functions",
    "text": "Helpful Vector Functions\n\nAll VectorsNumeric VectorsCategorical Vectors\n\n\n\nclass() returns the class of the values in a vector\nlength() returns the number of values in a vector\nis.na() for each value, returns whether the value is an NA value\n\n\n\n\nsum() returns the sum of the values in a vector\nmax() returns the maximum value in a vector\nrank() returns the ranking of a value in a vector\nR has other functions for accomplishing statistical, mathematical, and ordering operations\n\n\n\n\nunique() returns the unique values of a vector\ntable() returns the distribution of unique values of a vector"
  },
  {
    "objectID": "lectures/w2l1_introR.html#learning-check-3",
    "href": "lectures/w2l1_introR.html#learning-check-3",
    "title": "R Fundamentals",
    "section": "Learning Check",
    "text": "Learning Check\nHow would I find the sum of the third column in this data frame, which I have named df?\n\n\n  col1 col2 col3\n1    1    2    3\n2    5    4    6\n3    7    6    9"
  },
  {
    "objectID": "lectures/w2l1_introR.html#helpful-data-frame-functions",
    "href": "lectures/w2l1_introR.html#helpful-data-frame-functions",
    "title": "R Fundamentals",
    "section": "Helpful Data Frame Functions",
    "text": "Helpful Data Frame Functions\n\nView(): Opens a tab to view the data frame as a table\nhead(): returns first six rows of dataset\nnames(): returns the dataset’s column names\nnrow(): returns the number of rows in the dataset\nncol(): returns the number of columns in the dataset"
  },
  {
    "objectID": "lectures/w2l1_introR.html#do-i-really-have-to-memorize-all-of-these-functions",
    "href": "lectures/w2l1_introR.html#do-i-really-have-to-memorize-all-of-these-functions",
    "title": "R Fundamentals",
    "section": "Do I really have to memorize all of these functions?!",
    "text": "Do I really have to memorize all of these functions?!\n\nNo. There are cheatsheets! See this cheatsheet for Base R.\nGoogle, ChatGPT, and various forums can also be used to discover new functions\n\ne.g. “what function can be used to order a vector in R?”"
  },
  {
    "objectID": "lectures/w2l1_introR.html#pipe-operator-in-r",
    "href": "lectures/w2l1_introR.html#pipe-operator-in-r",
    "title": "R Fundamentals",
    "section": "Pipe Operator in R",
    "text": "Pipe Operator in R\n\nFunnel objects into actions\n\ne.g. data structures into various functions\n|&gt; or %&gt;%\n\nUseful for nesting functions\n\n\nlength(unique(mtcars$am))\n\n[1] 2\n\nmtcars |&gt; pull(am) |&gt; unique() |&gt; length()\n\n[1] 2"
  },
  {
    "objectID": "lectures/w2l1_introR.html#missing-values",
    "href": "lectures/w2l1_introR.html#missing-values",
    "title": "R Fundamentals",
    "section": "Missing Values",
    "text": "Missing Values\n\nRemember that missing values still have a position in rectangular datasets\nMissing values get recorded as NA in R\n…but sometimes analysts put words or numbers in their datasets to indicate missingness:\n\n“NONE”\n-999\n“” &lt;- this is the most challenging to uncover!\n\n…but what happens when we try to perform functions on vectors that contain missing values?"
  },
  {
    "objectID": "lectures/w2l1_introR.html#missing-values-in-math-functions",
    "href": "lectures/w2l1_introR.html#missing-values-in-math-functions",
    "title": "R Fundamentals",
    "section": "Missing Values in Math Functions",
    "text": "Missing Values in Math Functions\nWe can use na.rm = TRUE to ignore NA values in math functions.\n\nvals &lt;- c(1, 2, NA, 4, NA, 6)\nsum(vals)\n\n[1] NA\n\nsum(vals, na.rm = TRUE)\n\n[1] 13"
  },
  {
    "objectID": "lectures/w2l1_introR.html#for-now-and-friday",
    "href": "lectures/w2l1_introR.html#for-now-and-friday",
    "title": "R Fundamentals",
    "section": "For now and Friday",
    "text": "For now and Friday\n\nWork on Tech Setup\nWork on Problem Solving lab (optional)\nFriday’s class: Lab #1"
  },
  {
    "objectID": "lectures/w2l1_introR.html#activity",
    "href": "lectures/w2l1_introR.html#activity",
    "title": "R Fundamentals",
    "section": "Activity",
    "text": "Activity\nNavigate over to the activity for today’s lecture on the website (via the Schedule).\n\nWork on the first problem with a group of 2-3 for 8-10 minutes!"
  },
  {
    "objectID": "lectures/w2l1_act.html",
    "href": "lectures/w2l1_act.html",
    "title": "Class #2: Intro to R",
    "section": "",
    "text": "Load the following dataset into your R environment:\n\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nWith a group of 2-3 people, explore this dataset and find the following information (and where you got them from):\n\nNumber of observations and variables\nWhat does each row represent?\nA categorical and numeric variable\nInformation about the dataset (hint: use the Help tab)\n\n\nThink and write down all possible operations you would do inside an algebra class.\nConvert the following variable name into something descriptive in snake case:\n\n\na &lt;- round(pi, digits = 2)\n\nRun the code in your Console. How can we find this variable in RStudio once we run this code?\n\nSuppose I use this code to find the mean of the disp and drat columns from mtcars:\n\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\nsapply(select(mtcars, c(mpg, cyl)), mean)\n\n     mpg      cyl \n20.09062  6.18750 \n\n\nRe-write this code such that we use the piping operators.\n\nThe functions below are commonly used on vectors:\n\n\nlength()\nunique()\nsort()\npaste()\n\nFor each function, look at its help file and briefly explain what each function does when applied to a numeric vector.\nWhen done: Save, commit, and push this file to your activities repository."
  },
  {
    "objectID": "lectures/w2l1_introR.html",
    "href": "lectures/w2l1_introR.html",
    "title": "R Fundamentals",
    "section": "",
    "text": "Data fundamentals\n\nRectangular datasets\nObservations, variables, and values\nCategorical vs. discrete"
  },
  {
    "objectID": "lectures/w2l1_introR.html#objects-and-the-actions",
    "href": "lectures/w2l1_introR.html#objects-and-the-actions",
    "title": "R Fundamentals",
    "section": "Objects and the Actions",
    "text": "Objects and the Actions\n\nInformation is stored in various data structures\n\ne.g. value, data frame, list\nmtcars\n\nCan write functions to perform actions on these data structures\n\ne.g. calculations, printing/storing information\nselect()\n\n\n\nmtcars |&gt; select(mpg, hp)\n\n                     mpg  hp\nMazda RX4           21.0 110\nMazda RX4 Wag       21.0 110\nDatsun 710          22.8  93\nHornet 4 Drive      21.4 110\nHornet Sportabout   18.7 175\nValiant             18.1 105\nDuster 360          14.3 245\nMerc 240D           24.4  62\nMerc 230            22.8  95\nMerc 280            19.2 123\nMerc 280C           17.8 123\nMerc 450SE          16.4 180\nMerc 450SL          17.3 180\nMerc 450SLC         15.2 180\nCadillac Fleetwood  10.4 205\nLincoln Continental 10.4 215\nChrysler Imperial   14.7 230\nFiat 128            32.4  66\nHonda Civic         30.4  52\nToyota Corolla      33.9  65\nToyota Corona       21.5  97\nDodge Challenger    15.5 150\nAMC Javelin         15.2 150\nCamaro Z28          13.3 245\nPontiac Firebird    19.2 175\nFiat X1-9           27.3  66\nPorsche 914-2       26.0  91\nLotus Europa        30.4 113\nFord Pantera L      15.8 264\nFerrari Dino        19.7 175\nMaserati Bora       15.0 335\nVolvo 142E          21.4 109"
  },
  {
    "objectID": "lectures/w2l1_introR.html#for-now-and-wednesday",
    "href": "lectures/w2l1_introR.html#for-now-and-wednesday",
    "title": "R Fundamentals",
    "section": "For Now and Wednesday",
    "text": "For Now and Wednesday\n\nFinish activities for today’s class\nReading annotations due tomorrow at 11:59pm"
  },
  {
    "objectID": "lectures/w2l2_github.html#last-time",
    "href": "lectures/w2l2_github.html#last-time",
    "title": "R and GitHub",
    "section": "Last Time",
    "text": "Last Time\n\nWelcome to R!\n\nInterface\nBasics\n\nCoding in R\n\n“hello world!”\nObjects and data structures\nOperators and functions"
  },
  {
    "objectID": "lectures/w2l2_github.html#activity",
    "href": "lectures/w2l2_github.html#activity",
    "title": "R and GitHub",
    "section": "Activity",
    "text": "Activity\n\nTalk to 2-3 people around you and discuss any questions you may have about using R/RStudio.\nPut any questions in the anonymous Google Form here"
  },
  {
    "objectID": "lectures/w2l2_github.html#today",
    "href": "lectures/w2l2_github.html#today",
    "title": "R and GitHub",
    "section": "Today",
    "text": "Today\n\nMore behind R\n\nData imports\nMissing data\nOther topics\n\nWhat is a workflow?\n\nWhy?\nProcess\n\nGitHub\n\nWhat is it?\nActions"
  },
  {
    "objectID": "lectures/w2l2_github.html#working-directories",
    "href": "lectures/w2l2_github.html#working-directories",
    "title": "R and GitHub",
    "section": "Working directories",
    "text": "Working directories\n\nCurrent workspace that you are situated in on your computer\nCan check with getwd()\n\n\ngetwd()"
  },
  {
    "objectID": "lectures/w2l2_github.html#working-directories-1",
    "href": "lectures/w2l2_github.html#working-directories-1",
    "title": "R and GitHub",
    "section": "Working directories",
    "text": "Working directories\n\nImportant to set your working directory\n\nIf you create a project in directory, your working directory is set\nOtherwise, use setwd()\n\nNeed to find file path (Properties for Windows users, Cmd + Opt + C for Mac users on file)\n\n\n\n\nsetwd(\"..\") # to go back a folder\n\n\nsetwd(\"C:/Users/jericho/Documents\")"
  },
  {
    "objectID": "lectures/w2l2_github.html#r-projects",
    "href": "lectures/w2l2_github.html#r-projects",
    "title": "R and GitHub",
    "section": "R projects",
    "text": "R projects\n\nAssociated with an R working directory\n\nResults in own workspace and history\n\nCan be associated with a version control repository (e.g. Git)\n\nYour lab submission repository is an example\n\nTo make: File &gt; New Project"
  },
  {
    "objectID": "lectures/w2l2_github.html#data-imports",
    "href": "lectures/w2l2_github.html#data-imports",
    "title": "R and GitHub",
    "section": "Data imports",
    "text": "Data imports\n\nCan be seen as a .txt or .csv file\n\nread.table() for .txt files\nread.csv() for .csv files\n\nSpecify file path and if the header exists"
  },
  {
    "objectID": "lectures/w2l2_github.html#a-.csv-file",
    "href": "lectures/w2l2_github.html#a-.csv-file",
    "title": "R and GitHub",
    "section": "A .csv file",
    "text": "A .csv file\n\nA comma-separated file\n\nRows are created with new lines (e.g. return/enter)\nColumns are separated by commas"
  },
  {
    "objectID": "lectures/w2l2_github.html#importing-data-from-a-.csv-file",
    "href": "lectures/w2l2_github.html#importing-data-from-a-.csv-file",
    "title": "R and GitHub",
    "section": "Importing data from a .csv file",
    "text": "Importing data from a .csv file\n\nNeed to place data into same working directory as your code\n\nAdjust file path as necessary\n\n\n\nnba_data &lt;- read.csv(\"nba2024.csv\", header = T)"
  },
  {
    "objectID": "lectures/w2l2_github.html#absolute-paths",
    "href": "lectures/w2l2_github.html#absolute-paths",
    "title": "R and GitHub",
    "section": "Absolute paths",
    "text": "Absolute paths\n\nAbsolute paths list all folders from your root folder to the location of the file\n\nAvoid this as much as possible!\nReproducibility issues\n\n\nExample: “C:/Users/jericho/Documents/SDS 192”"
  },
  {
    "objectID": "lectures/w2l2_github.html#relative-paths",
    "href": "lectures/w2l2_github.html#relative-paths",
    "title": "R and GitHub",
    "section": "Relative paths",
    "text": "Relative paths\n\nRelative paths direct to the desired file from your current location\n\nMove up a directory: ../\nMove up two directories: ../../\nMove up a directory and into datasets folders: ../datasets/\n\n\nExample:\n\ndatasets/\ncode.qmd\nREADME.md"
  },
  {
    "objectID": "lectures/w2l2_github.html#reading-data-in-from-url",
    "href": "lectures/w2l2_github.html#reading-data-in-from-url",
    "title": "R and GitHub",
    "section": "Reading data in from URL",
    "text": "Reading data in from URL\n\nInstead of a file path, we can put in a URL\n\nMake sure we are connected to the internet\n\n\n\nhospital_costs_2018 &lt;- read.csv(\"https://raw.githubusercontent.com/SDS-192-Intro/SDS-192-public-website/main/slides/datasets/Hospital_Cost_Report_2018.csv\")\n\nhead(hospital_costs_2018[, 1:5])\n\n  rpt_rec_num Provider.CCN                 Hospital.Name        Street.Address\n1      623132        10032              WEDOWEE HOSPITAL 301 NORTH MAIN STREET\n2      628158       250042   NORTHWEST MS MEDICAL CENTER   1970 HOSPITAL DRIVE\n3      628833       440235 BIG SOUTH FORK MEDICAL CENTER      18797 ALBERTA ST\n4      631016        50523   SUTTER DELTA MEDICAL CENTER    3901 LONE TREE WAY\n5      631094        50305     ALTA BATES MEDICAL CENTER     2450 ASHBY AVENUE\n6      631292        50043         SUMMIT MEDICAL CENTER  350 HAWTHORNE AVENUE\n        City\n1    WEDOWEE\n2 CLARKSDALE\n3     ONEIDA\n4    ANTIOCH\n5   BERKELEY\n6    OAKLAND"
  },
  {
    "objectID": "lectures/w2l2_github.html#importing-tips",
    "href": "lectures/w2l2_github.html#importing-tips",
    "title": "R and GitHub",
    "section": "Importing tips",
    "text": "Importing tips\n\nData should be rectangular!\n\nNo merged columns/rows\nValues in every cell\n\nAvoid Excel and other proprietary formats\nAvoid spaces in column names if possible"
  },
  {
    "objectID": "lectures/w2l2_github.html#repairing-names",
    "href": "lectures/w2l2_github.html#repairing-names",
    "title": "R and GitHub",
    "section": "Repairing names",
    "text": "Repairing names\n\nIf spaces exist in column name, you must use backticks in order to reference column\n\ne.g. `column name`\nOther solutions:\n\nAssign make.names(names(your_data)) to names(your_data)\nFix each unwanted column name by accessing names(your_data)"
  },
  {
    "objectID": "lectures/w2l2_github.html#missing-data",
    "href": "lectures/w2l2_github.html#missing-data",
    "title": "R and GitHub",
    "section": "Missing data",
    "text": "Missing data\n\nIn almost all cases, missing data will occur\n\nMay show up as blank or NA\n\nSolutions:\n\nUse na.omit(your_data) to remove observations with at least one missing value\n\nEasy solution, but may be problematic if missing values occur in various spots in data\n\nImputation (only when data are missing at random)\n\nUse of replace() function"
  },
  {
    "objectID": "lectures/w2l2_github.html#example",
    "href": "lectures/w2l2_github.html#example",
    "title": "R and GitHub",
    "section": "Example",
    "text": "Example\n\ncities &lt;- c(\"Northampton\", \"Amherst\", \"Hadley\")\ntemps &lt;- c(57, 60, NA)\ninter &lt;- c(T, F, F)\ndata &lt;- data.frame(city = cities, temp = temps, inter = inter)\n\n\nna.omit(data)\n\n         city temp inter\n1 Northampton   57  TRUE\n2     Amherst   60 FALSE\n\n\n\ndata$temp &lt;- replace(data$temp, is.na(data$temp), mean(data$temp, na.rm = T))\ndata$temp\n\n[1] 57.0 60.0 58.5"
  },
  {
    "objectID": "lectures/w2l2_github.html#unnecessary-data",
    "href": "lectures/w2l2_github.html#unnecessary-data",
    "title": "R and GitHub",
    "section": "Unnecessary data",
    "text": "Unnecessary data\n\nSuppose there are small pockets of data that you deem are not the main focus of your project\n\nUse of subsetting\nTo remove: Use !(condition) within []\nTo keep: Use condition within []\n\n\n\nmtcars[mtcars$mpg &lt; 15, ]\nmtcars[!(mtcars$mpg &lt; 15), ]"
  },
  {
    "objectID": "lectures/w2l2_github.html#version-control-1",
    "href": "lectures/w2l2_github.html#version-control-1",
    "title": "R and GitHub",
    "section": "Version control",
    "text": "Version control\n\nAllows us to save and refer to versions of digital documents over time\nSupports “reproducibility” by allowing us to retrace our steps in a systematic way\n\ne.g. a resume folder\ne.g. a package\n\n\nQuestion: Why is version control important?"
  },
  {
    "objectID": "lectures/w2l2_github.html#git",
    "href": "lectures/w2l2_github.html#git",
    "title": "R and GitHub",
    "section": "Git",
    "text": "Git\n\n\nGit\n\nOpen source command line tool for version control\nInstalled on your local machine (OS-specific)\nDoes not require the use of any external tools\n\n\nGitHub\n\nWeb-hosting platform for git projects\nHosts repositories for publishing/sharing work with the broader coding community"
  },
  {
    "objectID": "lectures/w2l2_github.html#github-workflow",
    "href": "lectures/w2l2_github.html#github-workflow",
    "title": "R and GitHub",
    "section": "GitHub workflow",
    "text": "GitHub workflow\n\nPull changes from GitHub (remote) to your machine (local)\n\nImportant to ensure there are not any conflicts!\n\nMake changes on your computer\nCommit changes\n\nDo this often and leave descriptive commit messages!\n\nPull changes from remote again if working with others.\nPush changes from machine (local) to GitHub (remote)"
  },
  {
    "objectID": "lectures/w2l2_github.html#pulls",
    "href": "lectures/w2l2_github.html#pulls",
    "title": "R and GitHub",
    "section": "Pulls",
    "text": "Pulls\n\nRetrieves any changes made in remote repository, adds those changes to machine\n\nNeeds to be done when collaborating with multiple people\nWhen not done, merging conflicts can arise"
  },
  {
    "objectID": "lectures/w2l2_github.html#example-pull",
    "href": "lectures/w2l2_github.html#example-pull",
    "title": "R and GitHub",
    "section": "Example: pull",
    "text": "Example: pull"
  },
  {
    "objectID": "lectures/w2l2_github.html#commits",
    "href": "lectures/w2l2_github.html#commits",
    "title": "R and GitHub",
    "section": "Commits",
    "text": "Commits\n\nCommits are saves to a digital document\n\nStored snapshot of the document at that time\nIncludes a unique hash that allows you to track the history of changes to the document\n\nWhen you commit, you create a commit message where you document your changes.\n\nCommit messages should be descriptive of the changes made"
  },
  {
    "objectID": "lectures/w2l2_github.html#differences-and-pushing",
    "href": "lectures/w2l2_github.html#differences-and-pushing",
    "title": "R and GitHub",
    "section": "Differences and pushing",
    "text": "Differences and pushing\n\nOn committing, we can review the differences between the previous and current version of a document\n\nAdditions highlighted in green\nDeletions highlighted in red\n\nCommit, pull, and push"
  },
  {
    "objectID": "lectures/w2l2_github.html#example-differences-and-pushing",
    "href": "lectures/w2l2_github.html#example-differences-and-pushing",
    "title": "R and GitHub",
    "section": "Example: differences and pushing",
    "text": "Example: differences and pushing"
  },
  {
    "objectID": "lectures/w2l2_github.html#why-github",
    "href": "lectures/w2l2_github.html#why-github",
    "title": "R and GitHub",
    "section": "Why GitHub?",
    "text": "Why GitHub?\n\nReproducibility\nCollaboration\nLicensing\nRobust way to add descriptions (e.g. README files) and issues"
  },
  {
    "objectID": "lectures/w2l2_github.html#github-vocabulary",
    "href": "lectures/w2l2_github.html#github-vocabulary",
    "title": "R and GitHub",
    "section": "GitHub vocabulary",
    "text": "GitHub vocabulary\n\nFork: Create a copy of a GitHub repository for editing in your own user account\nClone: Download a copy of a remote repository to your local machine\nPull: Fetch changes to code from a remote repository to local machine\nStage: Select the files you wish to commit changes on\nDiff: Review the differences between different versions of files\nCommit: Take a snapshot of changes to files\nPush: Upload changes to code from local machine to remote repository"
  },
  {
    "objectID": "lectures/w2l2_github.html#collaboration-on-github",
    "href": "lectures/w2l2_github.html#collaboration-on-github",
    "title": "R and GitHub",
    "section": "Collaboration on GitHub",
    "text": "Collaboration on GitHub\n\nGitHub assigns permissions to different users to manage and make changes to files stored in a GitHub repository\n\nUse of branches and pull requests\n\nSeparate users can clone a repo to their local machine to make changes at the same time\n\nIf cloned, users will not know what changes the other is making!\nThis is why pulling often is so important!\nThere may be a different version of a file in GitHub by the time you go to push your changes"
  },
  {
    "objectID": "lectures/w2l2_github.html#push-error",
    "href": "lectures/w2l2_github.html#push-error",
    "title": "R and GitHub",
    "section": "Push error",
    "text": "Push error\n\n\nThis error indicates that you don’t have the latest version of the files on your local machine. You should pull, then push again."
  },
  {
    "objectID": "lectures/w2l2_github.html#pull-error",
    "href": "lectures/w2l2_github.html#pull-error",
    "title": "R and GitHub",
    "section": "Pull error",
    "text": "Pull error\n\n\nThis error indicates that pulling the changes that you or someone else made in remote would overwrite the changes you made on your local machine. You should commit, pull, and then push."
  },
  {
    "objectID": "lectures/w2l2_github.html#collaboration-challenges",
    "href": "lectures/w2l2_github.html#collaboration-challenges",
    "title": "R and GitHub",
    "section": "Collaboration challenges",
    "text": "Collaboration challenges\n\nWhat happens when two users have cloned a GitHub repo to their local machine and are making changes to that repo in the same place at the same time?\nWhen pushing you will get an error indicating that there is a merge conflict.\ngit wants to know which version of the file you prefer - yours or your collaborators.\nYou have to manually resolve these conflicts in an editor."
  },
  {
    "objectID": "lectures/w2l2_github.html#merge-conflicts",
    "href": "lectures/w2l2_github.html#merge-conflicts",
    "title": "R and GitHub",
    "section": "Merge conflicts",
    "text": "Merge conflicts\n\n\n\nDelete lines so that only desired code appears. Commit changes, and then push."
  },
  {
    "objectID": "lectures/w2l2_github.html#for-now-and-wednesday",
    "href": "lectures/w2l2_github.html#for-now-and-wednesday",
    "title": "R and GitHub",
    "section": "For Now and Wednesday",
    "text": "For Now and Wednesday\n\nFinish activity for today’s class\nFinish reading exercises by end of Thursday\n\nAppendix B, problems 1 and 3\n\nLab #1 due on Wednesday at 11:59pm"
  },
  {
    "objectID": "lectures/w2l2_github.html#creation-of-a-repository",
    "href": "lectures/w2l2_github.html#creation-of-a-repository",
    "title": "R and GitHub",
    "section": "Creation of a repository",
    "text": "Creation of a repository\n\nMultiple ways to do this:\n\nCreate repository on GitHub, then clone on your computer using RStudio/GitHub Desktop\nCreate new project on RStudio, then connect to GitHub\n\n\n*Note:** The repository will be seen locally and remotely."
  },
  {
    "objectID": "lectures/w2l2_act.html",
    "href": "lectures/w2l2_act.html",
    "title": "Class #4: R and GitHub",
    "section": "",
    "text": "In this activity, you will collaborate on a sample repository by making small changes and requesting a pull request."
  },
  {
    "objectID": "lectures/w2l2_act.html#questions",
    "href": "lectures/w2l2_act.html#questions",
    "title": "Class #4: R and GitHub",
    "section": "Questions",
    "text": "Questions\n\nGo to File &gt; New Project. Then, go to Version Control &gt; git. You will put the following in the first two fields:\n\n\nhttps://github.com/jericholawson/fixthis\nfixthis\n\nIn the last field, specify a folder you would want to clone this Git repository to. Click Create Project.\n\n\nGo to the Git tab in the top-right corner of RStudio. Click on the L-shaped button (right next to the “main” button).\n\n\n\nWe will create a new branch, which creates a replicate of the “main” branch that will allow us to track changes individually. Put your first name as a branch name and click Create.\n\n\n\nOpen the README.md file in your Files tab at the bottom-right corner of RStudio. You are free to add any changes to the file. Once you’ve done so, go to the Git tab and stage the README.md file by clicking the checkbox next to the file, as seen below.\n\n\n\nIn the same Git tab, click on the double-paned check button (to the left of the downward arrow). A window will pop up. Here, we need to specify a message that marks when we’ve made changes. Type a commit message along the lines of what you see below:\n\n\nClick Commit afterwards. Afterwards, use the green upward arrow to push changes.\n\nGo to the GitHub repository and click on Pull Requests. Here, you will click on the Compare & Pull Request button.\n\n\n\nAdd a quick description and click Create Pull Request. When we do this, other members of a shared repository can determine if these changes should be merged into the main branch.\n\n\nOnce you’ve made it here, you are good to go. There is nothing to submit into your activities repository."
  },
  {
    "objectID": "lectures/w1l2_data.html",
    "href": "lectures/w1l2_data.html",
    "title": "Datasets",
    "section": "",
    "text": "Tech setup\n\nComponents due tonight at 11:59pm\nImportant to do before next Friday’s first lab"
  },
  {
    "objectID": "lectures/w2l2_github.html",
    "href": "lectures/w2l2_github.html",
    "title": "R and GitHub",
    "section": "",
    "text": "Welcome to R!\n\nInterface\nBasics\n\nCoding in R\n\n“hello world!”\nObjects and data structures\nOperators and functions"
  },
  {
    "objectID": "labs/lab2/index.html",
    "href": "labs/lab2/index.html",
    "title": "Lab #2: Git and GitHub (30 pts)",
    "section": "",
    "text": "There are many reasons that Git and GitHub are essential infrastructures for collaborative coding projects. For one Git saves snapshots of a code repository at different stages of a project so that we can track how it has changed over time and revert back to an older version if we discover a more recent error. We call this version control. Certain Git features also facilitate many people working on a coding project at once, by providing a number of tools to help prevent collaborators from over-writing each other’s work. These features also make it possible for developers to simultaneously modify, extend, and test components of the code without jeopardizing the project’s current functionality. I use GitHub for assignment submission in this course because it offers a number of features for commenting on and making suggestions in your code, which will be super helpful when reviewing assignments and projects. Further, GitHub supports code publication; by publishing code on GitHub, you contribute to an open access/free software community, enabling others to learn from and build off of your work.\nDespite all of these awesome benefits, there can be a significant learning curve when getting started with Git and GitHub. There are new vocabularies, workflows, and error mitigation strategies to learn when getting started. This lab is designed to help you get acquainted with the concepts behind Git and GitHub, suggested workflows for collaborating on projects in this course, and error resolution strategies.\n\n\n\nCreate, update, and close issues\nBranch a repo\nIssue pull requests\nAddress common push/pull errors\nAddress merge conflicts"
  },
  {
    "objectID": "labs/lab2/index.html#introduction",
    "href": "labs/lab2/index.html#introduction",
    "title": "Lab #2: Git and GitHub (30 pts)",
    "section": "",
    "text": "There are many reasons that Git and GitHub are essential infrastructures for collaborative coding projects. For one Git saves snapshots of a code repository at different stages of a project so that we can track how it has changed over time and revert back to an older version if we discover a more recent error. We call this version control. Certain Git features also facilitate many people working on a coding project at once, by providing a number of tools to help prevent collaborators from over-writing each other’s work. These features also make it possible for developers to simultaneously modify, extend, and test components of the code without jeopardizing the project’s current functionality. I use GitHub for assignment submission in this course because it offers a number of features for commenting on and making suggestions in your code, which will be super helpful when reviewing assignments and projects. Further, GitHub supports code publication; by publishing code on GitHub, you contribute to an open access/free software community, enabling others to learn from and build off of your work.\nDespite all of these awesome benefits, there can be a significant learning curve when getting started with Git and GitHub. There are new vocabularies, workflows, and error mitigation strategies to learn when getting started. This lab is designed to help you get acquainted with the concepts behind Git and GitHub, suggested workflows for collaborating on projects in this course, and error resolution strategies.\n\n\n\nCreate, update, and close issues\nBranch a repo\nIssue pull requests\nAddress common push/pull errors\nAddress merge conflicts"
  },
  {
    "objectID": "labs/lab2/index.html#review-of-key-terms",
    "href": "labs/lab2/index.html#review-of-key-terms",
    "title": "Lab #2: Git and GitHub (30 pts)",
    "section": "Review of Key Terms",
    "text": "Review of Key Terms\n\nRepo\n\nCollaborative storage space for folders, documents, data, and code\n\nBranch\n\nAn isolated version of a repo that can be modified without affecting the main branch\n\nClone\n\nCreates a copy of a repo stored in a remote space (e.g. GitHub) to your local machine (e.g. your computer)\n\nPull\n\nDownloads the latest version of a repo from remote space (e.g. GitHub) to your local machine (e.g. your computer)\n\nStage\n\nThe process of marking which changes of the code are ready to be saved\n\nCommit\n\nA stored snapshot of a repo at a particular moment in time\n\nPush\n\nUploads commits from your local machine (e.g. your computer) to a remote space (e.g. GitHub)\n\nPull Request\n\nA request for modified code to be integrated with a different branch\n\nMerge\n\nThe process of integrating code modifications from one branch into another branch"
  },
  {
    "objectID": "labs/lab2/index.html#github-flow",
    "href": "labs/lab2/index.html#github-flow",
    "title": "Lab #2: Git and GitHub (30 pts)",
    "section": "GitHub Flow",
    "text": "GitHub Flow\n\ngit vs. GitHub\nAt the beginning of this semester, many of you installed git on your computers. git is a series of commands available in our computers to save snapshots of files at different moments in time. On the other hand, github.com is a website where we can store projects that have been configured with git commands. When you accepted the lab submission repository for this course, a project folder (what we will call repository) had been created for you on GitHub. If you navigate to GitHub right now, you will see the project folder, and you can click on it see changes that have been made. However, when you created a project for this repository in RStudio, you were using git commands on your computer to copy the project from GitHub to your computer. Similarly, you were using git commands when you staged, committed, and pushed your changes back to GitHub. In summary, git is a series of command line tools to manage changes to files. GitHub is a Web hosting platform for storing git projects.\n\n\nRemote vs. Local\nWe can store, edit, and publish files on GitHub without ever copying them to our local computers. Files on GitHub are technically stored on a server somewhere, so we will refer to the projects stored on GitHub as remote (i.e. distant, far-off, etc). Similarly, we can use git commands to save snapshots of different versions of files on our local computers without ever pushing the changes to GitHub, so we will refer to the projects stored on on our computers as local. In this course, we need the ability to move file changes between our local and remote repositories.\nWhy can’t we just do everything at GitHub or everything on our local machines? Well GitHub doesn’t have the nice environment for writing and running code that you have in RStudio, so we need to be able to move things to your local computers so that you can work on the code in RStudio. On the other hand, if all the work was done on your local computer and never pushed to GitHub, I (your instructor) would never see it! So the first important consideration in the GitHub Flow is how do we move changes made on our local machines to GitHub and vice versa.\nThe great news is that you’ve already been doing this! The primary way that we move changes between remote and local is through two git commands: pull and push. Pull copies changes from a remote repository to our local machines. Push pushes changes from our local machines to a remote repository. It looks like this:\n\nTypically, we want to make sure that we always follow this flow:\n\nPull changes from GitHub (remote) to local.\nMake changes locally.\nPush changes to GitHub.\n\nAs we are going to see later in the lab, the most frustrating issues with GitHub emerge when we break this flow.\n\n\nTo Branch or Not to Branch?\nIn my opinion, there are two kinds of workflows for GitHub. There’s the quick and dirty version, and there’s the long and elegant version. We just went over the Quick and Dirty version, and you’ve already had practice in it when submitting all of your labs for the course. Below are the differences between these two workflows (don’t worry about if you don’t understand what the steps mean right now; we will learn all of them in the lab).\n\n\n\n\n\n\n\nQuick and Dirty Version\nLong and Elegant Version\n\n\n\n\n\nPull recent changes from GitHub to local machine.\nMake edits and save them\nStage and commit changes.\nPush changes from local machine to GitHub.\n\nIn the quick and dirty version, all of this occurs in the main branch.\n\nCreate an issue at GitHub |\nBranch the repo at GitHub. |\nPull recent changes from GitHub to local machine. |\nMake edits in the new branch and save them.\nStage and commit changes.\nPush changes from local machine to GitHub. |\nCreate a pull request at GitHub |\nAssign a reviewer to review the proposed changes and wait for their approval.\nMerge changes, while also closing the issue and deleting the branch.\n\n\n\n\nThe long and elegant version is recommended for group work as it is designed to avoid errors and ensure that collaborators are all on the same page regarding changes to files. However, occasionally when you have to make small, quick changes to a file, and it won’t impact your teammate’s work, it will make more sense to follow the quick and dirty workflow. The goal for today is to get practice in the long and elegant version.\n\n\nRepo\n\n\n\n\n\n\nImportantQuestion 1\n\n\n\nNavigate to GitHub Classroom to accept the assignment. For this assignment, you will work with up to 2-3 people. Make sure everyone is in the same group.\n\n\nThis will create a repository at GitHub called lab-2. You’ll notice that the repository has a few files:\n\nREADME.md\ngithub-practice.Rmd\n\n\n\nClone\nCloning is a git command that copies a remote repository to your local machine. In other words, it will copy all of the project files in the remote GitHub folder to your local computer.\n\n\n\n\n\n\nImportantQuestion 2\n\n\n\nClone the repo to your RStudio environment. To do so, copy the repo’s URL at GitHub. You will want to make sure you are in the main project folder when you copy this URL; it won’t work if you’ve clicked through to any of the files. Then in RStudio click on File &gt; New Project &gt; Version Control &gt; Git, and paste the copied URL into the window that appears. Note what you see in the RStudio files pane after cloning the repo.\n\n\nRemember that cloning creates a copy of a remote repo on a local machine. In creating this project, you’ve copied all of the files that make up the github-practice repo at GitHub to your local computer. This means that you will find all of the files associated with this repo by navigating to the folder where you created the project on your computer.\nIt’s important to note that this is not just any old folder on your computer though. By cloning, you’ve created a git folder. This means that the folder has been set up in a way where git can track the changes that you make to it over time, and it knows that there is a remote version of the repository somewhere that you might want to keep it consistent with. If you tried to just create a new folder on your computer, it wouldn’t necessarily have these nice features.\n\n\nIssues\n\n\n\n\n\n\nImportantQuestion 3\n\n\n\nNavigate back to GitHub, and click on the repo’s Issues tab. Create an issue by clicking the ‘New Issue’ button. Title the issue: “Adding &lt;your name&gt; to the assignment.” Submit the issue, and to the left of the screen, assign the issue to yourself.\n\n\n\nIssues support project planning by allowing you to track changes you hope to make to your project over time. By assigning issues to certain collaborators on your project team, you can have clear documentation of who is responsible for what.\n\n\n\n\n\n\nTip\n\n\n\nIssues can be used for a number of purposes. Issues can be assigned to bugs that are in certain coding scripts. Other times, issues can be used to track features that need to be added to code down the road. Additionally, those using code can submit issues to ask questions about how something works, to report bugs, or to request features.\n\n\n\n\nBranch\nWhen you first create a repository, all of the code will be stored in the main branch of the repository. If you were to think of a project like a tree growing up from the ground, then the main branch would be the like the trunk of the tree. We don’t want the main branch to break because the whole tree could come down. One goal of a branching workflow in GitHub is to keep the most stable and polished versions of code in the main branch.\nSo what do we do in the meantime - when we’re editing code, potentially breaking things, trying to sort out its bugs, and it’s not quite in that stable and polished state yet? That’s where branching comes in.\nWhen we create a branch of our repo, GitHub creates a separate copy of the repo where you can make changes without impacting what’s in the main branch. Later, once we’re done making changes and things are stable and polished, we will have the opportunity to merge those changes back into the main branch.\nThink of it another way: You write a rockstar first draft of a final paper, and you decide to send it to a few friends to review. You could just share the original document with them and tell them “Have at it! Edit away!” The problem is that, if they are making changes directly to the original document, you could lose some of that awesome original text. A better option would be to create separate copies for each teammate to edit, send them those copies, and then figure out how to layer in their edits later. This is like branching. The original document would be the main branch, and each copy sent to a friend would be a branch off of main. Friends can make as many edits as they want in their branch because you still have the original stable and polished copy. Later, we can merge their changes back into the main branch.\n\n\n\n\n\n\n\nTip\n\n\n\nBranching can get pretty wild in GitHub. You can have branches of branches of branches. I don’t recommend this. A good workflow is to create a branch for making specific changes, merge those changes back into main, delete the branch, and then create a new branch for the next batch of changes.\n\n\n\n\n\n\n\n\nImportantQuestion 4\n\n\n\nClick on the Code tab on your repo’s page on GitHub. irectly below this tab, you will see a dropdown that is currently labeled “main.” This means that you are in the main branch. Each member of your team should click the down arrow, and create a branch by entering their first name into the textbox that appears, and then clicking “Create branch.”\n\n\n\n\n\nPull\nAs of right now, the branch that was created in the previous step only exists on GitHub; it doesn’t exist yet on your local machine. To get these changes to your local machine, you need to Pull the changes. Remember how we said that the super fancy git folder knows that there is a remote version of the repository somewhere that you might want to keep it consistent with? When we pull changes to our local machines, we are basically saying, check that remote version for changes, and then pull them into the repo on my computer.\n\n\n\n\n\n\nImportantQuestion 5\n\n\n\nHead back to RStudio. In the Environment pane, you will notice a tab labeled “Git.” It’s important to note that this tab will only appear in projects that are built from super fancy git folders. This is your RStudio command center for Git and GitHub. When you click on this tab, you will see a few buttons in the navigation bar. To pull changes, you should click the blue downward arrow. Click this button to pull the branches created remotely to your local machine.\n\n\n\n\n\nSwitch Branches\nEven though you pulled the new branches to your local machine, you are still currently working in the main branch. Remember that we always want to keep the main branch stable and polished. This is not where we are going to make edits. Instead, you will make edits in the branch that you just created. Later, we will merge those changes back into the main branch.\n\n\n\n\n\n\nImportantQuestion 6\n\n\n\nIn the top right hand corner of the Git tab, you will see a dropdown currently set to “main”. Click the downward arrow, and switch to your branch by selecting the appropriate branch.\n\n\n\n\n\nMake Changes\n\n\n\n\n\n\nImportantQuestion 7\n\n\n\nOnce in your branch, open github-practice.Rmd from the files pane. Decide within your group who will be Group member 1, 2, 3, and so on. Each group member should edit this file on their own local machines by adding their name and only their name to the appropriate location in the document (line 5, 7, or 9) based on their assigned number. It’s very important that this be the only section of the document you edit. Save the file by clicking File&gt;Save.\n\n\n\n\nStage\nSometimes we make a changes to a few files, save them, and we’re ready to create a snapshot of our repo (i.e. create a commit) with some of those changes. Remember that creating this snapshot is almost like taking a photo of the repo at this particular moment, allowing us to later go back to that photo to see what the repo looked like in that moment. To let Git know which changes we want to include in that snapshot, we need to stage the files. Staging basically says, “these files are ready to be included in the snapshot.”\n\n\n\n\n\n\nImportantQuestion 8\n\n\n\nOnce you save the file you’ll notice in the RStudio Git pane that the file name appears after a blue square labeled “M” (which stands for Modified). This means that the file is ready for staging. Stage the file - indicating that it’s ready for committing - by clicking the checkbox in front of the file name.\n\n\n\n\n\nCommit\nAs we just noted, committing changes basically means taking a snapshot of a repo at a particular moment in time. Commits are given unique hashes - sort of like a unique identifier that enables us to access the snapshot of the repo at a later date. In collaborative projects, it is typically recommended to commit often - after any major changes are made to a file. This ensures that we can eventually go back to look at very specific changes. It’s also important to label commits with descriptive titles so that we can recall what changes within that commit. Descriptive titles should detail what changes were made in the last round of edits.\nTo help put this into context, think back to our photograph metaphor. Let’s say that we are a photographer assigned to document how a baby develops in the first year of its life. If the photographer only took one photograph when the baby was 1 year old, we wouldn’t have a lot of documentation regarding how the baby developed! …so instead, let’s say that the photographer took a snapshot of the baby after every major milestone - their first laugh, their first solid food, their first crawl, their first word. We would have a lot more to go by when trying to understand how the baby developed. Same goes for committing code often.\nNow let’s say the photographer handed the batch of photos to the parents, and said - “look, here’s how your baby developed over time.” The parents might not remember which photograph was taken after which milestone. …but if the photographer were to label each photograph with things like “baby had first laugh,” the parents would be able to easily go back to specific moments in their baby’s development. This is why we want descriptive commit messages. We want to later be able to go back and scan through what changes were made after each commit.\nTo get a sense of what it means to be able to look back on these changes, check out the latest commits that I made to the GitHub repo for our course website. While I’m not going to claim to be the most diligent commit-er, you do get a basic sense of what changes were made to the repo following each commit from these commit messages. I could click through any of these links to see what my repo looked like at this moment in time.\n\n\n\n\n\n\n\nImportantQuestion 9\n\n\n\nCommit your changes by clicking the ‘Commit’ button in the Git pane. When you click this button, a new window will open showcasing the changes that have been made to the staged file. You should enter a commit message in the window that appears. Remember that commit messages should be descriptive. In this case, something like “added &lt;your-name&gt;’s name” would work. Click commit. Now a snapshot of this version of the code repo has been taken.\n\n\n\n\nPush\nOnly your local machine knows that a change has been made to the code. Remember again how we said that the super fancy git folder knows that there is a remote version of the repository somewhere that you might want to keep it consistent with? Now we want to do the opposite of pulling changes from GitHub to our local machines. Instead, we want to push the changes on our local machines to GitHub.\n\n\n\n\n\n\nImportantQuestion 10\n\n\n\nClick the Green upward arrow in the Git pane to push your changes to GitHub.\n\nOnce all group members have pushed their changes, head back over to GitHub. On the main code page, switch between branches and check out the contents of github-practice.Rmd in each branch. What differences do you notice?\n\n\n\n\nPull Request\nNote that now we have a few versions of our repo in separate branches on GitHub, and in each of those versions of the repo, the github-practice.Rmd file looks a little bit different. Now that we’ve made our changes and things are stable and polished, we want to move all of those changes into the main branch. To do this, we are going to issue a Pull Request. This is a request that signals to all of our collaborators that we are ready to move our changes back into the main branch.\n\n\n\n\n\n\nImportantQuestion 11\n\n\n\nOn your repo’s page in GitHub, click the “Pull Requests” tab, and then click the green “New Pull Request” button. You’re requesting to pull the changes from your personal branch into the main branch. This means that the base branch should be main, and the compare branch should be your personal branch.\n\nYou’ll see a screen where you can compare your branch to the main branch. Click the button to “Create Pull Request,” enter a descriptive title of the changes made, and then click “Create Pull Request” again.\n\n\n\n\nReview Pull Requests\nI recommend that you get in the habit of reviewing your collaborator’s work before merging their changes into the main branch. By creating pull requests, we scaffold an opportunity to review each other’s work before fully integrating the changes.\nNow there should be a pull request for all members of your team. Assign one team member to review one other team member’s code. All team members should have one reviewer.\n\n\n\n\n\n\nImportantQuestion 12\n\n\n\nOpen your own pull request in GitHub, and in the right sidebar, assign the team member responsible for reviewing your changes as a “Reviewer.”\n\nThen navigate to the pull request you are responsible for reviewing. Click on the “Files Changed” tab. Note that the left side of the screen shows the previous version of the file, and the right side of the screen shows the new version of the file. Lines in red have been deleted, and lines in green have been added.\n\nAfter looking through the changes, click the green button “Review changes.” Leave a note for your collaborator, indicating your evaluation of their changes. If everything looks good, check the radio button for “Approve.” If there are issues, check the radio button for “Request Changes.” Then click the button to “Submit Review.”\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf your reviewer requested changes, you should go back to RStudio, and make sure you are in your own branch. Then make the requested changes, save the file, stage the file, commit the changes, and push again. The changes to your file will be tracked in your pull request. After this, you may move on to the Merge step. See here for further options on dismissing or re-requesting reviews.\n\n\n\n\nMerge\nOnce all reviewers have approved changes, we are ready to merge those changes into the main branch. Open each pull request. If everything is good and ready to merge, you will see a green checkmark that says “This branch has no conflicts with the base branch.”\n\n(If you get a message that there are conflicts, call myself or one of the Data Assistants over.)\n\n\n\n\n\n\nImportantQuestion 13\n\n\n\nClick the button to “Merge Pull Request”. In the comment box that appears, enter the text “closes #”. When you enter this text, you will see a dropdown of issues and pull requests currently in the repo. Issues will have an icon that appears as a circle with a dot in the center.\n\nSelect the issue associated with this pull request, and then click “Confirm Merge.” This will both merge the changes into the main branch and simultaneously close the issue you opened earlier. Finally, click the button to the delete the branch. Once this has been completed for all pull requests, head back over to the “Code” tab at GitHub, and check out github-practice.Rmd. What has happened to the file since merging the code? Navigate to the “Issues” tab. What has happened to the issues since confirming the merge?\n\n\n\n\n\n\n\n\nImportantBefore moving on to the next section…\n\n\n\nYou’ve now deleted branches at GitHub that your local machines don’t know have been deleted. Before moving on to the next step, you should navigate back to RStudio and pull these changes to your local machine by clicking the blue downward arrow. To streamline things in the next section of the lab, we are going to work entirely in the main branch (something that I would otherwise not recommend)."
  },
  {
    "objectID": "labs/lab2/index.html#error-resolution",
    "href": "labs/lab2/index.html#error-resolution",
    "title": "Lab #2: Git and GitHub (30 pts)",
    "section": "Error Resolution",
    "text": "Error Resolution\nThe workflow presented above seems to work all fine and dandy. But there are a number of factors that can impede this seamless workflow. In this final section of the lab, we will go over three kinds of errors that you might come across in the workflow above, and talk about how you would resolve them. I can almost guarantee that you will deal with some of these issues when working on your group projects, so I would encourage you to keep this lab handy when engaging in project work.\n\nPush error\nA push error occurs when we make changes to files on our local machines, and go to commit and push them to GitHub, but other changes had already been made to the file at GitHub that were not yet pulled into our local environments. We get an error because our local repo is inconsistent with the remote repo. To fix this error, we need to pull changes to our local machine, and try committing and pushing again. Let’s replicate this error:\n\n\n\n\n\n\nImportantQuestion 14\n\n\n\nOne of your partners should navigate to the GitHub repository. Click on the file README.md. Click the pencil icon to edit the file. Replace the text: ADD NAME 1 HERE ADD NAME 2 HERE, and so on with your names. Scroll to the bottom of the page and commit changes noting in the message that your names were added.\nOther partner: Return to RStudio. Do not pull changes yet. Open github-practice.Rmd. On line 40 change the ncol() function to dim(). Save the file. Stage and commit your changes. Click the green upward arrow to push your changes. You should get an error that looks like this.\n\nFollow the steps above to resolve the error.\n\n\nAn easy way to avoid a push error is to always click the blue downward arrow to pull remote changes before starting to edit files on your local machine.\n\n\nPull error\nA pull error occurs when changes have already been made to the same location (the same line number) in both a remote file and a local file, and then we try to pull the changes from the remote repo to our local machines. As far as Git can tell, there are two options for what this line is supposed to look like, and it can’t tell which to prioritize. So Git recommends that, as a first step, we commit the changes that we made locally. It’s basically saying, let’s take a snapshot of your local repo as it looks right now, so that later we can figure out what to do about this conflict.\nIf this seems confusing imagine this: let’s say you write a paper, and you share it with one of your classmates to review. The classmate reads through it, makes suggested changes to the opening sentence, and sends it back you. …but, while your classmate was reviewing the paper, you were getting antsy about the paper deadline and started making your own edits to the paper, including edits to the opening sentence. Now you’re trying to incorporate the changes from your classmate’s review, and you’re not sure what to do about that opening sentence. As a first step, you have two options you can scrap your recent changes (maybe your classmate’s suggestions were better!) or you can save a separate copy of the file with your recent changes and figure out later how to resolve the differences. That’s exactly what we are going to do here:\nTo fix this error, you should stage and commit your local changes and then try pulling again. Let’s replicate this error:\n\n\n\n\n\n\nImportantQuestion 15\n\n\n\nOne of your partners should navigate to the GitHub repository. Click on the file github-practice.Rmd. Click the pencil icon to edit the file. Replace the code on line 47 with the following: colnames(pioneer_valley_2013).\nScroll to the bottom of the page and commit changes noting in the message how you updated the function.\nOther partner: Return to RStudio. Do not pull changes yet. Open github-practice.Rmd. Replace the code on line 47 with the following: ncol(pioneer_valley_2013)\nSave the file. Click the blue downward button to Pull changes. You should get an error that looks like this.\n\nFollow the steps above to resolve the error.\n\n\n\n\nMerge conflict\nSo now we have these two snapshots of github-practice.Rmd, and they are in conflict with one another. If we try to push our changes back to GitHub, Git is not going to know what to do. Should the file at GitHub look like the version currently at GitHub, should it look like the snapshot that we just commit to our local machines, or should it look like something else entirely?\nLet’s return to the example of trying to incorporate a peer’s edits to a paper that you have recently made changes to. We have to figure out what to do about that opening sentence. Do we want our version, their version, or some combination of the two? This is what it is like to fix a merge conflict.\nTo fix this error, open the file with conflicts and edit the lines with conflict.\n\n\n\n\n\n\nImportantQuestion 16\n\n\n\nOne of your partners should try to pull changes by clicking the blue downward arrow in RStudio. You will get an error that looks like this:\n{fig-alt=“This is the window that we see when we get a merge conflict. It says: CONFLICT (content): Merge conflict in README.md}\nTo fix this one your partners should open the file with the conflict. In this case it will be github-practice.Rmd. Scroll to the section of the file with the conflict. It will now look something like this:\n    &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n\n    ncol(pioneer_valley_2013)\n\n    =======\n\n    colnames(pioneer_valley_2013)\n\n    &gt;&gt;&gt;&gt;&gt;&gt;&gt; ee175895783b64e0e1f696d9456be4c4c7c3f3bf\nThe code following HEAD represents the recent changes you made on your local machine, and the code right before the long string of characters represents the changes that were made in an earlier commit (the long string of characters is the commit hash). Decide what that line should look like and delete all other content. This means you must delete “&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD”, “=======”, and “&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;long-hash&gt;”, and you likely should delete at least one other line. Save the file, stage the file by clicking the checkbox next to the file in the Git page, and then commit your changes, and push them to GitHub.\n\n\n\n\n\n\n\n\nTipAvoiding Merge Conflicts\n\n\n\nYou may have noticed that the most frustrating merge conflicts tend to emerge when we have two people working on the same line of a repo’s file. The most effective way to avoid merge conflicts is to ensure that collaborators are working on different documents or different lines in a file. One way you might do this when starting to work on your group project is to open a file that you all plan to work on and having one of your team mates section off space of that file for different people to work. It might look something like this:\n\nOnce this change has been made, that group mate should stage, commit, and push the file to GitHub, and all other group mates should pull the change to their local machines.\n\n\n\n\nPath of Least Resistance\nI have been working with GitHub for years, and even to this day, I run into instances where things become so inconsistent between my local machine and the repo at GitHub that the fastest way to fix things is just to save local copies of the files that I’ve changed to somewhere else on my machine, delete the super fancy Git folder from its current location, and then re-clone the most up-to-date remote version to my local machine. Then I can figure out how I want to edit the most up-to-date version with my changes. This comic from XKCD captures this widely acknowledged solution beautifully:\n\n\n\n\n\n\n\nCautionEthical Considerations\n\n\n\nIncreasingly, when data science researchers publish a paper in a journal, they are making the code they used to reach certain results freely available on GitHub for other researchers and the public to review. This is in part a response to the reproducibility crisis that you learned or will learn about in SDS 100. What do you see as the social benefits to making the code behind a data science finding publicly available online? What might be some of the social consequences of making this code freely available? How might we mitigate these consequences? Share your ideas on our discussions Slack channel."
  },
  {
    "objectID": "lectures/w1l1_intro.html",
    "href": "lectures/w1l1_intro.html",
    "title": "Introductions",
    "section": "",
    "text": "Course: SDS 192, Sect. 02\nTimes:\n\nM, 1:40-2:55pm\nW/F, 1:20-2:35pm"
  },
  {
    "objectID": "lectures/w1l1_intro.html#for-friday-and-beyond",
    "href": "lectures/w1l1_intro.html#for-friday-and-beyond",
    "title": "Introductions",
    "section": "For Friday and beyond",
    "text": "For Friday and beyond\n\nNavigate the course website\nRead through the syllabus\nComplete the pre-course survey and tech setup\n\nDue Friday at 11:59pm, link on website under Week 1\nJoin the Slack, Perusall, and GitHub classroom sites"
  },
  {
    "objectID": "lectures/w1l2_data.html#for-monday",
    "href": "lectures/w1l2_data.html#for-monday",
    "title": "Datasets",
    "section": "For Monday",
    "text": "For Monday\n\nWork on Tech Setup (due tonight!)\nMonday’s class: Exploring R\nReading annotations due by Tuesday at 11:59pm"
  },
  {
    "objectID": "lectures/w1l1_intro.html#happy-snow-day",
    "href": "lectures/w1l1_intro.html#happy-snow-day",
    "title": "Introductions",
    "section": "Happy Snow Day!!",
    "text": "Happy Snow Day!!"
  },
  {
    "objectID": "schedule.html#extra",
    "href": "schedule.html#extra",
    "title": "Schedule",
    "section": "Extra",
    "text": "Extra\n\n\n\n\n\n\nNoteLab #2: GitHub\n\n\n\n\nInstructions\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #2 (due Sunday, 2/8 at 11:59pm on Perusall)\nLab #2 (due Wednesday, 2/11 at 11:59pm)\n\nTemplate\n\n\n\n\n–&gt;"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#last-time",
    "href": "lectures/w3l1_visualization.html#last-time",
    "title": "Intro to Data Visualization",
    "section": "Last Time",
    "text": "Last Time\n\nMore behind R\n\nData imports\nMissing data\nOther topics\n\nWhat is a workflow?\n\nWhy?\nProcess\n\nGitHub\n\nWhat is it?\nActions"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#activity",
    "href": "lectures/w3l1_visualization.html#activity",
    "title": "Intro to Data Visualization",
    "section": "Activity",
    "text": "Activity\n\nTalk to 2-3 people around you and discuss any questions you may have about using GitHub.\nPut any questions in the anonymous Google Form here"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#today",
    "href": "lectures/w3l1_visualization.html#today",
    "title": "Intro to Data Visualization",
    "section": "Today",
    "text": "Today"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#for-today",
    "href": "lectures/w3l1_visualization.html#for-today",
    "title": "Intro to Data Visualization",
    "section": "For Today",
    "text": "For Today\n\nData visualizations\n\nIntroduction\nTaxonomy\nConventions and critiques\n5NG\nActivity"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#what-is-data-visualization",
    "href": "lectures/w3l1_visualization.html#what-is-data-visualization",
    "title": "Intro to Data Visualization",
    "section": "What is Data Visualization?",
    "text": "What is Data Visualization?\n\nThe translation of information into a graphical format\n\nInformation \\(\\rightarrow\\) graphics\n\nHelps analysts summarize and identify patterns across large datasets\nAlways involves critical judgment calls on the part of the designer"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#elements-of-data-graphics",
    "href": "lectures/w3l1_visualization.html#elements-of-data-graphics",
    "title": "Intro to Data Visualization",
    "section": "Elements of Data Graphics",
    "text": "Elements of Data Graphics\n\nAesthetics (i.e. visual cues)\nScale\nContext 1\nCoordinate systems\n\nFramework drawn from: Yau, Nathan. 2013. Data Points: Visualization That Means Something. 1st edition. Indianapolis, IN: Wiley."
  },
  {
    "objectID": "lectures/w3l1_visualization.html#visual-cues",
    "href": "lectures/w3l1_visualization.html#visual-cues",
    "title": "Intro to Data Visualization",
    "section": "Visual Cues",
    "text": "Visual Cues\n\n\n\nWhere is the data positioned on the plot?\nWhat is the length of shapes on the plot?\nHow large is the angle between vectors?\nWhich direction is the data going towards?\nWhat shapes/symbols appear on the plot?\nHow much area and volume do shapes take up on a plot?\nHow intense is the color or shade presented on the plot?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues",
    "href": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues",
    "title": "Intro to Data Visualizations",
    "section": "Which variables are mapped onto what visual cues?",
    "text": "Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-1",
    "href": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-1",
    "title": "Intro to Data Visualizations",
    "section": "Which variables are mapped onto what visual cues?",
    "text": "Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-2",
    "href": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-2",
    "title": "Intro to Data Visualizations",
    "section": "Which variables are mapped onto what visual cues?",
    "text": "Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-3",
    "href": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-3",
    "title": "Intro to Data Visualizations",
    "section": "Which variables are mapped onto what visual cues?",
    "text": "Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-4",
    "href": "lectures/w3l1_visualization.html#which-variables-are-mapped-onto-what-visual-cues-4",
    "title": "Intro to Data Visualizations",
    "section": "Which variables are mapped onto what visual cues?",
    "text": "Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#coordinate-systems",
    "href": "lectures/w3l1_visualization.html#coordinate-systems",
    "title": "Intro to Data Visualization",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\n\n\nOrganization of data points\nWe will focus primarily on a Cartesian system (i.e. rectangular coordinate system you are used to)\nOther systems: polar, geographic"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#scale",
    "href": "lectures/w3l1_visualization.html#scale",
    "title": "Intro to Data Visualization",
    "section": "Scale",
    "text": "Scale\n\n\n\n“How does distance in the data graphic translate into meaningful differences in quantity?”\nThree choices:\n\nNumeric: linear, logarithmic, or percentage\nCategorical: nominal or ordinal\nTime: by time units or wrap-around"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#examples",
    "href": "lectures/w3l1_visualization.html#examples",
    "title": "Intro to Data Visualization",
    "section": "Examples",
    "text": "Examples"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#context",
    "href": "lectures/w3l1_visualization.html#context",
    "title": "Intro to Data Visualization",
    "section": "Context",
    "text": "Context\n\nThe “why” to data visualization\nInformation to carefully highlight what needs to be highlighted\n\nTitles, subtitles, axis labels, reference points, etc."
  },
  {
    "objectID": "lectures/w3l1_visualization.html#context-in-this-class",
    "href": "lectures/w3l1_visualization.html#context-in-this-class",
    "title": "Intro to Data Visualization",
    "section": "Context in This Class",
    "text": "Context in This Class\nFive pieces of context MUST be in every plot you submit:\n\nThe data’s unit of observation\nUsing titles, axis labels\nVariables represented on the plot\nUsing axis/legend titles\nFilters applied to the data\nGeographic context of the data\nTemporal (date/time range) context of the date"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#context-in-this-class-cont.",
    "href": "lectures/w3l1_visualization.html#context-in-this-class-cont.",
    "title": "Intro to Data Visualization",
    "section": "Context in This Class (cont.)",
    "text": "Context in This Class (cont.)"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#data-visualization-conventions",
    "href": "lectures/w3l1_visualization.html#data-visualization-conventions",
    "title": "Intro to Data Visualization",
    "section": "Data Visualization Conventions",
    "text": "Data Visualization Conventions\n\nEdward Tufte, American statistician sometimes considered “father of data visualization”\nIntroduced the concept of “graphical integrity”\nHow do we present data as honestly as possible?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#lie-factor",
    "href": "lectures/w3l1_visualization.html#lie-factor",
    "title": "Intro to Data Visualization",
    "section": "Lie Factor",
    "text": "Lie Factor\n\nLie Factor = (size of effect in graphic)/(size of effect in data)\nLie factor is greater when variations on a graph fail to match variations in data\n\n\nTufte, Visual Display of Quantitative Information\n5.3-0.6 / 0.6 * 100= 783 (graph)\n27.5-18 /18 *100 = 53 (data)\n783/53 = 14.8"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#inconsistent-scales",
    "href": "lectures/w3l1_visualization.html#inconsistent-scales",
    "title": "Intro to Data Visualization",
    "section": "Inconsistent Scales",
    "text": "Inconsistent Scales\n\nExample from callingbullshit.org"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#presenting-data-out-of-context",
    "href": "lectures/w3l1_visualization.html#presenting-data-out-of-context",
    "title": "Intro to Data Visualization",
    "section": "Presenting Data Out of Context",
    "text": "Presenting Data Out of Context\n\nExample from mediamatters.org"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#disproportionate-data-to-ink-ratio",
    "href": "lectures/w3l1_visualization.html#disproportionate-data-to-ink-ratio",
    "title": "Intro to Data Visualization",
    "section": "Disproportionate Data-to-Ink Ratio",
    "text": "Disproportionate Data-to-Ink Ratio\n\nEnsure that the ink used on the data match the amount of data presented\nData-to-ink ratio = (ink used to represent data)/(ink used to print graphic)\nShould be as close as possible to 1\nAnother way to think about it: How much of this graph could I erase without losing data?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#disproportionate-data-to-ink-ratio-1",
    "href": "lectures/w3l1_visualization.html#disproportionate-data-to-ink-ratio-1",
    "title": "Intro to Data Visualization",
    "section": "Disproportionate Data-to-Ink Ratio",
    "text": "Disproportionate Data-to-Ink Ratio"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#deviating-from-norms",
    "href": "lectures/w3l1_visualization.html#deviating-from-norms",
    "title": "Intro to Data Visualization",
    "section": "Deviating from Norms",
    "text": "Deviating from Norms\n\nExample from callingbullshit.org"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#when-can-i-break-convention",
    "href": "lectures/w3l1_visualization.html#when-can-i-break-convention",
    "title": "Intro to Data Visualization",
    "section": "When Can I Break Convention??",
    "text": "When Can I Break Convention??"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#types-of-graphs",
    "href": "lectures/w3l1_visualization.html#types-of-graphs",
    "title": "Intro to Data Visualization",
    "section": "Types of Graphs",
    "text": "Types of Graphs\n\nThe 5NGs\n\n\nLine GraphsHistogramsBar PlotsBox PlotsScatter Plots"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#for-now-and-wednesday",
    "href": "lectures/w3l1_visualization.html#for-now-and-wednesday",
    "title": "Intro to Data Visualization",
    "section": "For Now and Wednesday",
    "text": "For Now and Wednesday\n\nFinish activity for today’s class\nLab #1 due on Wednesday at 11:59pm"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#information-rightarrow-graphics",
    "href": "lectures/w3l1_visualization.html#information-rightarrow-graphics",
    "title": "Intro to Data Visualization",
    "section": "Information \\(\\rightarrow\\) Graphics",
    "text": "Information \\(\\rightarrow\\) Graphics\n  &gt; Source: Silver Bulletin\nQuestion: What information is displayed in these maps? How is it being displayed?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#example",
    "href": "lectures/w3l1_visualization.html#example",
    "title": "Intro to Data Visualization",
    "section": "Example",
    "text": "Example\nQuestion: Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#example-1",
    "href": "lectures/w3l1_visualization.html#example-1",
    "title": "Intro to Data Visualization",
    "section": "Example",
    "text": "Example\nQuestion: Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#example-2",
    "href": "lectures/w3l1_visualization.html#example-2",
    "title": "Intro to Data Visualization",
    "section": "Example",
    "text": "Example\nQuestion: Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#example-3",
    "href": "lectures/w3l1_visualization.html#example-3",
    "title": "Intro to Data Visualization",
    "section": "Example",
    "text": "Example\nQuestion: Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#example-4",
    "href": "lectures/w3l1_visualization.html#example-4",
    "title": "Intro to Data Visualization",
    "section": "Example",
    "text": "Example\nQuestion: Which variables are mapped onto what visual cues?"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#activity-1",
    "href": "lectures/w3l1_visualization.html#activity-1",
    "title": "Intro to Data Visualization",
    "section": "Activity",
    "text": "Activity\n\nSeen in schedule\n\nOr here\nSubmit in Slack"
  },
  {
    "objectID": "lectures/w3l1_act.html",
    "href": "lectures/w3l1_act.html",
    "title": "Week 3, Lecture 1: Data Visualizations",
    "section": "",
    "text": "Today, you will be working in groups of 3-4 to examine and critique a data visualization. You will post the graphic and your analysis on Slack under #discussions.\n\nSelect a data visualization from one of the following resources below:\n\n\nNYT Graphics\nUSA Today Graphics\n538 Graphics\n\nOnce you find a data visualization, drop the link to the visualization in the discussions channel on Slack.\n\nIdentify the visual cues in the visualization, along with the scale. Note that visual cues are used to represent variations in the data, while scale refers to how the visual cues are differentiated.\n\nVisual cues include: position, length, angle, shape, size, color\nScales include: numeric, logarithmic, categorical, ordinal, percentage, date-time\n\nIdentify and summarize the context provided on the visualization. Are all five components of context represented?\n\nContext components include: units of observation, variables, filter, geographic context, temporal context.\n\nAre there any issues or concerns with the graphical integrity of the visualization? Discuss what these issues are and if they serve a purpose/narrative."
  },
  {
    "objectID": "lectures/w3l1_visualization.html",
    "href": "lectures/w3l1_visualization.html",
    "title": "Intro to Data Visualizations",
    "section": "",
    "text": "More behind R\n\nData imports\nMissing data\nOther topics\n\nWhat is a workflow?\n\nWhy?\nProcess\n\nGitHub\n\nWhat is it?\nActions"
  },
  {
    "objectID": "lectures/w3l1_visualization.html#footnotes",
    "href": "lectures/w3l1_visualization.html#footnotes",
    "title": "Intro to Data Visualizations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFramework drawn from: Yau, Nathan. 2013. Data Points: Visualization That Means Something. 1st edition. Indianapolis, IN: Wiley.↩︎"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#last-time",
    "href": "lectures/w3l2_ggplot.html#last-time",
    "title": "The Amazing World of ggplot2",
    "section": "Last Time",
    "text": "Last Time\n\nData visualizations\n\nIntroduction\nTaxonomy\nConventions and critiques\n5NG\nActivity"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#for-today",
    "href": "lectures/w3l2_ggplot.html#for-today",
    "title": "The Amazing World of ggplot2",
    "section": "For Today",
    "text": "For Today\n\nVisualizations (a review)\nggplot\n\nWhat it is and why?\nLayering\nSyntax\nAesthetics, scaling, and context\nActivity\n\nbase R (given time)\n\nSyntax"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#the-amazing-world-of-ggplot",
    "href": "lectures/w3l2_ggplot.html#the-amazing-world-of-ggplot",
    "title": "The Amazing World of ggplot2",
    "section": "The Amazing World of ggplot",
    "text": "The Amazing World of ggplot\n\nSystem/package for creating graphics\n\nBased on The Grammar of Graphics\nLayers! Lots of them\nUsed by statisticians and data scientists\n\nPart of tidyverse\n\nUse library(ggplot2) to access in environment"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#ggplot-vs.-base-r",
    "href": "lectures/w3l2_ggplot.html#ggplot-vs.-base-r",
    "title": "The Amazing World of ggplot2",
    "section": "ggplot vs. Base R",
    "text": "ggplot vs. Base R"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#ggplot",
    "href": "lectures/w3l2_ggplot.html#ggplot",
    "title": "The Amazing World of ggplot2",
    "section": "ggplot",
    "text": "ggplot\n\nWe will generate plots using ggplot\ndata \\(\\rightarrow\\) mapping \\(\\rightarrow\\) layers\n\nStart with data, specify its mapping to visual cues, layer with information"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#ggplot-1",
    "href": "lectures/w3l2_ggplot.html#ggplot-1",
    "title": "The Amazing World of ggplot2",
    "section": "ggplot",
    "text": "ggplot\n\n\nVisuals are built upon each other using + operator"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#motivating-dataset",
    "href": "lectures/w3l2_ggplot.html#motivating-dataset",
    "title": "The Amazing World of ggplot2",
    "section": "Motivating Dataset",
    "text": "Motivating Dataset\n\nThis dataset comes from Pioneer Valley Data and documents estimates of population characteristics for each municipality in the Pioneer Valley.\n\n\nlibrary(ggplot2)\nlibrary(tidyverse)\npioneer_valley_census_data &lt;- read.csv(\"https://raw.githubusercontent.com/SDS-192-Intro/SDS-192-public-website/main/slides/datasets/pioneer_valley_census.csv\")\nhampshire_census_data &lt;- pioneer_valley_census_data %&gt;% \n  filter(COUNTY == \"Hampshire\")"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#parts-i-and-ii-data-and-mapping",
    "href": "lectures/w3l2_ggplot.html#parts-i-and-ii-data-and-mapping",
    "title": "The Amazing World of ggplot2",
    "section": "Parts I and II: Data and Mapping",
    "text": "Parts I and II: Data and Mapping\n\nWe start with data and mapping through the ggplot() function\n\nTwo required arguments:\n\ndata: data frame or tibble used to produce plot\nmapping: variables from data set associated with various aesthetics\n\nMappings defined within aes() function\nSpecify x and y here for Cartesian plots"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#example-hampshire-county-data-data-mapping",
    "href": "lectures/w3l2_ggplot.html#example-hampshire-county-data-data-mapping",
    "title": "The Amazing World of ggplot2",
    "section": "Example: Hampshire County Data (Data & Mapping)",
    "text": "Example: Hampshire County Data (Data & Mapping)\n\nggplot(data = hampshire_census_data,\n       aes(x = COMMUNITY, y = CEN_EARLYED))"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#learning-checks",
    "href": "lectures/w3l2_ggplot.html#learning-checks",
    "title": "The Amazing World of ggplot2",
    "section": "Learning Checks",
    "text": "Learning Checks\n\nWhat’s the scale of the x-axis in the plot you just created?\nWhat’s the scale of the y-axis?\nWhat else is needed in the plot?"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#part-iii-wheres-the-data-we-need-layers",
    "href": "lectures/w3l2_ggplot.html#part-iii-wheres-the-data-we-need-layers",
    "title": "The Amazing World of ggplot2",
    "section": "Part III: Where’s the Data? We Need Layers!",
    "text": "Part III: Where’s the Data? We Need Layers!\n\nIn the previous plot, we told R what variables to plot, but we didn’t indicate how to plot them.\nWe need to stack layers on top of the data and mapping\n\nLayer defines geometry, statistical transformation and position adjustment\nDone via a geom function to be added (i.e. +) to our ggplot call"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#layers-geom-function-with-the-5ngs",
    "href": "lectures/w3l2_ggplot.html#layers-geom-function-with-the-5ngs",
    "title": "The Amazing World of ggplot2",
    "section": "Layers: geom Function with the 5NGs",
    "text": "Layers: geom Function with the 5NGs\n\nLine graphs: geom_line()\nHistograms: geom_histogram()\nBar plots: geom_bar(), geom_col\nBox plots: geom_boxplot()\nScatter plots: geom_point()"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#example-hampshire-county-data-data-mapping-layering",
    "href": "lectures/w3l2_ggplot.html#example-hampshire-county-data-data-mapping-layering",
    "title": "The Amazing World of ggplot2",
    "section": "Example: Hampshire County Data (Data, Mapping, & Layering)",
    "text": "Example: Hampshire County Data (Data, Mapping, & Layering)\n\n# data, mapping, and layer\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, y = CEN_EARLYED)) +\n  geom_col() # adds bar plot layering"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#learning-check",
    "href": "lectures/w3l2_ggplot.html#learning-check",
    "title": "The Amazing World of ggplot2",
    "section": "Learning Check",
    "text": "Learning Check\n\nWhat variables are mapped on to what visual cues in this plot?\nWhat else can be improved/done with this plot?"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#part-iv-scales",
    "href": "lectures/w3l2_ggplot.html#part-iv-scales",
    "title": "The Amazing World of ggplot2",
    "section": "Part IV: Scales",
    "text": "Part IV: Scales\n\nScales are important for translating meaningful differences in data\nFunctions are written as scale_{aesthetic}_{type}()\n\nTerms of colors, intervals, etc."
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#example-hampshire-county-data-with-scaling",
    "href": "lectures/w3l2_ggplot.html#example-hampshire-county-data-with-scaling",
    "title": "The Amazing World of ggplot2",
    "section": "Example: Hampshire County Data (with Scaling)",
    "text": "Example: Hampshire County Data (with Scaling)\n\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, y = CEN_EARLYED, fill = CEN_POVRATE)) +\n  geom_col() +\n  scale_fill_gradient(low = \"gray\", high = \"blue\") # adds scaling based on fill"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#part-v-facets",
    "href": "lectures/w3l2_ggplot.html#part-v-facets",
    "title": "The Amazing World of ggplot2",
    "section": "Part V: Facets",
    "text": "Part V: Facets\n\nUsed to break data into different data sets, producing a grid of plots\nUseful for comparing difference between groups, works well for scatter plots\nfacet_grid()"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#example-pioneer-valley-data-with-facetting",
    "href": "lectures/w3l2_ggplot.html#example-pioneer-valley-data-with-facetting",
    "title": "The Amazing World of ggplot2",
    "section": "Example: Pioneer Valley Data (with Facetting)",
    "text": "Example: Pioneer Valley Data (with Facetting)\n\nggplot(data = pioneer_valley_census_data, \n       aes(x = COMMUNITY, \n           y = CEN_EARLYED, fill = CEN_POVRATE)) + \n  geom_col() +\n  scale_fill_gradient(low = \"gray\", high = \"blue\") +\n  facet_grid(COUNTY ~ 1) # divides bar plot into 3 different counties"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#part-vi-coordinates",
    "href": "lectures/w3l2_ggplot.html#part-vi-coordinates",
    "title": "The Amazing World of ggplot2",
    "section": "Part VI: Coordinates",
    "text": "Part VI: Coordinates\n\nThe standard coordinate system is Cartesian\n\nMay want to change at times\n\nMore concerned about orientation\n\ncoord_flip()"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#example-hampshire-county-data-with-coordinate-flipping",
    "href": "lectures/w3l2_ggplot.html#example-hampshire-county-data-with-coordinate-flipping",
    "title": "The Amazing World of ggplot2",
    "section": "Example: Hampshire County Data (with Coordinate Flipping)",
    "text": "Example: Hampshire County Data (with Coordinate Flipping)\n\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, \n           y = CEN_EARLYED, fill = CEN_POVRATE)) + \n  geom_col() +\n  scale_fill_gradient(low = \"gray\", high = \"blue\") +\n  coord_flip() # flips coordinate system"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#part-vii-theme",
    "href": "lectures/w3l2_ggplot.html#part-vii-theme",
    "title": "The Amazing World of ggplot2",
    "section": "Part VII: Theme",
    "text": "Part VII: Theme\n\nWe may want to change the basic visuals not controlled by the data\ntheme_*(), element_*() functions with theme()\nMost common use (even ChatGPT will use it): theme_minimal()"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#example-hampshire-county-data-with-theme-change",
    "href": "lectures/w3l2_ggplot.html#example-hampshire-county-data-with-theme-change",
    "title": "The Amazing World of ggplot2",
    "section": "Example: Hampshire County Data (with Theme Change)",
    "text": "Example: Hampshire County Data (with Theme Change)\n\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, \n           y = CEN_EARLYED, fill = CEN_POVRATE)) + \n  geom_col() +\n  scale_fill_gradient(low = \"gray\", high = \"blue\") +\n  coord_flip() +\n  theme_minimal() # adds minimal theme"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#other-components-labels-and-titles",
    "href": "lectures/w3l2_ggplot.html#other-components-labels-and-titles",
    "title": "The Amazing World of ggplot2",
    "section": "Other Components: Labels and Titles",
    "text": "Other Components: Labels and Titles\n\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, \n           y = CEN_EARLYED, fill = CEN_POVRATE)) + \n  geom_col() +\n  scale_fill_gradient(low = \"gray\", high = \"blue\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Hampshire County Early Education Enrollment Rates, 2018\",\n       fill = \"Poverty Rate\") +\n  xlab(\"Enrollment Rate for 3-4 yr old\") +\n  ylab(\"Municipality in Hampshire County, MA\")"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#aeshetics-vs.-attributes",
    "href": "lectures/w3l2_ggplot.html#aeshetics-vs.-attributes",
    "title": "The Amazing World of ggplot2",
    "section": "Aeshetics vs. Attributes",
    "text": "Aeshetics vs. Attributes\n\nWe can adjust the way the data appears on plots in two ways:\n\nAccording to a variable:\n\nThis must be done inside of the aes() function\n\nIn a fixed way:\n\nThis must be done outside of the aes() function"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#other-components-aesthetics",
    "href": "lectures/w3l2_ggplot.html#other-components-aesthetics",
    "title": "The Amazing World of ggplot2",
    "section": "Other Components: Aesthetics",
    "text": "Other Components: Aesthetics\n\nWe add visual cues to the plot in the aes() call\n\n\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, \n           y = CEN_EARLYED, fill = CEN_POVRATE)) + # fill here as example\n  geom_col() +\n  scale_fill_gradient(low = \"gray\", high = \"blue\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Hampshire County Early Education Enrollment Rates, 2018\",\n       fill = \"Poverty Rate\") +\n  xlab(\"Enrollment Rate for 3-4 yr old\") +\n  ylab(\"Municipality in Hampshire County, MA\")"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#other-components-attributes",
    "href": "lectures/w3l2_ggplot.html#other-components-attributes",
    "title": "The Amazing World of ggplot2",
    "section": "Other Components: Attributes",
    "text": "Other Components: Attributes\n\nggplot(data = hampshire_census_data, \n       aes(x = COMMUNITY, \n           y = CEN_EARLYED, fill = CEN_POVRATE)) + \n  geom_col(width = 0.98) + # changed sizing of columns\n  scale_fill_gradient(low = \"gray\", high = \"blue\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Hampshire County Early Education Enrollment Rates, 2018\",\n       fill = \"Poverty Rate\") +\n  xlab(\"Enrollment Rate for 3-4 yr old\") +\n  ylab(\"Municipality in Hampshire County, MA\")"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#endless-possibilities",
    "href": "lectures/w3l2_ggplot.html#endless-possibilities",
    "title": "The Amazing World of ggplot2",
    "section": "Endless Possibilities",
    "text": "Endless Possibilities\n\nYou, probably: “Do I really have to memorize all of these stylistic functions?!”\n\nAnswer: No\n\nResources:\n\nCheatsheet: ggplot2() cheatsheet\nHelp tab documentation\nGoogle (and yes, generative AI)"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#generative-ai",
    "href": "lectures/w3l2_ggplot.html#generative-ai",
    "title": "The Amazing World of ggplot2",
    "section": "Generative AI",
    "text": "Generative AI\n\n\n\n\n\n\nBest Practices of genAI Usage\n\n\n\nPrompt with a specific item that can add something to plot\n\ne.g. what function is used to change the color scaling of a variable that is continuous in ggplot2?\n\nDo not ask the model to plot the whole thing for you\n\nCan result in many small errors (which can cause all your code to run into errors)\n\nFor the assignments and activities: use it sparingly (only use to find new functions/arguments) and cite usage when needed"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#activity",
    "href": "lectures/w3l2_ggplot.html#activity",
    "title": "The Amazing World of ggplot2",
    "section": "Activity",
    "text": "Activity\n\nSeen on schedule\n\nOr here"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#for-now-and-monday",
    "href": "lectures/w3l2_ggplot.html#for-now-and-monday",
    "title": "Types of Data Visualizations",
    "section": "For Now and Monday",
    "text": "For Now and Monday\n\nFinish activity for today’s class\nLab #1 due tonight at 11:59pm\nReading Exercise #2 due Thursday at 11:59pm\n\nSeen on schedule"
  },
  {
    "objectID": "lectures/w3l2_ggplot.html#for-now-and-friday",
    "href": "lectures/w3l2_ggplot.html#for-now-and-friday",
    "title": "The Amazing World of ggplot2",
    "section": "For Now and Friday",
    "text": "For Now and Friday\n\nFinish activity for today’s class\nLab #1 due tonight at 11:59pm\nReading Exercise #2 due Thursday at 11:59pm\n\nSeen on schedule"
  },
  {
    "objectID": "lectures/w3l2_act.html",
    "href": "lectures/w3l2_act.html",
    "title": "Week 3, Lecture 2: ggplot2",
    "section": "",
    "text": "In this activity, you will generate and replicate several plots based on the California Housing dataset, which analyzes housing information from the 1990 U.S. census. More information can be found here: link\nMake sure to create a .qmd file in your Activities repository first.\nTo import the dataset into your machine, do the following:\n\nImport the ‘housing.csv’ file using the following URL and code:\n\n\nhttps://jericholawson.github.io/classes/sds192/data/housing.csv\n\n\nlibrary(ggplot2)\nhousing &lt;- read.csv(\"https://jericholawson.github.io/classes/sds192/data/housing.csv\")"
  },
  {
    "objectID": "lectures/w3l2_act.html#introduction",
    "href": "lectures/w3l2_act.html#introduction",
    "title": "Week 3, Lecture 2: ggplot2",
    "section": "",
    "text": "In this activity, you will generate and replicate several plots based on the California Housing dataset, which analyzes housing information from the 1990 U.S. census. More information can be found here: link\nMake sure to create a .qmd file in your Activities repository first.\nTo import the dataset into your machine, do the following:\n\nImport the ‘housing.csv’ file using the following URL and code:\n\n\nhttps://jericholawson.github.io/classes/sds192/data/housing.csv\n\n\nlibrary(ggplot2)\nhousing &lt;- read.csv(\"https://jericholawson.github.io/classes/sds192/data/housing.csv\")"
  },
  {
    "objectID": "lectures/w3l2_act.html#questions",
    "href": "lectures/w3l2_act.html#questions",
    "title": "Week 3, Lecture 2: ggplot2",
    "section": "Questions",
    "text": "Questions\n\nIdentify the number of observations and variables in this dataset.\nDetermine which variables are numerical and categorical.\nRecreate the following plot you see below using the housing dataset and ggplot2.\n\n\n\n# RECREATE PLOT HERE\n\n\nUsing code from the last problem, add to your code such that you are able to generate the following image:\n\n\n\n# RECREATE PLOT HERE\n\nHint: Once you find the correct scale function, please look through the help file and find a diverging palette that matches the above chart.\n\nQuestion for Reflection: Note how in this plot, the x and y axis don’t start at 0. Why might it be ok here vs. in other kinds of plots?\n\n\nRecreate the following plot you see below using the housing dataset and ggplot2.\n\n\n\nCreate one of the following plots below based on some combination of variables OCEAN_PROXIMITY, median_income, and housing_median_age. Make sure to have an appropriate title, axis labels, and appropriate scaling. Consider what each point represents in the data."
  },
  {
    "objectID": "schedule.html#week-4-data-visualizations-with-ggplot-216---220",
    "href": "schedule.html#week-4-data-visualizations-with-ggplot-216---220",
    "title": "Schedule",
    "section": "Week 4: Data Visualizations with ggplot (2/16 - 2/20)",
    "text": "Week 4: Data Visualizations with ggplot (2/16 - 2/20)\n\nMonday, 2/16Wednesday, 2/18Friday, 2/20\n\n\n\n\n\n\n\n\nNoteLecture: Frequency Plots\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Box and Scatter Plots\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLab #3: Visualization Aesthetics\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due"
  },
  {
    "objectID": "schedule-abc.html",
    "href": "schedule-abc.html",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28Friday, 1/30\n\n\n\n\n\n\n\n\nNoteLecture: CANCELLED\n\n\n\nStay warm and enjoy the snow!\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Introductions\n\n\n\n\nSlides + Activity\nNote: Office hours will be held from 3-4pm today in McConnell 207. Feel free to stop by!\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Intro to Data\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\nReadings #1 (due Tuesday, 2/1 on Perusall at 11:59pm)"
  },
  {
    "objectID": "schedule-abc.html#week-1-what-is-data-science-126---130",
    "href": "schedule-abc.html#week-1-what-is-data-science-126---130",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28Friday, 1/30\n\n\n\n\n\n\n\n\nNoteLecture: CANCELLED\n\n\n\nStay warm and enjoy the snow!\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Introductions\n\n\n\n\nSlides + Activity\nNote: Office hours will be held from 3-4pm today in McConnell 207. Feel free to stop by!\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Intro to Data\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Friday, 1/30 at 11:59pm)\nTech Setup (due Friday, 1/30 at 11:59pm)\nReadings #1 (due Tuesday, 2/1 on Perusall at 11:59pm)"
  },
  {
    "objectID": "projects/proj1inst.html",
    "href": "projects/proj1inst.html",
    "title": "Project #1 (150 pts)",
    "section": "",
    "text": "WarningWarning\n\n\n\nUpdates to this document are indicated in red."
  },
  {
    "objectID": "projects/proj1inst.html#background",
    "href": "projects/proj1inst.html#background",
    "title": "Project #1 (150 pts)",
    "section": "Background",
    "text": "Background\nIn this project, you will be analyzing a particular dataset and developing meaningful and clear visualizations that detail various trends and patterns within the data that inform the audience about particular issues. This will be framed within a workflow, in which you will import the data, write code to analyze and create plots, and format your files so that they are reproducible. By the end of this project, you will be able to:\n\nNavigate different forms of data documentation.\nRecognize differences in variable types and how they get assigned to certain R objects.\nExamine trends and patterns within the data through exploratory plotting in R.\nCreate clear and informative plots that highlight particular patterns in the data.\nSummarize findings and ethical issues within data and its resources through a short video and report.\n\nThe project will contain the following parts:\n\nProject Proposal (5 pts; due Friday, 2/20 at 11:59pm) \nVideo Summary (25 pts; due Friday, 3/6 at 11:59pm)\nProject Repository (120 pts; due Friday, 3/6 at 11:59pm)"
  },
  {
    "objectID": "projects/proj1inst.html#working-time",
    "href": "projects/proj1inst.html#working-time",
    "title": "Project #1 (150 pts)",
    "section": "Working Time",
    "text": "Working Time\nParts of 2-3 lectures will be dedicated to working on the project. Aside from these times, you will be tasked with working on this project outside of class.\nAs questions/concerns arise during the project, ask your instructor for assistance and guidance. There will be some hints and pointers that can be given to assist you through the project."
  },
  {
    "objectID": "projects/proj1inst.html#instructions",
    "href": "projects/proj1inst.html#instructions",
    "title": "Project #1 (150 pts)",
    "section": "Instructions",
    "text": "Instructions\n\nChoose a dataset. You will choose one of the following datasets to base your project on. The datasets are the following:\n\nMental Health Care in the Last 4 Weeks\nChicago Microlending Institute (CMI) Microloans\nMTA Daily Ridership Data: 2020 - 2025\nEmergency Department Volume and Capacity\n\nCreate a repository on GitHub. You will need to go to your GitHub profile. On your profile, you will create a new repository by clicking “New” at the top-right hand corner of the screen.\n From there, you will put in the following specifications for your new repository:\n\nThen, create the repository.\nCreate new project in RStudio. You will now create a new project in RStudio based around your new repository. To do so, go to File \\(\\rightarrow\\) New Project \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Git. Copy the new repository URL and paste it into the first field. Name your project “project1” and place the new repository into a new folder on your laptop. Then, click “Create Project”.\nImport data into R. You will need to download the .csv file from the data link above and import the data into R. Additionally, some of the datasets may contain missing observations, which will need to be omitted before you continue this project (depending on which variables you are looking at). More on this later. You will find the following pieces of code to be helpful:\n\nread.csv(filepath/name, header = TRUE)\nna.omit(object)\n\nYou will need to place the .csv file you are referencing into a “data” folder in your project folder. Any references to your .csv file from code should have a file path of “data/yourData.csv”.\nGet to know the data set. This will involve a combination of looking at the metadata and a snippet of the data itself. Consider the following questions as you examine the data:\n\nWho is the creator/maintainer of the data?\nWhat do the observations represent? How many variables are there?\nHow many observations and variables are in the data set?\nWhat are the variables in there? What are the possible values in each variable?\nIdentify the response or variable of interest in this data set.\n\nThis should be numerical.\n\nAre there missing values in the data set? If so, how many and is there a reason why this is the case?\n\nIf it appears to be random, you can omit the missing observations. If not, you will need to subset your data.\n\n\nDetermine which variables to analyze. You will need to identify the main (continuous) variable of interest in your dataset. Once you do so, pick five more variables you want to analyze alongside the variable of interest. For these five variables, you must follow these rules:\n\nAt least one variable must be categorical\nAt least one variable must be continuous\n\nNote that you may need to discretize a variable or two, which involves making a new variable based on other variables.\nPrepare the data set for analysis. Some data wrangling may need to be done, particularly if you are looking at certain subsets of the data or missing data exists. Your code should properly subset the data so that you are able to complete the data visualizations.\nCreate the data visualizations. You will need to create four visualizations, which should (1) facilitate a discussion of the variable of interest based on its own distribution/subset or when compared to other variables and (2) be concise, informative, and adhere to the principles of data visualization. For grading purposes, you should adhere to the following:\n\nAt least three types of graphs need to be represented by your visualizations (e.g. bar, scatter, histogram, boxplot)\nThe main variable of interest should be represented in some capacity in at least two plots. The other variables just need to be used at least once.\nEach plot should adhere to the five principles of context (see Lecture #4 for details)\nEach aesthetic or stylistic choice should add to the interpretability of the plot.\n\nAnalyze each of the visualizations. For each of the plots, you will consider the following questions:\n\nWhat can be said about the data? Trends? Patterns? Characteristics?\nWhat does this say about the situation at hand? How does this further your understanding of the topic?\n\nYou will also consider the pitfalls of your analysis and data as a whole. This will include exposing potential biases, exclusions, and data collection procedures."
  },
  {
    "objectID": "projects/proj1inst.html#components",
    "href": "projects/proj1inst.html#components",
    "title": "Project #1 (150 pts)",
    "section": "Components",
    "text": "Components\n\nProject Proposal (5 pts; due Friday, 2/20 at 11:59pm via GitHub)\nFor this component, you will do two tasks:\n\nShare your repository to me on GitHub. To do so, go to your repository, then go to Settings -&gt; Collaborators. Click “Add People” and put in my username (@jericholawson).\nCreate a .qmd file named proposal.qmd that answers the following in 3-4 sentences:\n\nWhich dataset will you use?\nWhat question are you trying to answer with this project?\nWhich variables do you want to explore?\n\n\nThese tasks must be done by the due date mentioned above. A project late day cannot be used here.\n\n\nRecording (25 pts; due Friday, 3/6 at 11:59pm via email)\nThe recording will consist of you walking through each of your four data visualizations. In this 2-4 minute recording, you will talk briefly about the dataset, present the visualizations, and summarize what you found.\nThe best (and preferable) way to creating this recording will be to record yourself in a Zoom meeting while sharing a slide deck of your plots and brief bullet points. Once you’ve created the recording, you can choose to turn in the following via email to me:\n\nA unlisted YouTube link\nA .mp4 recording straight from Zoom\n\nThe slides/visuals you present should be almost exclusively the plots you’ve generated. If you do have some prose on your slides, it should be at most one bullet point for a slide if accompanied with a visual and three bullet points other wise.\nYou will be graded based on the proficiency of the following criteria:\n\n(5 pts) Delivery: points are talked about clearly; done within 2-4 minutes\n(5 pts) Organization: slides are reduced to visualizations and minimal bullet-points; easy for the audience to interpret\n(15 pts) Content: recording goes through the following:\n\nContext, with a brief introduction into the data set and problem\nVisualizations, with succinct and correct interpretations\nAnalysis, with proper mention of stakeholders and impact\n\n\nSubmit the recording to me via email by Friday, 3/6 at 11:59pm.\nThis task must be done by the due date mentioned above. In conjunction with the repository, a project late day may be used here if needed.\n\n\nProject Repository (120 pts; due Friday, 3/6 at 11:59pm via GitHub)\nThe project repository will contain all of the work completed. This includes all code, the dataset, a README.md file, and a 2-4 page report of all work (in a report.md file). As such, the final version of your repository will have the following elements:\n\ndata folder\n\nThe .csv file of the data set you chose\nThe .csv file of the revised data set you used\n\nR folder\n\nAt least one .qmd file that includes all code used to complete the data cleaning and visualizations\n\nplots folder\n\nPlace all generated plots here.\n\nREADME.md file\nReport file\nProposal file\n\nA detailed account of what goes in each of the parts and how it should look is seen next.\n\n1. Data Folder (5 pts)\nYou will have a folder named ``data” that contains (1) the .csv file of the dataset you initially chose and (2) the .csv file of the dataset that contains relevant observations and variables you chose.\nThe updated data set should contain no missing observations and have only the variables you analyzed.\n\n\n2. R Folder (5 pts)\nYou will have a folder named “R” that contains all code necessary to run through data cleaning and visualization. At a minimum, you just need one .qmd file in here, meaning that all code can be placed into a single file. However, if you feel the need to divide your code up, you can do so here. Your code files should be named accordingly.\nR code needs to be organized properly, have proper variable names, and contain clean and simplified code. To this regard, any written code should be the product of your own and not through any use of generative AI. Penalties from the syllabus will apply here.\n\n\n3. README File (5 pts)\nIn many repositories, the role of the README file is to provide the viewer a basic summary of what the repository is for and how it is structured. You can find more details about what a README file entails at the following link.\nIn your README file, you will need a name, a one-paragraph description, an author, and an overview of the structure. This can be done in a .md file (seen in RStudio), where # creates headers in the file.\n\n\n4. Plots (40 pts)\nIn the plots folder, you will place all four generated visualizations here. Keep the file names to the plots simple, such as naming them plot1.png.\nFor each plot, you will be graded on the following:\n\n(5 pts) Appropriate variables plotted; adheres to basic principles in guideline #8\n(5 pts) Context is provided in clear and concise manner; adhers to basic principles in guideline #8\n\n\n\n5. Report (65 pts)\nThis report will contain all of the analysis and discussion related to the question you are trying to answer with the dataset.\nFormatting-wise, your report should:\n\n(3 pts) Contain 2-4 pages (with no title, abstract, or table of contents required)\n(2 pts) Be organized into multiple, sensible sections\n\nThe report should have the following:\n\n(10 pts) Introduction\n\nAn introduction into the chosen dataset, including the dimensions, variables, and information of the dataset; adhering to questions mentioned in guideline #5.\nThe question you’re trying to answer.\n\n(10 pts each) Analysis (of each plot)\n\nShould include your analysis of the plot, adhering to guideline #9.\n\n(10 pts) Conclusion\n\nSummarize your findings, examine pitfalls in data and process.\n\n\nYou will need to share this repository to me (@jericholawson) on GitHub. This task must be done by the due date mentioned above. In conjunction with the recording, a project late day may be used here if needed.\n\n\n6. Proposal (0 pts)\nThis is the same proposal you created initally."
  },
  {
    "objectID": "projects/proj1inst.html#tips",
    "href": "projects/proj1inst.html#tips",
    "title": "Project #1 (150 pts)",
    "section": "Tips",
    "text": "Tips\n\nStart early and plan accordingly. This will make it easier to space out the workload, especially since we’re in the middle of the semester.\nTalk to Jericho about pointers or concerns. Feel free to email me or come to office hours regarding some recommendations on your project."
  },
  {
    "objectID": "lectures/w1l2_data.html#from-survey-2",
    "href": "lectures/w1l2_data.html#from-survey-2",
    "title": "Datasets",
    "section": "From Survey",
    "text": "From Survey\n\nIs this course an overview of the SDS major?\n\nYes, for data science\nNo, for stats & data science\n\nSimilarity to SDS 100 labs?\n\nMore involved; real-world applications\n\nPerusall readings?\n\nHere!"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset-cont.-1",
    "href": "lectures/w1l2_data.html#what-is-a-dataset-cont.-1",
    "title": "Datasets",
    "section": "What is a dataset? (cont.)",
    "text": "What is a dataset? (cont.)\n\nGrolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "lectures/w1l2_data.html#collecting-and-organizing-data-cont.",
    "href": "lectures/w1l2_data.html#collecting-and-organizing-data-cont.",
    "title": "Datasets",
    "section": "Collecting and Organizing Data (cont.)",
    "text": "Collecting and Organizing Data (cont.)\n\nDetermine a sample, observation units, and variables to gather\nIn most cases: can be formed into a rectangular format\n\nRows represent the observations\nColumns represent the variables"
  },
  {
    "objectID": "lectures/w1l2_data.html#lets-explore",
    "href": "lectures/w1l2_data.html#lets-explore",
    "title": "Datasets",
    "section": "Let’s Explore!",
    "text": "Let’s Explore!\n\nNYC Open Data on Community Food Banks"
  },
  {
    "objectID": "lectures/w2l1_introR.html#objects-and-their-actions",
    "href": "lectures/w2l1_introR.html#objects-and-their-actions",
    "title": "R Fundamentals",
    "section": "Objects and their Actions",
    "text": "Objects and their Actions\n\nInformation is stored in various data structures\n\ne.g. value, data frame, list\nmtcars\n\nCan write functions to perform actions on these data structures\n\ne.g. calculations, printing/storing information\nselect()\n\n\n\nmtcars |&gt; select(mpg, hp)\n\n                     mpg  hp\nMazda RX4           21.0 110\nMazda RX4 Wag       21.0 110\nDatsun 710          22.8  93\nHornet 4 Drive      21.4 110\nHornet Sportabout   18.7 175\nValiant             18.1 105\nDuster 360          14.3 245\nMerc 240D           24.4  62\nMerc 230            22.8  95\nMerc 280            19.2 123\nMerc 280C           17.8 123\nMerc 450SE          16.4 180\nMerc 450SL          17.3 180\nMerc 450SLC         15.2 180\nCadillac Fleetwood  10.4 205\nLincoln Continental 10.4 215\nChrysler Imperial   14.7 230\nFiat 128            32.4  66\nHonda Civic         30.4  52\nToyota Corolla      33.9  65\nToyota Corona       21.5  97\nDodge Challenger    15.5 150\nAMC Javelin         15.2 150\nCamaro Z28          13.3 245\nPontiac Firebird    19.2 175\nFiat X1-9           27.3  66\nPorsche 914-2       26.0  91\nLotus Europa        30.4 113\nFord Pantera L      15.8 264\nFerrari Dino        19.7 175\nMaserati Bora       15.0 335\nVolvo 142E          21.4 109"
  },
  {
    "objectID": "lectures/w4l1_freq.html#last-time",
    "href": "lectures/w4l1_freq.html#last-time",
    "title": "Frequency Plots",
    "section": "Last Time",
    "text": "Last Time\n\nVisualizations (a review)\nggplot\n\nWhat it is and why?\nLayering\nSyntax\nAesthetics, scaling, and context\nActivity\n\nbase R (given time)\n\nSyntax"
  },
  {
    "objectID": "lectures/w4l1_freq.html#for-today",
    "href": "lectures/w4l1_freq.html#for-today",
    "title": "Frequency Plots",
    "section": "For Today",
    "text": "For Today\n\nFrequency plots\n\nHistograms\nBar plots\nMultivariate frequencies"
  },
  {
    "objectID": "lectures/w4l1_freq.html#frequency-plots",
    "href": "lectures/w4l1_freq.html#frequency-plots",
    "title": "Frequency Plots",
    "section": "Frequency Plots",
    "text": "Frequency Plots\n\nInvolve counting the values in a variable\n\nHistograms (geom_histogram())\nBar plots: (geom_bar(), geom_col)"
  },
  {
    "objectID": "lectures/w4l1_freq.html#dataset-for-today",
    "href": "lectures/w4l1_freq.html#dataset-for-today",
    "title": "Frequency Plots",
    "section": "Dataset for Today",
    "text": "Dataset for Today\n\nLoad in the nba2024.csv file\n\n572 observations with 30 variables\n\nSteps:\n\nDownload nba2024.csv file here\nSave to folder of your choice\nCreate .qmd file in RStudio housed in same folder\nUse the following code to load in data\n\n\n\nnba_data &lt;- read.csv(\"../data/nba2024.csv\", header = T)"
  },
  {
    "objectID": "lectures/w4l1_freq.html#histogram",
    "href": "lectures/w4l1_freq.html#histogram",
    "title": "Frequency Plots",
    "section": "Histogram",
    "text": "Histogram\n\nVisualizes distribution of one numeric variable\nThree traits we note:\n\nCenter: where is the middle of our data?\n\ne.g. median, mean\n\nSpread: how spread out are our values?\n\ne.g. standard deviation, range\n\nShape: where is the bulk of the data? what about outliers?\n\ne.g. mode\n\n\nFive-number summary can help with inference: summary()"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example",
    "href": "lectures/w4l1_freq.html#example",
    "title": "Frequency Plots",
    "section": "Example",
    "text": "Example\n\nActivity: Amongst groups of 2-3, describe elements within the histogram that you thing could be changed."
  },
  {
    "objectID": "lectures/w4l1_freq.html#semantics-of-a-histogram",
    "href": "lectures/w4l1_freq.html#semantics-of-a-histogram",
    "title": "Frequency Plots",
    "section": "Semantics of a Histogram",
    "text": "Semantics of a Histogram\n\nbase R: hist(variable)\nggplot: geom_histogram()\n\nArguments within: binwidth, bins, orientation\nAspects that can be adjusted: text size, orientation"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-1",
    "href": "lectures/w4l1_freq.html#example-1",
    "title": "Frequency Plots",
    "section": "Example",
    "text": "Example\n\nCreate bins of width 10\n\nDetermine how many data points fall into each bin\nCount = height of bar\n\nAdd labels\nAdjust title size to 15pt"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-cont.",
    "href": "lectures/w4l1_freq.html#example-cont.",
    "title": "Frequency Plots",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nset.seed(13)\ndf &lt;- data.frame(x = rnorm(100, mean = 50, sd = 20))\nggplot(df, aes(x = x)) +\n  geom_histogram(color = \"white\", binwidth = 10) +\n  theme(text = element_text(size = 20), title = element_text(size = 15)) +\n  labs(title = \"Histogram of X ~ N(50, 20)\", x = \"X\", y = \"Count\")"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-analysis",
    "href": "lectures/w4l1_freq.html#example-analysis",
    "title": "Frequency Plots",
    "section": "Example: Analysis",
    "text": "Example: Analysis\n\n\n\nset.seed(13)\ndf &lt;- data.frame(x = rnorm(100, mean = 50, sd = 20))\nggplot(df, aes(x = x)) +\n  geom_histogram(color = \"white\", binwidth = 10) +\n  theme(text = element_text(size = 20), title = element_text(size = 15)) +\n  labs(title = \"Histogram of X ~ N(50, 20)\", x = \"X\", y = \"Count\") +\n  geom_vline(aes(xintercept = mean(x)), color = \"red\")\n\n\n\n\n\n\n\n\n\n\nDiscuss center, shape, and spread\n\nCenter is around 50\nUnimodal\nMost values between 25 and 75"
  },
  {
    "objectID": "lectures/w4l1_freq.html#activity-create-your-own-histogram",
    "href": "lectures/w4l1_freq.html#activity-create-your-own-histogram",
    "title": "Frequency Plots",
    "section": "Activity: Create your Own Histogram",
    "text": "Activity: Create your Own Histogram\nUsing the nba_data, do the following:\n\nView the data and identify a variable that is numerical and continuous.\nUsing the ggplot() and geom_histogram() functions, create a histogram.\nPerform two adjustments to the histogram created in the last slide.\nAnalyze the center, shape, and spread of the histogram."
  },
  {
    "objectID": "lectures/w4l1_freq.html#bar-plot",
    "href": "lectures/w4l1_freq.html#bar-plot",
    "title": "Frequency Plots",
    "section": "Bar Plot",
    "text": "Bar Plot\n\nVisualizes counts of a categorical variable\nTraits to note:\n\nNumber of categories\nMost and least appeared groups\nDistribution of counts\n\nTable can help with inference: table()"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-2",
    "href": "lectures/w4l1_freq.html#example-2",
    "title": "Frequency Plots",
    "section": "Example",
    "text": "Example\n\nActivity: Amongst groups of 2-3, describe elements within the bar plot that you thing could be changed."
  },
  {
    "objectID": "lectures/w4l1_freq.html#semantics-of-a-bar-plot",
    "href": "lectures/w4l1_freq.html#semantics-of-a-bar-plot",
    "title": "Frequency Plots",
    "section": "Semantics of a Bar plot",
    "text": "Semantics of a Bar plot\n\nbase R: barplot(variable)\nggplot: geom_bar() if individualized, geom_col if summarized\n\nArguments within: position, just, stat\nAspects that can be adjusted: text size, orientation"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-3",
    "href": "lectures/w4l1_freq.html#example-3",
    "title": "Frequency Plots",
    "section": "Example",
    "text": "Example\n\nCreate number of bars based on number of groups\n\nCount number of data points in each group\nCount = height of bar\n\nAdd labels\nAdjust title size to 15pt"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-cont.-1",
    "href": "lectures/w4l1_freq.html#example-cont.-1",
    "title": "Frequency Plots",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\ndf &lt;- data.frame(x =c(\"a\", \"b\", \"c\", \"a\", \"c\", \"a\", \"a\", \"b\", \"c\", \"a\", \"b\", \"c\"))\nggplot(df, aes(x = x)) +\n  geom_bar(color = \"white\") +\n  theme(text = element_text(size = 20), title = element_text(size = 15)) +\n  labs(title = \"Bar Plot of X\", x = \"X\", y = \"Count\")"
  },
  {
    "objectID": "lectures/w4l1_freq.html#example-analysis-1",
    "href": "lectures/w4l1_freq.html#example-analysis-1",
    "title": "Frequency Plots",
    "section": "Example: Analysis",
    "text": "Example: Analysis\n\n\n\ndf &lt;- data.frame(x =c(\"a\", \"b\", \"c\", \"a\", \"c\", \"a\", \"a\", \"b\", \"c\", \"a\", \"b\", \"c\"))\nggplot(df, aes(x = x)) +\n  geom_bar(color = \"white\") +\n  theme(text = element_text(size = 20), title = element_text(size = 15)) +\n  labs(title = \"Bar Plot of X\", x = \"X\", y = \"Count\")\n\n\n\n\n\n\n\n\n\n\n5, 3, and 4 observations in groups a, b, and c respectively\nEvenly distributed"
  },
  {
    "objectID": "lectures/w4l1_freq.html#factor",
    "href": "lectures/w4l1_freq.html#factor",
    "title": "Frequency Plots",
    "section": "factor()",
    "text": "factor()\n\nWhen data is imported into R (or even when we create it), R may not interpret the data as categorical\n\nSolution: factor()\n\nType in R, special case of integer class\nProvides levels/groups\n\nExample: 0s, 1s, and 2s"
  },
  {
    "objectID": "lectures/w4l1_freq.html#factor-1",
    "href": "lectures/w4l1_freq.html#factor-1",
    "title": "Frequency Plots",
    "section": "factor()",
    "text": "factor()\n\n\nTo check:\n\nintData &lt;- c(0, 1, 2, 2, 1, 0)\nintData\n\n[1] 0 1 2 2 1 0\n\n\n\nIf no levels show, vector is of a non-factor type\n\n\nTo fix:\n\nintData &lt;- factor(intData)\nintData\n\n[1] 0 1 2 2 1 0\nLevels: 0 1 2\n\n\nQuestion: What do you notice?"
  },
  {
    "objectID": "lectures/w4l1_freq.html#activity-create-your-own-bar-plot",
    "href": "lectures/w4l1_freq.html#activity-create-your-own-bar-plot",
    "title": "Frequency Plots",
    "section": "Activity: Create your Own Bar Plot",
    "text": "Activity: Create your Own Bar Plot\nUsing the nba_data, do the following:\n\nView the data and identify a variable that is categorical.\n\nIf necessary, convert the column to a factor type.\n\nUsing the ggplot() and geom_bar() functions, create a bar plot.\nPerform two adjustments to the bar plot created in the last slide.\nAnalyze characteristics of the bar plot."
  },
  {
    "objectID": "lectures/w4l1_freq.html#characteristics-of-a-ggplot",
    "href": "lectures/w4l1_freq.html#characteristics-of-a-ggplot",
    "title": "Frequency Plots",
    "section": "Characteristics of a ggplot",
    "text": "Characteristics of a ggplot\n\nAt a minimum, we have data, layers, and a mapping\n\nWe can play around with the scales, facets, coordinates, and themes"
  },
  {
    "objectID": "lectures/w4l1_freq.html#scaling-a-histogram",
    "href": "lectures/w4l1_freq.html#scaling-a-histogram",
    "title": "Frequency Plots",
    "section": "Scaling a Histogram",
    "text": "Scaling a Histogram\n\nggplot(nba_data, aes(x = PTS)) +\n  geom_histogram(bins = 10, color = \"white\") +\n  labs(title = \"Points per 36 Minutes of All NBA Players, 2024\", \n       x = \"Points per 36 Mins\",\n       y = \"Number of Players\") +\n  scale_x_sqrt()"
  },
  {
    "objectID": "lectures/w4l1_freq.html#faceting-a-histogram",
    "href": "lectures/w4l1_freq.html#faceting-a-histogram",
    "title": "Frequency Plots",
    "section": "Faceting a Histogram",
    "text": "Faceting a Histogram\n\nggplot(nba_data, aes(x = PTS)) +\n  geom_histogram(binwidth = 10, color = \"white\") +\n  labs(title = \"Points per 36 Minutes of All NBA Players, 2024\", \n       x = \"Points per 36 Mins\",\n       y = \"Number of Players\") +\n  facet_wrap(vars(Pos))\n\n\n\nActivity: On your own, play around with one function that alters the coordinates and another that alters the theme."
  },
  {
    "objectID": "lectures/w4l1_freq.html#labels-for-a-bar-plot",
    "href": "lectures/w4l1_freq.html#labels-for-a-bar-plot",
    "title": "Frequency Plots",
    "section": "Labels for a Bar Plot",
    "text": "Labels for a Bar Plot\n\nggplot(nba_data, aes(x = Pos)) +\n  geom_bar(color = \"white\") +\n  coord_flip() +\n  labs(title = \"Counts of Different Positions of All NBA Players, 2024\", \n       x = \"Position\",\n       y = \"Number of Players\")"
  },
  {
    "objectID": "lectures/w4l1_freq.html#stacked-bar-plot",
    "href": "lectures/w4l1_freq.html#stacked-bar-plot",
    "title": "Frequency Plots",
    "section": "Stacked Bar Plot",
    "text": "Stacked Bar Plot\n\nggplot(nba_data, aes(x = Tm, fill = Pos)) +\n  geom_bar(color = \"white\") +\n  coord_flip() +\n  labs(title = \"Counts of Different Positions across Teams\\nof All NBA Players, 2024\", \n       x = \"Position\",\n       y = \"Number of Players\") +\n  scale_fill_brewer(palette = 'Set3')"
  },
  {
    "objectID": "lectures/w4l1_freq.html#dodging",
    "href": "lectures/w4l1_freq.html#dodging",
    "title": "Frequency Plots",
    "section": "Dodging",
    "text": "Dodging\n\nggplot(nba_data[nba_data$Tm %in% c(\"BOS\", \"NYK\"), ], aes(x = Tm, fill = Pos)) +\n  geom_bar(color = \"white\", position = \"dodge\") +\n  coord_flip() +\n  labs(title = \"Counts of Different Positions across Teams\\nof All NBA Players, 2024\", \n       x = \"Position\",\n       y = \"Number of Players\") +\n  scale_fill_brewer(palette = 'Set3')"
  },
  {
    "objectID": "lectures/w4l1_freq.html#converting-to-percentages",
    "href": "lectures/w4l1_freq.html#converting-to-percentages",
    "title": "Frequency Plots",
    "section": "Converting to Percentages",
    "text": "Converting to Percentages\n\nggplot(nba_data[nba_data$Tm %in% c(\"BOS\", \"NYK\"), ], aes(x = Tm, fill = Pos)) +\n  geom_bar(color = \"white\", position = \"fill\") +\n  coord_flip() +\n  labs(title = \"Counts of Different Positions across Teams\\nof All NBA Players, 2024\", \n       x = \"Position\",\n       y = \"Proportion of Players\") +\n  scale_fill_brewer(palette = 'Set3')"
  },
  {
    "objectID": "lectures/w4l1_freq.html#activity",
    "href": "lectures/w4l1_freq.html#activity",
    "title": "Frequency Plots",
    "section": "Activity",
    "text": "Activity\nIn groups of 2-3, determine how you can create a histogram and bar plot using the mtcars data frame.\n\nMake sure to include labels, a title, and one modification\nCode these plots up along with the other two activities\nStage, commit, and push changes to Activities repository"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#last-time",
    "href": "lectures/w4l2_boxScatter.html#last-time",
    "title": "Box Plots and Scatter Plots",
    "section": "Last Time",
    "text": "Last Time\n\nFrequency plots\n\nHistograms\nBar plots\nMultivariate frequencies"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#for-today",
    "href": "lectures/w4l2_boxScatter.html#for-today",
    "title": "Box Plots and Scatter Plots",
    "section": "For Today",
    "text": "For Today\n\nBox plots\n\nFive-number summaries\nAnalysis\n\nLine charts\n\nAcross time\n\nScatter plots\n\nCorrelation and trends"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#dataset-for-today",
    "href": "lectures/w4l2_boxScatter.html#dataset-for-today",
    "title": "Box Plots and Scatter Plots",
    "section": "Dataset for Today",
    "text": "Dataset for Today\n\nBoston Housing data\n\nvia the mlbench library\n506 observations, 14 variables\nEstimate median housing values through other variables\n\nCreate a new .qmd file in your activities repository and name the file 2-18.qmd. Use the following code:\n\n\nlibrary(mlbench)\nlibrary(ggplot2)\ndata(BostonHousing2)"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#box-plot",
    "href": "lectures/w4l2_boxScatter.html#box-plot",
    "title": "Box Plots and Scatter Plots",
    "section": "Box Plot",
    "text": "Box Plot\n\nVisualizes distribution of one numeric variable\n\nSimilar usage to histogram\nBetter at detecting benchmarks and comparison\nUsually can compare across groups\n\nThree traits we still note:\n\nCenter, shape, and spread\n\nFive-number summary helps with inference: summary()"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#parts-of-a-box-plot",
    "href": "lectures/w4l2_boxScatter.html#parts-of-a-box-plot",
    "title": "Box Plots and Scatter Plots",
    "section": "Parts of a Box Plot",
    "text": "Parts of a Box Plot\n\nggplot(BostonHousing2, aes(x = medv)) +\n  geom_boxplot() + theme_classic() + \n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  labs(x = \"Median Value of Owner-Occupied Homes ($1000s)\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#parts-of-a-box-plot-cont.",
    "href": "lectures/w4l2_boxScatter.html#parts-of-a-box-plot-cont.",
    "title": "Box Plots and Scatter Plots",
    "section": "Parts of a Box Plot (cont.)",
    "text": "Parts of a Box Plot (cont.)\n\n\nsummary(BostonHousing2$medv)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.00   17.02   21.20   22.53   25.00   50.00 \n\nsummary(BostonHousing2$medv)[c(2, 5)] + c(-1, 1) * 1.5 * IQR(BostonHousing2$medv)\n\n1st Qu. 3rd Qu. \n 5.0625 36.9625"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#parts-of-a-box-plot-cont.-1",
    "href": "lectures/w4l2_boxScatter.html#parts-of-a-box-plot-cont.-1",
    "title": "Box Plots and Scatter Plots",
    "section": "Parts of a Box Plot (cont.)",
    "text": "Parts of a Box Plot (cont.)\n\n\nMinimum: lowest (qualified) value in variable\n1st quartile: 25% of data falls beneath this point\nMedian: 50% of data falls beneath this point\n3rd quartile: 75% of data falls beneath this point\nMaximum: highest (qualified) value in variable"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#outliers",
    "href": "lectures/w4l2_boxScatter.html#outliers",
    "title": "Box Plots and Scatter Plots",
    "section": "Outliers",
    "text": "Outliers\n\n\nOutliers: data points signficantly different from grouping of data\n\nCommon threshold: Those exceeding 1Q and 3Q by 1.5 times the interquartile range\n\ni.e. lower = \\(Q_1 - 1.5 * IQR = Q_1 - 1.5 * (Q_3 - Q_1)\\)\ni.e. upper = \\(Q_3 + 1.5 * IQR = Q_3 + 1.5 * (Q_3 - Q_1)\\)"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#why-median-and-iqr",
    "href": "lectures/w4l2_boxScatter.html#why-median-and-iqr",
    "title": "Box Plots and Scatter Plots",
    "section": "Why Median and IQR?",
    "text": "Why Median and IQR?\n\nData is skewed\n\ne.g. housing prices, Poisson (rate) data\nMedian and IQR are more robust\n\nMean and variance can dramatically change with one outlier\n\n\n\n\nex1 = c(4.6, 4.5, 4.3, 4.2)\nmean(ex1); median(ex1)\n\n[1] 4.4\n\n\n[1] 4.4\n\nsd(ex1); IQR(ex1)\n\n[1] 0.1825742\n\n\n[1] 0.25"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#why-median-and-iqr-cont.",
    "href": "lectures/w4l2_boxScatter.html#why-median-and-iqr-cont.",
    "title": "Box Plots and Scatter Plots",
    "section": "Why Median and IQR? (cont.)",
    "text": "Why Median and IQR? (cont.)\n\nData is skewed\n\ne.g. housing prices, Poisson (rate) data\nMedian and IQR are more robust\n\nMean and variance can dramatically change with one outlier\n\n\n\n\nex1 = c(ex1, 10.1)\nmean(ex1); median(ex1)\n\n[1] 5.54\n\n\n[1] 4.5\n\nsd(ex1); IQR(ex1)\n\n[1] 2.554016\n\n\n[1] 0.3"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#activity",
    "href": "lectures/w4l2_boxScatter.html#activity",
    "title": "Box Plots and Scatter Plots",
    "section": "Activity",
    "text": "Activity\nIn the 2-18.qmd file:\n\nCreate a new code chunk and develop a box plot that looks at another numerical variable from the BostonHousing2 dataset."
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#grouped-boxplots",
    "href": "lectures/w4l2_boxScatter.html#grouped-boxplots",
    "title": "Box Plots and Scatter Plots",
    "section": "Grouped Boxplots",
    "text": "Grouped Boxplots\n\nAdd second variable, which is a grouping variable\n\nUsed to do comparisons across groups\n\n\n\nggplot(BostonHousing2, aes(x = medv, y = chas)) +\n  geom_boxplot() + theme_classic() +\n  labs(x = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       y = \"Next to Charles River?\",\n       title = \"Median Value of Owner-Occupied Homes (in $1000s)\\nin Boston Census Tracts Near Charles River, 1970\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#grouped-boxplots-things-to-consider",
    "href": "lectures/w4l2_boxScatter.html#grouped-boxplots-things-to-consider",
    "title": "Box Plots and Scatter Plots",
    "section": "Grouped Boxplots: Things to Consider",
    "text": "Grouped Boxplots: Things to Consider\n\n\n\nOutliers: number, context\nRanges, IQR: larger, smaller?\n\n\n\nMedians\nSymmetry\n\n\n\nggplot(BostonHousing2, aes(x = medv, y = chas)) +\n  geom_boxplot() + theme_classic() +\n  labs(x = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       y = \"Next to Charles River?\",\n       title = \"Median Value of Owner-Occupied Homes (in $1000s)\\nin Boston Census Tracts Near Charles River, 1970\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#scatter-plot",
    "href": "lectures/w4l2_boxScatter.html#scatter-plot",
    "title": "Box Plots and Scatter Plots",
    "section": "Scatter Plot",
    "text": "Scatter Plot\n\nVisualizes distributions of two numeric variables\n\nCan be used to detect trends, patterns, and correlations\nUsed for regression\n\nFor relational purposes:\n\n\\(x\\) refers to independent variable (or predictor)\n\\(y\\) refers to dependent variable (or response)\nLooking for relationship between \\(x\\) and \\(y\\), leading to idea behind correlation\n\nCorrelation helps with inference: cor(x, y)"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#correlation",
    "href": "lectures/w4l2_boxScatter.html#correlation",
    "title": "Box Plots and Scatter Plots",
    "section": "Correlation",
    "text": "Correlation\n\nDescribes relationship between two continuous variables\n\n\\(cor(x, y) = Cov(xy) / \\sqrt{s_x s_y}\\)\nLook at three traits:\n\nMagnitude: 0 indicates no relationship, 1 indicates perfect relationship\nDirection: - refers to decreasing trend from left to right, + is increasing\nLinearity: how much data “hugs” line of best fit"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#correlation-examples",
    "href": "lectures/w4l2_boxScatter.html#correlation-examples",
    "title": "Box Plots and Scatter Plots",
    "section": "Correlation Examples",
    "text": "Correlation Examples"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot",
    "href": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot",
    "title": "Box Plots and Scatter Plots",
    "section": "Example of a Scatter Plot",
    "text": "Example of a Scatter Plot\n\nggplot(BostonHousing2, aes(x = nox, y = medv)) +\n  geom_point() + theme_minimal() +\n  labs(x = \"Nitric Oxide Concentration (parts per 10mil)\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Nitric Oxide Concentration vs. Median Value of Owner-Occupied Homes\\nin Boston Census Tracts, 1970\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot-cont.",
    "href": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot-cont.",
    "title": "Box Plots and Scatter Plots",
    "section": "Example of a Scatter Plot (cont.)",
    "text": "Example of a Scatter Plot (cont.)\n\nCan adjust for opacity to make point stand out\n\n\nggplot(BostonHousing2, aes(x = nox, y = medv)) +\n  geom_point(alpha = 0.3) + theme_minimal() +\n  labs(x = \"Nitric Oxide Concentration (parts per 10mil)\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Nitric Oxide Concentration vs. Median Value of Owner-Occupied Homes\\nin Boston Census Tracts, 1970\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot-cont.-1",
    "href": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot-cont.-1",
    "title": "Box Plots and Scatter Plots",
    "section": "Example of a Scatter Plot (cont.)",
    "text": "Example of a Scatter Plot (cont.)\n\nCan create line of best fit and add correlation label\n\n\nggplot(BostonHousing2, aes(x = nox, y = medv)) +\n  geom_point(alpha = 0.3) + theme_minimal() +\n  labs(x = \"Nitric Oxide Concentration (parts per 10mil)\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Nitric Oxide Concentration vs. Median Value of Owner-Occupied Homes\\nin Boston Census Tracts, 1970\") +\n  geom_smooth(method = \"lm\") + \n  annotate(\"label\", x = 0.8, y = 50, size = 3, \n           label = paste(\"Corr.\", round(cor(BostonHousing2$nox, BostonHousing2$medv), 3)), color = \"red\", fontface = \"bold\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot-cont.-2",
    "href": "lectures/w4l2_boxScatter.html#example-of-a-scatter-plot-cont.-2",
    "title": "Box Plots and Scatter Plots",
    "section": "Example of a Scatter Plot (cont.)",
    "text": "Example of a Scatter Plot (cont.)\n\nCan make color differ by another variable\n\nlstat: percentage of lower status of population\n\n\n\nggplot(BostonHousing2, aes(x = nox, y = medv, colour = lstat)) +\n  geom_point(alpha = 0.3) + theme_minimal() +\n  labs(x = \"Nitric Oxide Concentration (parts per 10mil)\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       colour = \"% Lower Status\",\n       title = \"Nitric Oxide Concentration vs. Median Value of Owner-Occupied Homes\\nin Boston Census Tracts, 1970\") +\n  geom_smooth(method = \"lm\", color = \"blue\") + \n  annotate(\"label\", x = 0.8, y = 50, size = 3, \n           label = paste(\"Corr.\", round(cor(BostonHousing2$nox, BostonHousing2$medv), 3)), color = \"red\", fontface = \"bold\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#line-chart",
    "href": "lectures/w4l2_boxScatter.html#line-chart",
    "title": "Box Plots and Scatter Plots",
    "section": "Line Chart",
    "text": "Line Chart\n\nVisualizes trends of one variable across another variable (commonly time)\n\nSpecial case of a scatter plot\n\nOrder across points\n\n\nFocus on trend over the variable"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#example-of-a-line-chart",
    "href": "lectures/w4l2_boxScatter.html#example-of-a-line-chart",
    "title": "Box Plots and Scatter Plots",
    "section": "Example of a Line Chart",
    "text": "Example of a Line Chart\n\nlakes = data.frame(year = 1875:1972, level = as.numeric(LakeHuron))\n\nggplot(lakes, aes(x = year, y = level)) + \n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Levels (in ft) on Lake Huron, 1875-1972\") +\n  ylab(\"Level (ft)\") +\n  xlab(\"Year\")"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#bonus-spatial-maps",
    "href": "lectures/w4l2_boxScatter.html#bonus-spatial-maps",
    "title": "Box Plots and Scatter Plots",
    "section": "Bonus: Spatial Maps",
    "text": "Bonus: Spatial Maps\n\nWe have data that can be placed onto a map\n\nWhat would those variables be?"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#example",
    "href": "lectures/w4l2_boxScatter.html#example",
    "title": "Box Plots and Scatter Plots",
    "section": "Example",
    "text": "Example\n\n\n\nlibrary(maps)\nboston &lt;- map_data(\"county\", region = \"Massachusetts\")\n\nggplot(BostonHousing2, aes(x = lon, y = lat, colour = medv)) +\n  geom_polygon(data = boston,\n               aes(x = long, y = lat, group = group),\n               fill = NA, color = \"black\") +\n  geom_point(data = BostonHousing2, \n             aes(x = lon, y = lat, colour = medv),\n             alpha = 0.2) + theme_classic() +\n  coord_map(\"albers\",  lat0 = 45.5, lat1 = 29.5) +\n  labs(x = \"\",\n       y = \"\",\n       colour = \"Median\\nHousing\\nValues\\n($1000s)\",\n       title = \"Median Value of Owner-Occupied Homes\\n\nacross Boston Census Tracts, 1970\") +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.line.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())"
  },
  {
    "objectID": "lectures/w4l2_boxScatter.html#activity-1",
    "href": "lectures/w4l2_boxScatter.html#activity-1",
    "title": "Box Plots and Scatter Plots",
    "section": "Activity",
    "text": "Activity\nIn groups of 2-3, create either your own line chart or scatter plot.\n\nMake sure to include labels, a title, and one modification\nCode these plots up along with the other activities\nStage, commit, and push changes to your activities repository"
  },
  {
    "objectID": "lectures/w2l2_github.html#helpful-vector-functions",
    "href": "lectures/w2l2_github.html#helpful-vector-functions",
    "title": "R and GitHub",
    "section": "Helpful Vector Functions",
    "text": "Helpful Vector Functions\n\nAll VectorsNumeric VectorsCategorical Vectors\n\n\n\nclass() returns the class of the values in a vector\nlength() returns the number of values in a vector\nis.na() for each value, returns whether the value is an NA value\n\n\n\n\nsum() returns the sum of the values in a vector\nmax() returns the maximum value in a vector\nrank() returns the ranking of a value in a vector\nR has other functions for accomplishing statistical, mathematical, and ordering operations\n\n\n\n\nunique() returns the unique values of a vector\ntable() returns the distribution of unique values of a vector"
  },
  {
    "objectID": "lectures/w2l2_github.html#learning-check",
    "href": "lectures/w2l2_github.html#learning-check",
    "title": "R and GitHub",
    "section": "Learning Check",
    "text": "Learning Check\nHow would I find the sum of the third column in this data frame, which I have named df?\n\n\n  col1 col2 col3\n1    1    2    3\n2    5    4    6\n3    7    6    9"
  },
  {
    "objectID": "lectures/w2l2_github.html#helpful-data-frame-functions",
    "href": "lectures/w2l2_github.html#helpful-data-frame-functions",
    "title": "R and GitHub",
    "section": "Helpful Data Frame Functions",
    "text": "Helpful Data Frame Functions\n\nView(): Opens a tab to view the data frame as a table\nhead(): returns first six rows of dataset\nnames(): returns the dataset’s column names\nnrow(): returns the number of rows in the dataset\nncol(): returns the number of columns in the dataset"
  },
  {
    "objectID": "lectures/w2l2_github.html#do-i-really-have-to-memorize-all-of-these-functions",
    "href": "lectures/w2l2_github.html#do-i-really-have-to-memorize-all-of-these-functions",
    "title": "R and GitHub",
    "section": "Do I really have to memorize all of these functions?!",
    "text": "Do I really have to memorize all of these functions?!\n\nNo. There are cheatsheets! See this cheatsheet for Base R.\nGoogle, ChatGPT, and various forums can also be used to discover new functions\n\ne.g. “what function can be used to order a vector in R?”"
  },
  {
    "objectID": "lectures/w2l2_github.html#pipe-operator-in-r",
    "href": "lectures/w2l2_github.html#pipe-operator-in-r",
    "title": "R and GitHub",
    "section": "Pipe Operator in R",
    "text": "Pipe Operator in R\n\nFunnel objects into actions\n\ne.g. data structures into various functions\n|&gt; or %&gt;%\n\nUseful for nesting functions\n\n\nlength(unique(mtcars$am))\n\n[1] 2\n\nmtcars |&gt; pull(am) |&gt; unique() |&gt; length()\n\n[1] 2"
  },
  {
    "objectID": "lectures/w2l2_github.html#missing-values",
    "href": "lectures/w2l2_github.html#missing-values",
    "title": "R and GitHub",
    "section": "Missing Values",
    "text": "Missing Values\n\nRemember that missing values still have a position in rectangular datasets\nMissing values get recorded as NA in R\n…but sometimes analysts put words or numbers in their datasets to indicate missingness:\n\n“NONE”\n-999\n“” &lt;- this is the most challenging to uncover!\n\n…but what happens when we try to perform functions on vectors that contain missing values?"
  },
  {
    "objectID": "lectures/w2l2_github.html#missing-values-in-math-functions",
    "href": "lectures/w2l2_github.html#missing-values-in-math-functions",
    "title": "R and GitHub",
    "section": "Missing Values in Math Functions",
    "text": "Missing Values in Math Functions\nWe can use na.rm = TRUE to ignore NA values in math functions.\n\nvals &lt;- c(1, 2, NA, 4, NA, 6)\nsum(vals)\n\n[1] NA\n\nsum(vals, na.rm = TRUE)\n\n[1] 13"
  },
  {
    "objectID": "lectures/w2l2_github.html#for-now-and-friday",
    "href": "lectures/w2l2_github.html#for-now-and-friday",
    "title": "R and GitHub",
    "section": "For Now and Friday",
    "text": "For Now and Friday\n\nFinish activity for today’s class\nFinish reading exercises by end of Thursday\n\nAppendix B, problems 1 and 3\n\nLab #1 will be introduced in Friday’s class!"
  },
  {
    "objectID": "labs/lab3/index.html",
    "href": "labs/lab3/index.html",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "",
    "text": "Designing effective data visualizations involves reviewing available data and then determining how best to map variables in the data onto a variety of visual cues. When we refer to visual cues, we are referring to those visual components of the plot that help us discern differences across data points. For instance, a plot might use different shapes or colors to represent different categories of data. A plot might also place points at different positions or bars at different heights to represent different numeric values. This week we will practice mapping variables in a dataset onto different plot aesthetics in order to tell different stories with the data. We will only be creating one type of plot today - a scatterplot. However, we are going to show how we can use different visual cues to plot a number of different variables onto a scatterplot.\n\n\n\nRead the ggplot cheatsheets\nMap variables onto plot aeshetics\nAdjust the attributes of a plot\nAdjust the scales of aeshetics on plots\nDeal with overplotting\nFacet plots into small multiples"
  },
  {
    "objectID": "labs/lab3/index.html#introduction",
    "href": "labs/lab3/index.html#introduction",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "",
    "text": "Designing effective data visualizations involves reviewing available data and then determining how best to map variables in the data onto a variety of visual cues. When we refer to visual cues, we are referring to those visual components of the plot that help us discern differences across data points. For instance, a plot might use different shapes or colors to represent different categories of data. A plot might also place points at different positions or bars at different heights to represent different numeric values. This week we will practice mapping variables in a dataset onto different plot aesthetics in order to tell different stories with the data. We will only be creating one type of plot today - a scatterplot. However, we are going to show how we can use different visual cues to plot a number of different variables onto a scatterplot.\n\n\n\nRead the ggplot cheatsheets\nMap variables onto plot aeshetics\nAdjust the attributes of a plot\nAdjust the scales of aeshetics on plots\nDeal with overplotting\nFacet plots into small multiples"
  },
  {
    "objectID": "labs/lab3/index.html#review-of-key-terms",
    "href": "labs/lab3/index.html#review-of-key-terms",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "Review of Key Terms",
    "text": "Review of Key Terms\n\nAesthetics\n\nVisual cues that we map variables in a dataset onto\n\nCartesian grid\n\nA 2-dimensional grid with an intersecting x and y axis\n\nSequential color\n\nA uni-directional ordering of shades\n\nQualitative color\n\nA discrete set of colors\n\nDivergent color\n\nA diverging ordering of color shades\n\nOverplotting\n\nInstances when visual representations of individual data points overlap on a plot making aspects of the plot illegible"
  },
  {
    "objectID": "labs/lab3/index.html#national-bridge-inventory-dataset",
    "href": "labs/lab3/index.html#national-bridge-inventory-dataset",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "National Bridge Inventory Dataset",
    "text": "National Bridge Inventory Dataset\nEvery year the U.S. Federal Highway Administration publishes a dataset listing every federally-regulated bridge and tunnel in the U.S., along with its location, design features, operational conditions, and inspection ratings. The data is used to review the safety of these transportation infrastructures for the traveling public. As you can imagine, for politicians promising to the improve the state of transportation infrastructure, this dataset is integral to determining where to allocate improvement funds:\n\n\nToday, we are going to look at a subset of 2024 NBI data for Massachusetts and for Hampshire County, MA, and we are going to focus solely on highway bridges (excluding pedestrian and railroad bridges). We’re going to look at what kinds of variables might contribute to poor bridge conditions, where there are poor bridge conditions, and which entities are responsible for maintaining them. The data documentation for this dataset is quite thick, so I will provide you with a data dictionary for today.\n\n\n\n\n\n\n\nVARIABLE NAME\nDESCRIPTION\n\n\n\n\nSTRUCTURE_NUMBER_008\nUnique ID for the bridge\n\n\nCOUNTY_CODE_003_L\nName of the county where the bridge is located\n\n\nROUTE_PREFIX_005B_L\nRoute signing prefix for the inventory route\n\n\nMAINTENANCE_021_L\nThe actual name(s) of the agency(s) responsible for the maintenance of the structure\n\n\nYEAR_BUILT_027\nThe year of construction of the structure\n\n\nADT_029\nThe average daily traffic volume for the inventory route based on most recent available data\n\n\nSTRUCTURE_KIND_043A_L\nThe kind of material and/or design of the structure\n\n\nSTRUCTURAL_EVAL_067\nA rating of the structural evaluation of the bridge based on inspections of its main structures, substructures, and/or its load ratings\n\n\nBRIDGE_IMP_COST_094\nEstimated costs for bridge improvements"
  },
  {
    "objectID": "labs/lab3/index.html#setting-up-your-environment",
    "href": "labs/lab3/index.html#setting-up-your-environment",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "Setting Up Your Environment",
    "text": "Setting Up Your Environment\n\nInstall the RColorBrewer package by entering the following into your R Console: install.packages(\"RColorBrewer\")\nRun the code below to the import the bridge inventory for Massachusetts and for Hampshire County into R. Call me or one of the data assistants over if you get an error.\n\n\nlibrary(tidyverse)\nlibrary(RColorBrewer)\ncounties &lt;- read_csv(\"https://raw.githubusercontent.com/sds-192-intro-fall22/sds-192-public-website-quarto/a8b64e3070ca2543b904d4d92780b09e6062ced6/website/data/nbi_counties.csv\")\nroute_prefixes &lt;- read_csv(\"https://raw.githubusercontent.com/sds-192-intro-fall22/sds-192-public-website-quarto/a8b64e3070ca2543b904d4d92780b09e6062ced6/website/data/nbi_route_pre.csv\")\nmaintenance &lt;- read_csv(\"https://raw.githubusercontent.com/sds-192-intro-fall22/sds-192-public-website-quarto/a8b64e3070ca2543b904d4d92780b09e6062ced6/website/data/nbi_maintenance.csv\")\nkinds &lt;- read_csv(\"https://raw.githubusercontent.com/sds-192-intro-fall22/sds-192-public-website-quarto/a8b64e3070ca2543b904d4d92780b09e6062ced6/website/data/nbi_kind.csv\")\n\nnbi_ma &lt;- read.delim(\"https://www.fhwa.dot.gov/bridge/nbi/2024/delimited/MA24.txt\", sep = \",\") |&gt;\n  left_join(counties) |&gt;\n  left_join(route_prefixes) |&gt;\n  left_join(maintenance) |&gt;\n  left_join(kinds) |&gt;\n  filter(SERVICE_ON_042A == 1) |&gt;\n  select(STRUCTURE_NUMBER_008, COUNTY_CODE_003_L, ROUTE_PREFIX_005B_L, MAINTENANCE_021_L, YEAR_BUILT_027, ADT_029, STRUCTURE_KIND_043A_L, STRUCTURAL_EVAL_067, BRIDGE_IMP_COST_094) |&gt;\n  mutate(STRUCTURE_KIND_043A_L = \n           case_when(\n             STRUCTURE_KIND_043A_L == \"Concrete continuous\" ~ \"Concrete\",\n             STRUCTURE_KIND_043A_L == \"Steel continuous\" ~ \"Steel\",\n             STRUCTURE_KIND_043A_L == \"Prestressed concrete continuous\" ~ \"Prestressed concrete\",\n             TRUE ~ STRUCTURE_KIND_043A_L)) |&gt;\n  mutate(BRIDGE_IMP_COST_094 = BRIDGE_IMP_COST_094 * 1000)\n\nnbi_hampshire &lt;- nbi_ma |&gt; filter(COUNTY_CODE_003_L == \"Hampshire\")\n\nrm(counties, kinds, maintenance, route_prefixes)"
  },
  {
    "objectID": "labs/lab3/index.html#visualization-aesthetics",
    "href": "labs/lab3/index.html#visualization-aesthetics",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "Visualization Aesthetics",
    "text": "Visualization Aesthetics\nThe visual cues that we select to display on a plot largely depend on the kind of data that we have available. Last week we discussed the differences between categorical variables and numeric variables. Certain types of visual cues are more suited for representing categorical variables, while other types of visual cues are more suited for representing numeric variables. For instance, we wouldn’t use different shapes to represent different numeric values because there is no obvious ordering to a group of shapes (e.g. a triangle isn’t necessarily larger or greater than a circle; they’re just different). Because of this, shapes are much more appropriate for representing nominal categorical variables. Size is a much more effective visual cue for numeric variables because size can increase as the values in the data increase.\n\n\n\n\n\n\n\n\nCue\nEffective for what kinds of variables?\nExample where applied?\n\n\n\n\nShape\nCategorical\nPoints on scatterplots\n\n\nSize\nNumeric\nPoints on scatterplots\n\n\nArea\nNumeric\nBars in bar plots\n\n\nColor\nCategorical (Qualitative palette)\nNumeric (Sequential/Divergent)\nPoints on scatterplots;\nBars in bar plots;\nLines in a line plot\n\n\nPosition\nCategorical; Numeric\nPoints on scatterplots\n\n\nAngle\nNumeric\nSlices in pie chart\n\n\n\nYou’ll remember from lecture that we map variables onto these visual cues via the aesthetic function (aes()) in ggplot().\n\n\n\n\n\n\nTip\n\n\n\nYou may wish to reference this ggplot cheatsheet when completing this lab. Note how this cheatsheet is organized. There are headings for things like:\n\nBasics\nGeom functions\nScales\nCoordinate systems\n\nThe first tip to find what you’re looking for is to consider what heading the graphic element will likely fall under. Also note that, for many functions on this cheatsheet:\n\nan image is provided for how the plot will transform,\nthe function and its arguments are referenced in bold, and\na text description of what will happen when you apply the function is provided\n\nFinally note that most of these functions listed on this cheatsheet are appended to the ggplot() object with a + sign.\n\n\n\nPosition\nSince today we will be working with scatterplots, let’s start by talking about position. When we refer to position, we refer to the location of a point on a Cartesian plane (i.e. its position on an x-axis and its position on a y-axis). We can create scatterplots by mapping a variable in our dataset onto the x-axis and another variable onto the y-axis (aes(x = VARIABLE_NAME, y = VARIABLE_NAME)). Let’s take a look at what happens when we map the year a bridge was built onto the x aesthetic and the bridge’s structural evaluation onto the y aesthetic for all Hampshire County Massachusetts highway bridges.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point() +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEach point on the plot corresponds to one observation (row) in the dataset. Since each row in this dataset is one Hampshire County, MA highway bridge, each point on this plot also represents one Hampshire County, MA highway bridge. The position of the point indicates to us the year that bridge was built and its structural evaluation. Zooming out to look at all of this data we can see that newer bridges tend to have higher structural evaluations.\n\nOverplotting\nYou’ll notice that parts of this plot can be challenging to read because some points overlap each other making it hard to distinguish one from the next. This is an example of overplotting, and there are a number of strategies we can take to addressing it. Most of these strategies involve revising attributes of the points on the plot (e.g. the size, transparency, and position of the points).\nNote that attributes are different than aesthetics. Recall that when we assign aesthetics in a plot, we are adjusting the visual cues on a plot according to the values in a variable. The visual cues will be different based on the values in that variable (e.g. size will be greater with greater values). On the other hand, when we adjust attributes, we are adjusting the visual cues on a plot in a fixed way (i.e. every point will be styled in the same way regardless of its value). Because of this attributes are assigned outside of the aes() (aesthetic) function. Let’s adjust the plot we created above by reducing the size of every point (size =), reducing the transparency of every point (alpha =), and adding \"jitter\" to the plot (position=). Recall that alpha is assigned between 0 and 1: 0 being transparent and 1 being opaque. Jitter means that we add a bit of random noise to the points on the plot in order to prevent overlapping points.\n\n\n\n\n\n\nImportantQuestion 1 (3 pts)\n\n\n\nIn the code below, adjust the size to 2 and the alpha to 0.5. Set the position to \"jitter\". Note how this changes the plot.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point(size = 1, alpha = 1, position = \"identity\") +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nColor\nColor can be used on plots to either distinguish between discrete values in a categorical variable or to represent the range of values in numeric variable. We use different kinds of color palettes for each of these scenarios. Palettes refer to a range of colors. We can have palettes with discrete colors (e.g. red, orange, and blue) or palettes with a gradient of colors (e.g. lightest red to darkest red).\n\n\n\n\n\n\n\n\nPalette\nEffective for what kinds of variables?\nExample\n\n\n\n\nQualitative\nCategorical\nRed, yellow, blue\n\n\nSequential\nNumeric\nLight blue to dark blue\n\n\nDivergent\nNumeric, extending in two directions (e.g. &gt;1 and &lt;1)\nBlue to purple to red\n\n\n\n\n\n\n\n\n\nImportantQuestion 2 (3 pts)\n\n\n\nIn the plot below, color the points on the plot with a qualitative palette by setting col= to the categorical variable ROUTE_PREFIX_005B_L. Remember that, in this case, color is an aesthetic, so this must be added inside of the aes() function. Add a label for the legend by setting col= in the labs() function to a phrase that describes the color variable.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point(size = 2, alpha = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\",\n       col = \"ADD LEGEND LABEL HERE\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantQuestion 3 (3 pts)\n\n\n\nCopy the completed plot from the last exercise below but swap out the variable you mapped to the color aesthetic with a numeric variable from the dataset. Be sure to also adjust the legend label. What kind of palette gets created? What new information do you gain about Hampshire County bridges from the plot? Note your interpretations in your quarto file.\n\n#Copy plot here!\n\n\n\n\n\nShape\nA different way to differentiate data on a plot is to map the shape aesthetic onto the plot. In this case, rather than all observations in the dataset appearing as points on a plot, observations will appear as different shapes based on their associated values in a categorical variable.\n\n\n\n\n\n\nImportantQuestion 4 (3 pts)\n\n\n\nIn the plot below, assign the shape of the data on the plot by setting shape= to the categorical variable STRUCTURE_KIND_043A_L. Remember that, in this case, shape is an aesthetic, so this must be added inside of the aes() function. Add a label for the legend by setting shape= in the labs() function to a phrase that describes the shape variable.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point(size = 2, alpha = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\",\n       shape = \"ADD LEGED LABEL HERE\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nSize\nWhile we might map a categorical variable onto the the shape aesthetic, we can alternatively map a numeric variable onto the size aesthetic. For instance, note what we learn when we map the variable for average daily traffic onto the size aesthetic below.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = ROUTE_PREFIX_005B_L, \n             y = STRUCTURAL_EVAL_067, \n             size = ADT_029)) +\n  geom_point(alpha = 0.5, position = \"jitter\") +\n  coord_flip() +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Route Prefix\", \n       y = \"Structural Evaluation\",\n       size = \"Average Daily Traffic\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote how I moved my legend position to the bottom using + theme(legend.position = \"bottom\") in the code above.\n\n\n\n\n\n\n\n\nImportantQuestion 5 (3 pts)\n\n\n\nCopy one of your plots from above, and inside the aes() function, set size= to a numeric variable not already represented on the plot. Keep in mind that you’ll need to remove the size= attribute from geom_point() for the points to size correctly. Be sure to also adjust the legend labels. What new information do you gain about Hampshire County bridges from the plot?\n\n# Copy and adjust plot here"
  },
  {
    "objectID": "labs/lab3/index.html#scales",
    "href": "labs/lab3/index.html#scales",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "Scales",
    "text": "Scales\nWhen we map a variable onto an aesthetic, we are only indicating that the variable should be mapped. We are not indicating how the variable should be mapped. In order to indicate how we want a variable mapped to an aesthetic, we can adjust its scales. Scales are adjusted by tacking the following onto a ggplot() object: + scale_&lt;aesthetic&gt;_&lt;type&gt;(). For instance, let’s say that I wanted to adjust the scale of my x-axis to a log scale. I would attached + scale_x_log10() to my ggplot() object.\n\n\n\n\n\n\n\n\nScale\nDescription\nExample\n\n\n\n\nContinuous\nNumeric values are mapped along a continuum\n+ scale_y_continuous()\n\n\nDiscrete\nCategorical values are mapped into discrete buckets\n+ scale_color_discrete()\n\n\nBinned\nNumeric values are mapped into discrete bins\n+ scale_size_binned()\n\n\nLog\nNumeric values are mapped logarthmically\n+ scale_y_log10()\n\n\nDate-Time\nNumeric values are mapped along a timeline\n+ scale_x_datetime()\n\n\n\nLet’s talk about how we would adjust the scales for each of the aesthetics we’ve covered so far.\n\nPosition\nWe can adjust the scale of our x and y-axes by adding + scale_x_&lt;type&gt;() or + scale_y_&lt;type&gt;() to our plots. Note what happens when we attempt to create a scatterplot that shows the relationship between the year a bridge was built and the bridge improvement costs for all MA highway bridges.\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = BRIDGE_IMP_COST_094)) +\n  geom_point(size = 1, alpha = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Bridge Improvement Costs\") +\n  theme_minimal() + \n  scale_y_continuous(labels = scales::comma)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nDue to huge disparities in costs for bridge improvements, this plot is difficult to interpret. Most bridge improvement costs are under $10,000,000, but with at least one bridge with costs just under a $1,000,000,000, the vast majority of the points on the plot appear at the very bottom of the y-axis scale and are largely indiscernible from one another. This is a case when it makes sense to apply a log scale to the y-axis.\n\n\n\n\n\n\nImportantQuestion 6 (3 pts)\n\n\n\nIn the plot below, change the y-axis scale from continuous to log10. You might reference the formula specified above or reference the ggplot cheatsheet for help. Note that your y-axis will appear in scientific notation. Convert it to comma notation by adding: labels = scales::comma as an argument in the scale function call.\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = BRIDGE_IMP_COST_094)) +\n  geom_point(size = 1, alpha = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Bridge Improvement Costs\") +\n  theme_minimal() + \n  scale_y_continuous(labels = scales::comma)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nSometimes I might wish to group certain numeric values into bins on a plot. For instance, let’s say I just want to see how many bridges are structurally deficient in comparison to bridges that are operationally sound. Typically a bridge is considered structurally deficient when it scores 4 or lower. So I want to group the numeric values in STRUCTURAL_EVAL_067 into two bins: 0-4 and 4-9. To do this, I will set the scale to: + scale_y_binned() and add an argument to establish the bin breaks: breaks = c(4, 9) as well as an argument to label the bin breaks: labels = c(\"Structurally Deficent\", \"No Deficiencies\"). Check out what happens to the y-axis scale when I do this below.\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point(size = 1, alpha = 0.2, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\") +\n  theme_minimal() + \n  scale_y_binned(breaks = c(4, 9), labels = c(\"Structurally Deficent\", \"No Deficiencies\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantQuestion 7 (3 pts)\n\n\n\nThe Interstate Highway Act of 1956 (signed under Dwight D. Eisenhower) established the U.S.’s interstate highway system and is considered the country’s largest public works project. Adjust the x-axis scale of the plot below to help tell this story. Specifically, bin years into before 1954 (when Eisenhower was elected) and 1954-2021. Set the label at 1954 to “Eisenhower Elected” and the label at 2021 to “Today.”\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = ROUTE_PREFIX_005B_L)) +\n  geom_point(size = 1, alpha = 0.2, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Route Prefix\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nColor\nWe’ve already talked about how both categorical and numeric variables can be mapped to the color aesthetic. However, sometimes, we want to be able to further customize which colors should appear on the plot and how they appear on the plot. The RColorBrewer package, which you installed earlier in the lab includes a number of palettes for coloring points on a plot. Check them out below:\n\nRColorBrewer::display.brewer.all() \n\n\n\n\n\n\n\n\nNote how the first set of palettes is sequential, the second set is categorical, and the third set is divergent. We can assign these palettes to our plots using one of two functions: + scale_color_brewer() for categorical data and + scale_color_distiller() for numeric data. Within this function, we can set the argument palette equal to one of the palettes specified in the image above.\n\n\n\n\n\n\nImportantQuestion 8 (3 pts)\n\n\n\nAdd `+ scale_color_brewer()` to the ggplot() object below and assign a categorical palette. Refer to the ggplot cheatsheet or the help pages for help with formatting the function call.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067,\n             col = ROUTE_PREFIX_005B_L)) +\n  geom_point(size = 2, alpha = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, Massachusetts, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\",\n       col = \"Route Prefix\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantQuestion 9 (3 pts)\n\n\n\nAdd `+ scale_color_distiller()` to the ggplot() object below and assign a sequential palette. By default the colors will be ordered from darkest to lightest. Add an argument to the function call to reverse the direction of the colors. Refer to the ggplot cheatsheet or the help pages for help with formatting the function call.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067,\n             col = ADT_029)) +\n  geom_point(size = 2, alpha = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\",\n       col = \"Average Daily Traffic\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nSize and Shape\nThe following represents the values associated with ggplot() point shapes.\n\nWe can manually assign shapes using + scale_shape_manual(values = c(&lt;shape_values&gt;)).\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067, \n             shape = MAINTENANCE_021_L)) +\n  geom_point(alpha = 0.5, size = 2, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\",\n       shape = \"Maintainer\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        legend.box=\"vertical\") +\n  guides(shape = guide_legend(nrow = 3, byrow = TRUE)) +\n  scale_shape_manual(values = c(15:17))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the guides() function above allows us to wrap the legend into three rows!\n\n\nAlso note how we bin point sizes just like we binned values on the x and y axis.\n\nnbi_hampshire |&gt;\n  ggplot(aes(x = ROUTE_PREFIX_005B_L, \n             y = STRUCTURAL_EVAL_067, \n             size = ADT_029)) +\n  geom_point(alpha = 0.5, position = \"jitter\") +\n  coord_flip() +\n  labs(title = \"Highway Bridge Conditions, Hampshire County, MA, 2024\",\n       x = \"Route Prefix\", \n       y = \"Structural Evaluation\",\n       size = \"Average Daily Traffic\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_size_binned(breaks = c(0, 500, 5000, 100000))\n\nWarning in sqrt(x): NaNs produced\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "labs/lab3/index.html#faceting",
    "href": "labs/lab3/index.html#faceting",
    "title": "Lab #3: Visualization Aesthetics (30 pts)",
    "section": "Faceting",
    "text": "Faceting\nFaceting involves breaking out a single plot into multiple smaller plots based on the value in a variable. Faceting is very helpful when we have a categorical variable with many distinct values. If we tried to color by that variable, the colors would likely be indistinguishable from one another. For instance, check out what happens when we try to color by the COUNTY_CODE_003_L variable below.\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067, \n             col = COUNTY_CODE_003_L)) +\n  geom_point(alpha = 0.5, size = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\",\n       col = \"County\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere are so many counties that it’s extremely challenging to distinguish between colors on this plot. In this case, instead of using a color aesthetic, we facet the plot by adding + facet_wrap(vars(COUNTY_CODE_003_L)) to the ggplot() object. Check out what happens when we do that below.\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point(alpha = 0.1, size = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA, 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\") +\n  theme_minimal() +\n  facet_wrap(vars(COUNTY_CODE_003_L))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantQuestion 10 (3 pts)\n\n\n\nFacet the plot below by STRUCTURE_KIND_043A_L to see the degree of structural deficiencies for different kinds of highway bridges of different ages in Massachusetts.\n\nnbi_ma |&gt;\n  ggplot(aes(x = YEAR_BUILT_027, \n             y = STRUCTURAL_EVAL_067)) +\n  geom_point(alpha = 0.1, size = 0.5, position = \"jitter\") +\n  labs(title = \"Highway Bridge Conditions, MA 2024\",\n       x = \"Year Built\", \n       y = \"Structural Evaluation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCautionEthical Considerations\n\n\n\nFederal regulations require that highway bridges and public road bridges in the United States must be inspected every two years, and bridge inspectors must follow a strict set of guidelines when performing a bridge inspection. If a bridge is discovered to have certain structural deficiencies, it may be shut down or may require more frequent inspections. Despite these widespread safety standards, we still sometimes see catastrophic bridge failures or discover critical bridge conditions that could potentially put lives at risk. This could result from human error, low vigilance or attention to detail during inspections, lack of understanding/adherence to inspection standards, or inspection equipment malfunctions. What kinds of interventions do you think should be put in place to ensure the accountability of bridge inspection data? What kinds of policies, practices, or programs could help to minimize mistakes or encourage that mistakes be fixed promptly? Share your ideas on our discussions Slack channel."
  },
  {
    "objectID": "schedule.html#week-5-visuals-data-wrangling-223---227",
    "href": "schedule.html#week-5-visuals-data-wrangling-223---227",
    "title": "Schedule",
    "section": "Week 5: Visuals, Data Wrangling (2/23 - 2/27)",
    "text": "Week 5: Visuals, Data Wrangling (2/23 - 2/27)\n\nMonday, 2/23Wednesday, 2/25Friday, 2/27\n\n\n\n\n\n\n\n\nNoteLecture: Wrapup on Visuals; Intro to Data Wrangling\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture: Data Wrangling\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLab #4: Plotting Frequencies and Distributions\n\n\n\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#last-time",
    "href": "lectures/w5l1_visualsWrangling.html#last-time",
    "title": "Data Visualization & Data Wrangling",
    "section": "Last Time",
    "text": "Last Time\n\nBox plots\n\nFive-number summaries\nAnalysis\n\nLine charts\n\nAcross time\n\nScatter plots\n\nCorrelation and trends"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#for-today",
    "href": "lectures/w5l1_visualsWrangling.html#for-today",
    "title": "Data Visualization & Data Wrangling",
    "section": "For Today",
    "text": "For Today\n\nAdvanced ggplot2\n\nOverplotting\nResources\n\nData wrangling\n\nWhat is it?\nThe six verbs"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#more-stuff-in-ggplot2",
    "href": "lectures/w5l1_visualsWrangling.html#more-stuff-in-ggplot2",
    "title": "Data Visualization & Data Wrangling",
    "section": "More Stuff in ggplot2",
    "text": "More Stuff in ggplot2\n\nWe’ve discussed the following:\n\nSyntax to plots in ggplot2\nUsing the 5 named graphs\nVarious edits\n\nLet’s explore the following:\n\nSpecific issues and tricks\nOther plots\nResources"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#dataset-for-today",
    "href": "lectures/w5l1_visualsWrangling.html#dataset-for-today",
    "title": "Data Visualization & Data Wrangling",
    "section": "Dataset for Today",
    "text": "Dataset for Today\n\nBoston Housing data\n\nvia the mlbench library\n506 observations, 14 variables\nEstimate median housing values through other variables\n\nCreate a new .qmd file and name the file w5l1_act.qmd. Use the following code:\n\n\nlibrary(mlbench)\nlibrary(ggplot2)\ndata(BostonHousing2)"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#overplotting",
    "href": "lectures/w5l1_visualsWrangling.html#overplotting",
    "title": "Data Visualization & Data Wrangling",
    "section": "Overplotting",
    "text": "Overplotting\nSuppose we have the following plot:\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point() + theme_minimal() +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\")"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#overplotting-solution-opacity",
    "href": "lectures/w5l1_visualsWrangling.html#overplotting-solution-opacity",
    "title": "Data Visualization & Data Wrangling",
    "section": "Overplotting Solution: Opacity",
    "text": "Overplotting Solution: Opacity\n\nAdjusting the opacity of the points\n\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point(alpha = 0.2) + theme_minimal() +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\")"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#overplotting-solution-jitter",
    "href": "lectures/w5l1_visualsWrangling.html#overplotting-solution-jitter",
    "title": "Data Visualization & Data Wrangling",
    "section": "Overplotting Solution: Jitter",
    "text": "Overplotting Solution: Jitter\n\nWe can add in small noise to separate out groupings\n\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1, height = 0.1, seed = 0)) + \n  theme_minimal() +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\")"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#thematic-elements",
    "href": "lectures/w5l1_visualsWrangling.html#thematic-elements",
    "title": "Data Visualization & Data Wrangling",
    "section": "Thematic Elements",
    "text": "Thematic Elements\n\n\nArguments\n\naxis.title.x\ntitle\naxis.ticks.x\naxis.line.x\nlegend.background\n…and more and more\n\n\nFunctions\n\nelement_blank()\nelement_text()\nelement_point()\nelement_geom()\n\n\nElements\n\ncolour\nsize\nhjust\nangle"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#sizing",
    "href": "lectures/w5l1_visualsWrangling.html#sizing",
    "title": "Data Visualization & Data Wrangling",
    "section": "Sizing",
    "text": "Sizing\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1, height = 0.1, seed = 0)) +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\") + theme_minimal() +\n  theme(plot.title = element_text(size = 15, colour = \"red\"))"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#intervals",
    "href": "lectures/w5l1_visualsWrangling.html#intervals",
    "title": "Data Visualization & Data Wrangling",
    "section": "Intervals",
    "text": "Intervals\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1, height = 0.1, seed = 0)) +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\") + theme_minimal() +\n  theme(plot.title = element_text(size = 15, colour = \"red\")) +\n   scale_x_continuous(breaks = seq(0, 100, by = 10))"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#label-angles",
    "href": "lectures/w5l1_visualsWrangling.html#label-angles",
    "title": "Data Visualization & Data Wrangling",
    "section": "Label Angles",
    "text": "Label Angles\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1, height = 0.1, seed = 0)) +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\") + theme_minimal() +\n  theme(plot.title = element_text(size = 15, colour = \"red\"),\n        axis.text.x = element_text(angle = 45)) +\n   scale_x_continuous(breaks = seq(0, 100, by = 10))"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#centering",
    "href": "lectures/w5l1_visualsWrangling.html#centering",
    "title": "Data Visualization & Data Wrangling",
    "section": "Centering",
    "text": "Centering\n\nggplot(BostonHousing2, aes(x = zn, y = medv)) +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1, height = 0.1, seed = 0)) +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       y = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       title = \"Prop. of Residential Land Zoned for Large Lots vs. Median Value\\nof Owner-Occupied Homes in Boston Census Tracts, 1970\") + theme_minimal() +\n  theme(plot.title = element_text(size = 15, colour = \"red\", hjust = 0.5),\n        axis.text.x = element_text(angle = 45)) +\n   scale_x_continuous(breaks = seq(0, 100, by = 10))"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#activity",
    "href": "lectures/w5l1_visualsWrangling.html#activity",
    "title": "Data Visualization & Data Wrangling",
    "section": "Activity",
    "text": "Activity\nIn the w5l1_act.qmd file:\n\nCreate a new code chunk and adjust the following plot you see below, using various items mentioned before:\n\n\nggplot(BostonHousing2, aes(x = medv, y = chas)) +\n  geom_boxplot() + theme_classic()"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#other-plots-density-plot",
    "href": "lectures/w5l1_visualsWrangling.html#other-plots-density-plot",
    "title": "Data Visualization & Data Wrangling",
    "section": "Other Plots!: Density Plot",
    "text": "Other Plots!: Density Plot\n\nSmoother form of histogram; provides density of the data\n\nHas relations to looking at pdfs in statistics courses!\n\n\n\nggplot(BostonHousing2, aes(x = zn)) +\n  geom_density() +\n  labs(x = \"Prop. of Residential Land Zoned for Lots &gt; 25,000 Sq. Ft.\",\n       title = \"Distribution of Proportion of Residential Land\\nZoned for Large Lots in Boston Census Tracts, 1970\") + theme_minimal()"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#other-plots-heat-map",
    "href": "lectures/w5l1_visualsWrangling.html#other-plots-heat-map",
    "title": "Data Visualization & Data Wrangling",
    "section": "Other Plots!: Heat Map",
    "text": "Other Plots!: Heat Map\n\nUsed to show values across a grid\n\nUseful for correlation matrices\n\n\n\nlibrary(reshape)\ncorData &lt;- cor(BostonHousing2[, 5:9])\ncorDataMelted &lt;- melt(corData)\n\nggplot(corDataMelted, aes(x = X1, y = X2, fill = value)) +\n  geom_tile() + xlab(\"\") + ylab(\"\") +\n  labs(title = \"Correlation Matrix of 5 Variables of Boston Census Tracts, 1970\",\n       fill = \"Correlation\") + theme_classic()"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#other-plots-violin-plot",
    "href": "lectures/w5l1_visualsWrangling.html#other-plots-violin-plot",
    "title": "Data Visualization & Data Wrangling",
    "section": "Other Plots!: Violin Plot",
    "text": "Other Plots!: Violin Plot\n\nClever way to show distribution across groups\n\n\nggplot(BostonHousing2, aes(x = medv, y = chas, fill = chas)) +\n  geom_violin() + theme_classic() +\n  labs(x = \"Median Value of Owner-Occupied Homes ($1000s)\",\n       y = \"Next to Charles River?\",\n       fill = \"Next to\\nCharles\\nRiver?\",\n       title = \"Median Value of Owner-Occupied Homes (in $1000s)\\nin Boston Census Tracts Near Charles River, 1970\")"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#resources",
    "href": "lectures/w5l1_visualsWrangling.html#resources",
    "title": "Data Visualization & Data Wrangling",
    "section": "Resources",
    "text": "Resources\n\nReference page online: link\nggplot 2 Textbook: link\n\n3rd edition is work in progress!\n\nCheatsheet: link"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#data-wrangling",
    "href": "lectures/w5l1_visualsWrangling.html#data-wrangling",
    "title": "Data Visualization & Data Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nA process for transforming a dataset from its original form into a more relevant form.\n\n\nSource: NAM-IT"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#data-is-messy",
    "href": "lectures/w5l1_visualsWrangling.html#data-is-messy",
    "title": "Data Visualization & Data Wrangling",
    "section": "Data is Messy!",
    "text": "Data is Messy!\n\nWe are messy\n\nData, processes, views, government\n\nQuestion: Think of 1-2 actions/situations that can result in issues with our data."
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#the-messiness",
    "href": "lectures/w5l1_visualsWrangling.html#the-messiness",
    "title": "Data Visualization & Data Wrangling",
    "section": "The Messiness",
    "text": "The Messiness\n - Our focus for today: transformation!"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#lets-tidy-the-data",
    "href": "lectures/w5l1_visualsWrangling.html#lets-tidy-the-data",
    "title": "Data Visualization & Data Wrangling",
    "section": "Let’s Tidy the Data!",
    "text": "Let’s Tidy the Data!\n\nOrder them by some metric\nSubset certain variables or observations based on some criteria\nCreate columns based on other variables\nSummarize data into meaningful tables"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#dplyr-the-grammar-of-data-manipulation",
    "href": "lectures/w5l1_visualsWrangling.html#dplyr-the-grammar-of-data-manipulation",
    "title": "Data Visualization & Data Wrangling",
    "section": "dplyr: The Grammar of Data Manipulation",
    "text": "dplyr: The Grammar of Data Manipulation\n\nManipulation is good!\n\n…well, in the context of data wrangling\n\ndplyr is an R package used for data manipulation\n\nCommon verbs used as function names for actions on data\nTo install: install.packages('dplyr')\n\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#the-piping-operator",
    "href": "lectures/w5l1_visualsWrangling.html#the-piping-operator",
    "title": "Data Visualization & Data Wrangling",
    "section": "The Piping Operator",
    "text": "The Piping Operator\n\n%&gt;% or |&gt;\n\nUseful when multiple actions are done on object in succession\n\n\n\nmean(mtcars$mpg)\n\n[1] 20.09062\n\nmtcars$mpg |&gt; mean()\n\n[1] 20.09062"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#motivating-dataset",
    "href": "lectures/w5l1_visualsWrangling.html#motivating-dataset",
    "title": "Data Visualization & Data Wrangling",
    "section": "Motivating Dataset",
    "text": "Motivating Dataset\n\nmidwest data set in ggplot2 package\n\n437 midwest counties with 28 variables\nDemographic information of midwest U.S. counties from 2000 U.S. census\n\n\n\nlibrary(tidyverse)\ndata(midwest)"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#lets-tidy-the-data---the-six-verbs",
    "href": "lectures/w5l1_visualsWrangling.html#lets-tidy-the-data---the-six-verbs",
    "title": "Data Visualization & Data Wrangling",
    "section": "Let’s Tidy the Data! - The Six Verbs",
    "text": "Let’s Tidy the Data! - The Six Verbs\n\nOrder them by some metric\n\narrange()\n\nSubset certain variables or observations based on some criteria\n\nselect() for variables, filter() for observations\n\nCreate columns based on other variables\n\nmutate()\n\nSummarize data into meaningful tables\n\nsummarize() and group_by()"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#arrange",
    "href": "lectures/w5l1_visualsWrangling.html#arrange",
    "title": "Data Visualization & Data Wrangling",
    "section": "arrange()",
    "text": "arrange()\n\narrange() sorts rows according to values in a column\n\nSorts in ascending order (numeric) or alphabetically (character).\ndesc() changes it to descending order\nAdditional arguments results in subsequent ordering\nBase R analog: sort()\n\n\n\nmidwest |&gt;\n  arrange(county) |&gt;\n  head()\n\n# A tibble: 6 × 28\n    PID county   state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   561 ADAMS    IL    0.052    66090      1271.    63917     1702            98\n2   663 ADAMS    IN    0.021    31095      1481.    30530       36            42\n3  2009 ADAMS    OH    0.035    25371       725.    25212       47            67\n4  2981 ADAMS    WI    0.041    15682       382.    15001      375           125\n5  1197 ALCONA   MI    0.041    10145       247.    10026       27            56\n6   562 ALEXAND… IL    0.014    10626       759      7054     3496            19\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#arrange-1",
    "href": "lectures/w5l1_visualsWrangling.html#arrange-1",
    "title": "Data Visualization & Data Wrangling",
    "section": "arrange()",
    "text": "arrange()\n\narrange() sorts rows according to values in a column\n\nSorts in ascending order (numeric) or alphabetically (character).\ndesc() changes it to descending order\nAdditional arguments results in subsequent ordering\nBase R analog: sort()\n\n\n\nmidwest |&gt;\n  arrange(state, county) |&gt;\n  head()\n\n# A tibble: 6 × 28\n    PID county   state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   561 ADAMS    IL    0.052    66090      1271.    63917     1702            98\n2   562 ALEXAND… IL    0.014    10626       759      7054     3496            19\n3   563 BOND     IL    0.022    14991       681.    14477      429            35\n4   564 BOONE    IL    0.017    30806      1812.    29344      127            46\n5   565 BROWN    IL    0.018     5836       324.     5264      547            14\n6   566 BUREAU   IL    0.05     35688       714.    35157       50            65\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#arrange-2",
    "href": "lectures/w5l1_visualsWrangling.html#arrange-2",
    "title": "Data Visualization & Data Wrangling",
    "section": "arrange()",
    "text": "arrange()\n\narrange() sorts rows according to values in a column\n\nSorts in ascending order (numeric) or alphabetically (character).\ndesc() changes it to descending order\nAdditional arguments results in subsequent ordering\nBase R analog: sort()\n\n\n\nmidwest |&gt;\n  arrange(desc(state), county) |&gt;\n  head()\n\n# A tibble: 6 × 28\n    PID county   state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1  2981 ADAMS    WI    0.041    15682       382.    15001      375           125\n2  2982 ASHLAND  WI    0.054    16307       302.    14749       17          1478\n3  2983 BARRON   WI    0.053    40750       769.    40346       40           209\n4  2984 BAYFIELD WI    0.089    14008       157.    12707       29          1240\n5  2985 BROWN    WI    0.032   194594      6081.   186621     1012          3869\n6  2986 BUFFALO  WI    0.04     13584       340.    13521        5            22\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#subsetting-data-select-filter",
    "href": "lectures/w5l1_visualsWrangling.html#subsetting-data-select-filter",
    "title": "Data Visualization & Data Wrangling",
    "section": "Subsetting data: select(), filter()",
    "text": "Subsetting data: select(), filter()\n\nSubsetting involves selecting relevant variables and observations for analysis"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#select",
    "href": "lectures/w5l1_visualsWrangling.html#select",
    "title": "Data Visualization & Data Wrangling",
    "section": "select()",
    "text": "select()\n\nSelect variables (columns) of interest\n\nEach argument is a variable to keep\nBase R analog: data[, c(\"var1\", \"var2\", ...)]"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#select-1",
    "href": "lectures/w5l1_visualsWrangling.html#select-1",
    "title": "Data Visualization & Data Wrangling",
    "section": "select()",
    "text": "select()\n\nSelect variables (columns) of interest\n\nEach argument is a variable to keep\nBase R analog: data[, c(\"var1\", \"var2\", ...)]\n\n\n\nmidwest |&gt;\n  select(county, state, poptotal, percbelowpoverty, percollege) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  county    state poptotal percbelowpoverty percollege\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 ADAMS     IL       66090            13.2        19.6\n2 ALEXANDER IL       10626            32.2        11.2\n3 BOND      IL       14991            12.1        17.0\n4 BOONE     IL       30806             7.21       17.3\n5 BROWN     IL        5836            13.5        14.5\n6 BUREAU    IL       35688            10.4        18.9"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#filter",
    "href": "lectures/w5l1_visualsWrangling.html#filter",
    "title": "Data Visualization & Data Wrangling",
    "section": "filter()",
    "text": "filter()\n\nRetrieves observations (rows) according to a certain criteria that we provide\n\nBased on value from another column, range of values from another continuous columns\nBase R analog: data[condition ,]"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#filter-1",
    "href": "lectures/w5l1_visualsWrangling.html#filter-1",
    "title": "Data Visualization & Data Wrangling",
    "section": "filter()",
    "text": "filter()\n\n== for matching; &gt;, &gt;=, &lt;, &lt;= for numeric cutoffs\n\n&, | for merging statements together\ne.g. only want Illinois counties with populations above 10,000\n\nstate == \"IL\" & poptotal &gt; 10000"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#aside-truth-tables",
    "href": "lectures/w5l1_visualsWrangling.html#aside-truth-tables",
    "title": "Data Visualization & Data Wrangling",
    "section": "Aside: truth tables",
    "text": "Aside: truth tables\n\nUsed for showing truth in compounded statements\n\nSeen in discrete math (and proofwriting)\n\n\n\n\n\n\n\nAnd (&)\n\n\n\n\n\n\nOr (|)\n\n\n\n\nSource: Millersville University"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#filter-2",
    "href": "lectures/w5l1_visualsWrangling.html#filter-2",
    "title": "Data Visualization & Data Wrangling",
    "section": "filter()",
    "text": "filter()\n\nRetrieves observations (rows) according to a certain criteria that we provide\n\nBased on value from another column, range of values from another continuous columns\ne.g. only want Illinois counties with populations above 10,000\n\n\n\nmidwest |&gt;\n  select(county, state, poptotal, percbelowpoverty, percollege) |&gt;\n  filter(state == \"IL\" & poptotal &gt; 10000) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  county    state poptotal percbelowpoverty percollege\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 ADAMS     IL       66090            13.2        19.6\n2 ALEXANDER IL       10626            32.2        11.2\n3 BOND      IL       14991            12.1        17.0\n4 BOONE     IL       30806             7.21       17.3\n5 BUREAU    IL       35688            10.4        18.9\n6 CARROLL   IL       16805            11.7        16.2"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#mutate",
    "href": "lectures/w5l1_visualsWrangling.html#mutate",
    "title": "Data Visualization & Data Wrangling",
    "section": "mutate()",
    "text": "mutate()\n\nCreates a new variable (column) in a data frame and fills values according to criteria we provide\nSet name equal to mutation\n\ne.g. newVar = oldVar / 10000\n\nUseful for:\n\nconsolidating grouped variables\ncreating dummy variables (i.e. discretizing)\n\nBase R analog: data$newVar = ..."
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#mutate-1",
    "href": "lectures/w5l1_visualsWrangling.html#mutate-1",
    "title": "Data Visualization & Data Wrangling",
    "section": "mutate()",
    "text": "mutate()\n\nCreates a new variable (column) in a data frame and fills values according to criteria we provide\nSet name equal to mutation\n\ne.g. proportion of high-school degree holders with college degrees\n\n\n\nmidwest |&gt;\n  mutate(propDegreeOfHS = percollege / perchsd) |&gt;\n  select(county, state, poptotal, propDegreeOfHS) |&gt;\n  head()\n\n# A tibble: 6 × 4\n  county    state poptotal propDegreeOfHS\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;          &lt;dbl&gt;\n1 ADAMS     IL       66090          0.261\n2 ALEXANDER IL       10626          0.188\n3 BOND      IL       14991          0.246\n4 BOONE     IL       30806          0.229\n5 BROWN     IL        5836          0.210\n6 BUREAU    IL       35688          0.247"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#aggregating-data-summarize-group_by",
    "href": "lectures/w5l1_visualsWrangling.html#aggregating-data-summarize-group_by",
    "title": "Data Visualization & Data Wrangling",
    "section": "Aggregating data: summarize(), group_by()",
    "text": "Aggregating data: summarize(), group_by()\n\nInvolves compiling and summarizing data"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#summarize",
    "href": "lectures/w5l1_visualsWrangling.html#summarize",
    "title": "Data Visualization & Data Wrangling",
    "section": "summarize()",
    "text": "summarize()\n\ncomputes a value across a vector of values and stores it in a new data frame\nBase R analog: any summary function (e.g. mean, nrow, max)"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#summarize-1",
    "href": "lectures/w5l1_visualsWrangling.html#summarize-1",
    "title": "Data Visualization & Data Wrangling",
    "section": "summarize()",
    "text": "summarize()\n\ncomputes a value across a vector of values and stores it in a new data frame\n\n\nmidwest |&gt;\n  summarize(numCounties = n(),\n            meanPercAsian = mean(percasian),\n            medianPercAsian = median(percasian))\n\n# A tibble: 1 × 3\n  numCounties meanPercAsian medianPercAsian\n        &lt;int&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1         437         0.487           0.297"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#group_by",
    "href": "lectures/w5l1_visualsWrangling.html#group_by",
    "title": "Data Visualization & Data Wrangling",
    "section": "group_by()",
    "text": "group_by()\n\nGroups observations with a shared value in a variable\n\nGrouping only changes the metadata of a data frame\nWe combine group_by() with other functions to transform the data frame\n\nValues remain in groups unless we ungroup() it\n\nTypically at end of piping sequence unless we use ungroup()\n\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  select(county, state, poptotal, percollege) |&gt;\n  head()\n\n# A tibble: 6 × 4\n# Groups:   state [1]\n  county    state poptotal percollege\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;      &lt;dbl&gt;\n1 ADAMS     IL       66090       19.6\n2 ALEXANDER IL       10626       11.2\n3 BOND      IL       14991       17.0\n4 BOONE     IL       30806       17.3\n5 BROWN     IL        5836       14.5\n6 BUREAU    IL       35688       18.9"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#group_by-summarize",
    "href": "lectures/w5l1_visualsWrangling.html#group_by-summarize",
    "title": "Data Visualization & Data Wrangling",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\n\ngroup_by() groups observations with a shared value in a variable\nWhen we combine group_by() and summarize(), we can perform operations within groups\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  summarize(numCounties = n(),\n            meanPercAsian = mean(percasian),\n            medianPercAsian = median(percasian))\n\n# A tibble: 5 × 4\n  state numCounties meanPercAsian medianPercAsian\n  &lt;chr&gt;       &lt;int&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 IL            102         0.564           0.278\n2 IN             92         0.383           0.254\n3 MI             83         0.507           0.310\n4 OH             88         0.433           0.353\n5 WI             72         0.556           0.286"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#group_by-filter",
    "href": "lectures/w5l1_visualsWrangling.html#group_by-filter",
    "title": "Data Visualization & Data Wrangling",
    "section": "group_by() |> filter()",
    "text": "group_by() |&gt; filter()\n\ngroup_by() groups observations with a shared value in a variable\nWhen we combine group_by() and filter() we can filter within groups\n\ne.g. filter counties based on their populations being higher than the state means\n\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  filter(poptotal &gt; mean(poptotal)) |&gt;\n  select(county, state, poptotal)\n\n# A tibble: 94 × 3\n# Groups:   state [5]\n   county    state poptotal\n   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;\n 1 CHAMPAIGN IL      173025\n 2 COOK      IL     5105067\n 3 DU PAGE   IL      781666\n 4 KANE      IL      317471\n 5 LAKE      IL      516418\n 6 MCHENRY   IL      183241\n 7 MCLEAN    IL      129180\n 8 MACON     IL      117206\n 9 MADISON   IL      249238\n10 PEORIA    IL      182827\n# ℹ 84 more rows"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#group_by-mutate",
    "href": "lectures/w5l1_visualsWrangling.html#group_by-mutate",
    "title": "Data Visualization & Data Wrangling",
    "section": "group_by() |> mutate()",
    "text": "group_by() |&gt; mutate()\n\ngroup_by() groups observations with a shared value in a variable\nWhen we combine group_by() and mutate() we can perform operations within groups and add the resulting variable to the data frame\n\ne.g. create column that shows how many SDs above or below mean of % with high school degree\n\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  mutate(sdHS = (perchsd - mean(perchsd)) / sd(perchsd)) |&gt;\n  select(county, state, poptotal, sdHS)\n\n# A tibble: 437 × 4\n# Groups:   state [5]\n   county    state poptotal   sdHS\n   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n 1 ADAMS     IL       66090  0.289\n 2 ALEXANDER IL       10626 -2.20 \n 3 BOND      IL       14991 -0.646\n 4 BOONE     IL       30806  0.349\n 5 BROWN     IL        5836 -0.722\n 6 BUREAU    IL       35688  0.536\n 7 CALHOUN   IL        5322 -1.70 \n 8 CARROLL   IL       16805  0.426\n 9 CASS      IL       13437 -0.170\n10 CHAMPAIGN IL      173025  2.30 \n# ℹ 427 more rows"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#ungroup",
    "href": "lectures/w5l1_visualsWrangling.html#ungroup",
    "title": "Data Visualization & Data Wrangling",
    "section": "ungroup()",
    "text": "ungroup()\n\nungroup() returns data frame object to focus on individual-level transformations\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  mutate(sdHS = (perchsd - mean(perchsd)) / sd(perchsd)) |&gt;\n  select(county, state, poptotal, sdHS) |&gt;\n  ungroup()\n\n# A tibble: 437 × 4\n   county    state poptotal   sdHS\n   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n 1 ADAMS     IL       66090  0.289\n 2 ALEXANDER IL       10626 -2.20 \n 3 BOND      IL       14991 -0.646\n 4 BOONE     IL       30806  0.349\n 5 BROWN     IL        5836 -0.722\n 6 BUREAU    IL       35688  0.536\n 7 CALHOUN   IL        5322 -1.70 \n 8 CARROLL   IL       16805  0.426\n 9 CASS      IL       13437 -0.170\n10 CHAMPAIGN IL      173025  2.30 \n# ℹ 427 more rows"
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#activity-1",
    "href": "lectures/w5l1_visualsWrangling.html#activity-1",
    "title": "Data Visualization & Data Wrangling",
    "section": "Activity",
    "text": "Activity\n\nWork through the w5l1_act.qmd file on Moodle\n\nWill center on the BostonHousing data frame\nUse code from this lecture to guide you through\nTurn in by the end of the period"
  },
  {
    "objectID": "lectures/w5l2_act.html",
    "href": "lectures/w5l2_act.html",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "",
    "text": "Use the following code below to load in the midwest data. Answer the following wrangling questions below:\n\nlibrary(tidyverse)\ndata(midwest)"
  },
  {
    "objectID": "lectures/w5l2_act.html#introduction",
    "href": "lectures/w5l2_act.html#introduction",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "",
    "text": "Use the following code below to load in the midwest data. Answer the following wrangling questions below:\n\nlibrary(tidyverse)\ndata(midwest)"
  },
  {
    "objectID": "lectures/w5l2_act.html#questions",
    "href": "lectures/w5l2_act.html#questions",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nImportantQuestion 1\n\n\n\nUsing the help documentation for midwest, identify variables related to the following:\n\ncounty name\nstate to which the county belongs to\npercent of population with known poverty status\npercent with professional degree\nwhether county is in metropolitan area\n\nOnce done, select those columns using dplyr functions.\n\n\n\n\n\n\n\n\nImportantQuestion 2\n\n\n\nWith the columns selected from Q1, arrange the dataset based on the percent of populace with a professional degree in descending order, followed by percent of populace with known poverty status in ascending order.\n\n\n\n\n\n\n\n\nImportantQuestion 3\n\n\n\nAdding to what was created in Q1, keep counties that are not in a metropolitan area and have less than 5% of the populace with a professional degree.\n\n\n\n\n\n\n\n\nImportantQuestion 4\n\n\n\nTack a new column named popProf that contains the number of people who have a professional degree. Then, show only the county, state, and new column.\nHint: You will need two variables from the dataset to do this operation.\n\n\n\n\n\n\n\n\nImportantQuestion 5\n\n\n\nCreate a table that shows the following metrics in each state:\n\nNumber of counties\nTotal population\nMedian percent with known poverty status\nProportion of counties that are in metro area"
  },
  {
    "objectID": "lectures/w5l2_act.html#turn-in",
    "href": "lectures/w5l2_act.html#turn-in",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "Turn-in",
    "text": "Turn-in\nSave the .qmd file inside your activities repository. Please stage, commit, and push to GitHub."
  },
  {
    "objectID": "lectures/w5l2_wrangling.html",
    "href": "lectures/w5l2_wrangling.html",
    "title": "Data Visualization & Data Wrangling",
    "section": "",
    "text": "Advanced ggplot2\n\nOverplotting\nResources\n\nData wrangling\n\nWhat is it?\nThe six verbs"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#last-time",
    "href": "lectures/w5l2_wrangling.html#last-time",
    "title": "Data Wrangling",
    "section": "Last Time",
    "text": "Last Time\n\nAdvanced ggplot2\n\nOverplotting\nResources\n\nData wrangling\n\nWhat is it?\nThe six verbs"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#for-today",
    "href": "lectures/w5l2_wrangling.html#for-today",
    "title": "Data Wrangling",
    "section": "For Today",
    "text": "For Today\n\nData wrangling\n\nOrdering\nSubsetting\nCreating\nSummarizing\n\nExamples"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#motivating-dataset",
    "href": "lectures/w5l2_wrangling.html#motivating-dataset",
    "title": "Data Wrangling",
    "section": "Motivating Dataset",
    "text": "Motivating Dataset\n\nmidwest data set in ggplot2 package\n\n437 midwest counties with 28 variables\nDemographic information of midwest U.S. counties from 2000 U.S. census\n\n\n\nlibrary(tidyverse)\ndata(midwest)"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#lets-tidy-the-data---the-six-verbs",
    "href": "lectures/w5l2_wrangling.html#lets-tidy-the-data---the-six-verbs",
    "title": "Data Wrangling",
    "section": "Let’s Tidy the Data! - The Six Verbs",
    "text": "Let’s Tidy the Data! - The Six Verbs\n\nOrder them by some metric\n\narrange()\n\nSubset certain variables or observations based on some criteria\n\nselect() for variables, filter() for observations\n\nCreate columns based on other variables\n\nmutate()\n\nSummarize data into meaningful tables\n\nsummarize() and group_by()"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#arrange",
    "href": "lectures/w5l2_wrangling.html#arrange",
    "title": "Data Wrangling",
    "section": "arrange()",
    "text": "arrange()\n\narrange() sorts rows according to values in a column\n\nSorts in ascending order (numeric) or alphabetically (character).\ndesc() changes it to descending order\nAdditional arguments results in subsequent ordering\nBase R analog: sort()\n\n\n\nmidwest |&gt;\n  arrange(county) |&gt;\n  head()\n\n# A tibble: 6 × 28\n    PID county   state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   561 ADAMS    IL    0.052    66090      1271.    63917     1702            98\n2   663 ADAMS    IN    0.021    31095      1481.    30530       36            42\n3  2009 ADAMS    OH    0.035    25371       725.    25212       47            67\n4  2981 ADAMS    WI    0.041    15682       382.    15001      375           125\n5  1197 ALCONA   MI    0.041    10145       247.    10026       27            56\n6   562 ALEXAND… IL    0.014    10626       759      7054     3496            19\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#arrange-1",
    "href": "lectures/w5l2_wrangling.html#arrange-1",
    "title": "Data Wrangling",
    "section": "arrange()",
    "text": "arrange()\n\narrange() sorts rows according to values in a column\n\nSorts in ascending order (numeric) or alphabetically (character).\ndesc() changes it to descending order\nAdditional arguments results in subsequent ordering\nBase R analog: sort()\n\n\n\nmidwest |&gt;\n  arrange(state, county) |&gt;\n  head()\n\n# A tibble: 6 × 28\n    PID county   state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   561 ADAMS    IL    0.052    66090      1271.    63917     1702            98\n2   562 ALEXAND… IL    0.014    10626       759      7054     3496            19\n3   563 BOND     IL    0.022    14991       681.    14477      429            35\n4   564 BOONE    IL    0.017    30806      1812.    29344      127            46\n5   565 BROWN    IL    0.018     5836       324.     5264      547            14\n6   566 BUREAU   IL    0.05     35688       714.    35157       50            65\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#arrange-2",
    "href": "lectures/w5l2_wrangling.html#arrange-2",
    "title": "Data Wrangling",
    "section": "arrange()",
    "text": "arrange()\n\narrange() sorts rows according to values in a column\n\nSorts in ascending order (numeric) or alphabetically (character).\ndesc() changes it to descending order\nAdditional arguments results in subsequent ordering\nBase R analog: sort()\n\n\n\nmidwest |&gt;\n  arrange(desc(state), county) |&gt;\n  head()\n\n# A tibble: 6 × 28\n    PID county   state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1  2981 ADAMS    WI    0.041    15682       382.    15001      375           125\n2  2982 ASHLAND  WI    0.054    16307       302.    14749       17          1478\n3  2983 BARRON   WI    0.053    40750       769.    40346       40           209\n4  2984 BAYFIELD WI    0.089    14008       157.    12707       29          1240\n5  2985 BROWN    WI    0.032   194594      6081.   186621     1012          3869\n6  2986 BUFFALO  WI    0.04     13584       340.    13521        5            22\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#subsetting-data-select-filter",
    "href": "lectures/w5l2_wrangling.html#subsetting-data-select-filter",
    "title": "Data Wrangling",
    "section": "Subsetting Data: select(), filter()",
    "text": "Subsetting Data: select(), filter()\n\nSubsetting involves selecting relevant variables and observations for analysis"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#select",
    "href": "lectures/w5l2_wrangling.html#select",
    "title": "Data Wrangling",
    "section": "select()",
    "text": "select()\n\nSelect variables (columns) of interest\n\nEach argument is a variable to keep\nBase R analog: data[, c(\"var1\", \"var2\", ...)]"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#select-1",
    "href": "lectures/w5l2_wrangling.html#select-1",
    "title": "Data Wrangling",
    "section": "select()",
    "text": "select()\n\nSelect variables (columns) of interest\n\nEach argument is a variable to keep\nBase R analog: data[, c(\"var1\", \"var2\", ...)]\n\n\n\nmidwest |&gt;\n  select(county, state, poptotal, percbelowpoverty, percollege) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  county    state poptotal percbelowpoverty percollege\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 ADAMS     IL       66090            13.2        19.6\n2 ALEXANDER IL       10626            32.2        11.2\n3 BOND      IL       14991            12.1        17.0\n4 BOONE     IL       30806             7.21       17.3\n5 BROWN     IL        5836            13.5        14.5\n6 BUREAU    IL       35688            10.4        18.9"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#filter",
    "href": "lectures/w5l2_wrangling.html#filter",
    "title": "Data Wrangling",
    "section": "filter()",
    "text": "filter()\n\nRetrieves observations (rows) according to a certain criteria that we provide\n\nBased on value from another column, range of values from another continuous columns\nBase R analog: data[condition ,]"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#filter-1",
    "href": "lectures/w5l2_wrangling.html#filter-1",
    "title": "Data Wrangling",
    "section": "filter()",
    "text": "filter()\n\n== for matching; &gt;, &gt;=, &lt;, &lt;= for numeric cutoffs\n\n&, | for merging statements together\ne.g. only want Illinois counties with populations above 10,000\n\nstate == \"IL\" & poptotal &gt; 10000"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#aside-truth-tables",
    "href": "lectures/w5l2_wrangling.html#aside-truth-tables",
    "title": "Data Wrangling",
    "section": "Aside: Truth Tables",
    "text": "Aside: Truth Tables\n\nUsed for showing truth in compounded statements\n\nSeen in discrete math (and proofwriting)\n\n\n\n\n\n\n\nAnd (&)\n\n\n\n\n\n\nOr (|)\n\n\n\n\nSource: Millersville University"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#filter-2",
    "href": "lectures/w5l2_wrangling.html#filter-2",
    "title": "Data Wrangling",
    "section": "filter()",
    "text": "filter()\n\nRetrieves observations (rows) according to a certain criteria that we provide\n\nBased on value from another column, range of values from another continuous columns\ne.g. only want Illinois counties with populations above 10,000\n\n\n\nmidwest |&gt;\n  select(county, state, poptotal, percbelowpoverty, percollege) |&gt;\n  filter(state == \"IL\" & poptotal &gt; 10000) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  county    state poptotal percbelowpoverty percollege\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 ADAMS     IL       66090            13.2        19.6\n2 ALEXANDER IL       10626            32.2        11.2\n3 BOND      IL       14991            12.1        17.0\n4 BOONE     IL       30806             7.21       17.3\n5 BUREAU    IL       35688            10.4        18.9\n6 CARROLL   IL       16805            11.7        16.2"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#mutate",
    "href": "lectures/w5l2_wrangling.html#mutate",
    "title": "Data Wrangling",
    "section": "mutate()",
    "text": "mutate()\n\nCreates a new variable (column) in a data frame and fills values according to criteria we provide\nSet name equal to mutation\n\ne.g. newVar = oldVar / 10000\n\nUseful for:\n\nconsolidating grouped variables\ncreating dummy variables (i.e. discretizing)\n\nBase R analog: data$newVar = ..."
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#mutate-1",
    "href": "lectures/w5l2_wrangling.html#mutate-1",
    "title": "Data Wrangling",
    "section": "mutate()",
    "text": "mutate()\n\nCreates a new variable (column) in a data frame and fills values according to criteria we provide\nSet name equal to mutation\n\ne.g. proportion of high-school degree holders with college degrees\n\n\n\nmidwest |&gt;\n  mutate(propDegreeOfHS = percollege / perchsd) |&gt;\n  select(county, state, poptotal, propDegreeOfHS) |&gt;\n  head()\n\n# A tibble: 6 × 4\n  county    state poptotal propDegreeOfHS\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;          &lt;dbl&gt;\n1 ADAMS     IL       66090          0.261\n2 ALEXANDER IL       10626          0.188\n3 BOND      IL       14991          0.246\n4 BOONE     IL       30806          0.229\n5 BROWN     IL        5836          0.210\n6 BUREAU    IL       35688          0.247"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#aggregating-data-summarize-group_by",
    "href": "lectures/w5l2_wrangling.html#aggregating-data-summarize-group_by",
    "title": "Data Wrangling",
    "section": "Aggregating Data: summarize(), group_by()",
    "text": "Aggregating Data: summarize(), group_by()\n\nInvolves compiling and summarizing data"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#summarize",
    "href": "lectures/w5l2_wrangling.html#summarize",
    "title": "Data Wrangling",
    "section": "summarize()",
    "text": "summarize()\n\ncomputes a value across a vector of values and stores it in a new data frame\nBase R analog: any summary function (e.g. mean, nrow, max)"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#summarize-1",
    "href": "lectures/w5l2_wrangling.html#summarize-1",
    "title": "Data Wrangling",
    "section": "summarize()",
    "text": "summarize()\n\ncomputes a value across a vector of values and stores it in a new data frame\n\n\nmidwest |&gt;\n  summarize(numCounties = n(),\n            meanPercAsian = mean(percasian),\n            medianPercAsian = median(percasian))\n\n# A tibble: 1 × 3\n  numCounties meanPercAsian medianPercAsian\n        &lt;int&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1         437         0.487           0.297"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#group_by",
    "href": "lectures/w5l2_wrangling.html#group_by",
    "title": "Data Wrangling",
    "section": "group_by()",
    "text": "group_by()\n\nGroups observations with a shared value in a variable\n\nGrouping only changes the metadata of a data frame\nWe combine group_by() with other functions to transform the data frame\n\nValues remain in groups unless we ungroup() it\n\nTypically at end of piping sequence unless we use ungroup()\n\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  select(county, state, poptotal, percollege) |&gt;\n  head()\n\n# A tibble: 6 × 4\n# Groups:   state [1]\n  county    state poptotal percollege\n  &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;      &lt;dbl&gt;\n1 ADAMS     IL       66090       19.6\n2 ALEXANDER IL       10626       11.2\n3 BOND      IL       14991       17.0\n4 BOONE     IL       30806       17.3\n5 BROWN     IL        5836       14.5\n6 BUREAU    IL       35688       18.9"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#group_by-summarize",
    "href": "lectures/w5l2_wrangling.html#group_by-summarize",
    "title": "Data Wrangling",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\n\ngroup_by() groups observations with a shared value in a variable\nWhen we combine group_by() and summarize(), we can perform operations within groups\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  summarize(numCounties = n(),\n            meanPercAsian = mean(percasian),\n            medianPercAsian = median(percasian))\n\n# A tibble: 5 × 4\n  state numCounties meanPercAsian medianPercAsian\n  &lt;chr&gt;       &lt;int&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 IL            102         0.564           0.278\n2 IN             92         0.383           0.254\n3 MI             83         0.507           0.310\n4 OH             88         0.433           0.353\n5 WI             72         0.556           0.286"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#group_by-filter",
    "href": "lectures/w5l2_wrangling.html#group_by-filter",
    "title": "Data Wrangling",
    "section": "group_by() |> filter()",
    "text": "group_by() |&gt; filter()\n\ngroup_by() groups observations with a shared value in a variable\nWhen we combine group_by() and filter() we can filter within groups\n\ne.g. filter counties based on their populations being higher than the state means\n\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  filter(poptotal &gt; mean(poptotal)) |&gt;\n  select(county, state, poptotal)\n\n# A tibble: 94 × 3\n# Groups:   state [5]\n   county    state poptotal\n   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;\n 1 CHAMPAIGN IL      173025\n 2 COOK      IL     5105067\n 3 DU PAGE   IL      781666\n 4 KANE      IL      317471\n 5 LAKE      IL      516418\n 6 MCHENRY   IL      183241\n 7 MCLEAN    IL      129180\n 8 MACON     IL      117206\n 9 MADISON   IL      249238\n10 PEORIA    IL      182827\n# ℹ 84 more rows"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#group_by-mutate",
    "href": "lectures/w5l2_wrangling.html#group_by-mutate",
    "title": "Data Wrangling",
    "section": "group_by() |> mutate()",
    "text": "group_by() |&gt; mutate()\n\ngroup_by() groups observations with a shared value in a variable\nWhen we combine group_by() and mutate() we can perform operations within groups and add the resulting variable to the data frame\n\ne.g. create column that shows how many SDs above or below mean of % with high school degree\n\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  mutate(sdHS = (perchsd - mean(perchsd)) / sd(perchsd)) |&gt;\n  select(county, state, poptotal, sdHS)\n\n# A tibble: 437 × 4\n# Groups:   state [5]\n   county    state poptotal   sdHS\n   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n 1 ADAMS     IL       66090  0.289\n 2 ALEXANDER IL       10626 -2.20 \n 3 BOND      IL       14991 -0.646\n 4 BOONE     IL       30806  0.349\n 5 BROWN     IL        5836 -0.722\n 6 BUREAU    IL       35688  0.536\n 7 CALHOUN   IL        5322 -1.70 \n 8 CARROLL   IL       16805  0.426\n 9 CASS      IL       13437 -0.170\n10 CHAMPAIGN IL      173025  2.30 \n# ℹ 427 more rows"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#ungroup",
    "href": "lectures/w5l2_wrangling.html#ungroup",
    "title": "Data Wrangling",
    "section": "ungroup()",
    "text": "ungroup()\n\nungroup() returns data frame object to focus on individual-level transformations\n\n\nmidwest |&gt;\n  group_by(state) |&gt;\n  mutate(sdHS = (perchsd - mean(perchsd)) / sd(perchsd)) |&gt;\n  select(county, state, poptotal, sdHS) |&gt;\n  ungroup()\n\n# A tibble: 437 × 4\n   county    state poptotal   sdHS\n   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n 1 ADAMS     IL       66090  0.289\n 2 ALEXANDER IL       10626 -2.20 \n 3 BOND      IL       14991 -0.646\n 4 BOONE     IL       30806  0.349\n 5 BROWN     IL        5836 -0.722\n 6 BUREAU    IL       35688  0.536\n 7 CALHOUN   IL        5322 -1.70 \n 8 CARROLL   IL       16805  0.426\n 9 CASS      IL       13437 -0.170\n10 CHAMPAIGN IL      173025  2.30 \n# ℹ 427 more rows"
  },
  {
    "objectID": "lectures/w5l2_wrangling.html#activity",
    "href": "lectures/w5l2_wrangling.html#activity",
    "title": "Data Wrangling",
    "section": "Activity",
    "text": "Activity\n\nWork through the w5l2_act.qmd file on Moodle\n\nWill center on the midwest data frame\nUse code from this lecture to guide you through\nTurn in by the end of the period"
  },
  {
    "objectID": "lectures/w5l2_actTemp.html",
    "href": "lectures/w5l2_actTemp.html",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "",
    "text": "Use the following code below to load in the midwest data. Answer the following wrangling questions below:\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata(midwest)"
  },
  {
    "objectID": "lectures/w5l2_actTemp.html#introduction",
    "href": "lectures/w5l2_actTemp.html#introduction",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "",
    "text": "Use the following code below to load in the midwest data. Answer the following wrangling questions below:\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata(midwest)"
  },
  {
    "objectID": "lectures/w5l2_actTemp.html#questions",
    "href": "lectures/w5l2_actTemp.html#questions",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nImportantQuestion 1\n\n\n\nUsing the help documentation for midwest, identify variables related to the following:\n\ncounty name\nstate to which the county belongs to\npercent of population with known poverty status\npercent with professional degree\nwhether county is in metropolitan area\n\nOnce done, select those columns using dplyr functions.\n\n# PUT SOLUTION HERE\n\n\n\n\n\n\n\n\n\nImportantQuestion 2\n\n\n\nWith the columns selected from Q1, arrange the dataset based on the percent of populace with a professional degree in descending order, followed by percent of populace with known poverty status in ascending order.\n\n# PUT SOLUTION HERE\n\n\n\n\n\n\n\n\n\nImportantQuestion 3\n\n\n\nAdding to what was created in Q1, keep counties that are not in a metropolitan area and have less than 5% of the populace with a professional degree.\n\n# PUT SOLUTION HERE\n\n\n\n\n\n\n\n\n\nImportantQuestion 4\n\n\n\nTack a new column named popProf that contains the number of people who have a professional degree. Then, show only the county, state, and new column.\nHint: You will need two variables from the dataset to do this operation.\n\n# PUT SOLUTION HERE\n\n\n\n\n\n\n\n\n\nImportantQuestion 5\n\n\n\nCreate a table that shows the following metrics in each state:\n\nNumber of counties\nTotal population\nMedian percent with known poverty status\nProportion of counties that are in metro area\n\n\n# PUT SOLUTION HERE"
  },
  {
    "objectID": "lectures/w5l2_actTemp.html#turn-in",
    "href": "lectures/w5l2_actTemp.html#turn-in",
    "title": "Week 5, Lecture 2: Data Wrangling",
    "section": "Turn-in",
    "text": "Turn-in\nSave the .qmd file inside your activities repository. Please stage, commit, and push to GitHub."
  },
  {
    "objectID": "lectures/w5l1_visualsWrangling.html#for-now-and-wednesday",
    "href": "lectures/w5l1_visualsWrangling.html#for-now-and-wednesday",
    "title": "Data Visualization & Data Wrangling",
    "section": "For Now and Wednesday",
    "text": "For Now and Wednesday\n\nFinish activity for today’s class\nLab #3 due Wednesday at 11:59pm"
  },
  {
    "objectID": "labs/lab4/index.html",
    "href": "labs/lab4/index.html",
    "title": "Lab #4: Visualization Aesthetics (30 pts)",
    "section": "",
    "text": "Read the ggplot cheatsheets\nProduce and interpret univariate plots\nProduce and interpret multivariate plots\nSummarize and interpret variation and co-variation from observation of plots\nContextualize plots with descriptive labels and titles"
  },
  {
    "objectID": "labs/lab4/index.html#introduction",
    "href": "labs/lab4/index.html#introduction",
    "title": "Lab #4: Visualization Aesthetics (30 pts)",
    "section": "",
    "text": "Read the ggplot cheatsheets\nProduce and interpret univariate plots\nProduce and interpret multivariate plots\nSummarize and interpret variation and co-variation from observation of plots\nContextualize plots with descriptive labels and titles"
  },
  {
    "objectID": "labs/lab4/index.html#review-of-key-terms",
    "href": "labs/lab4/index.html#review-of-key-terms",
    "title": "Lab #4: Visualization Aesthetics (30 pts)",
    "section": "Review of Key Terms",
    "text": "Review of Key Terms\n\nMultivariate Plots\n\nPlots that summarize and visualize the distribution and relationship between multiple variables\n\nUnivariate Plots\n\nPlots that summarize and visualize the distribution of a single variable\n\nVariation\n\nThe degree to which categorical or numeric values vary across data"
  },
  {
    "objectID": "labs/lab4/index.html#home-mortgage-disclosure-act-hmda",
    "href": "labs/lab4/index.html#home-mortgage-disclosure-act-hmda",
    "title": "Lab #4: Visualization Aesthetics (30 pts)",
    "section": "Home Mortgage Disclosure Act (HMDA)",
    "text": "Home Mortgage Disclosure Act (HMDA)\nIn the United States, homeownership can offer a pathway to promoting stability and social mobility. However, historically, opportunities for purchasing a home have been unequally distributed along racial and ethnic lines. In a practice known as redlining, some banks in the mid-twentieth century would make decisions about who would be approved for loans based on the perceived “riskiness” of the neighborhoods they lived in; risk was often determined by the racial makeup of the neighborhood. This discrimination in lending enforced the racial segregation of communities and made it much more difficult for Black and other minority individuals to secure access to a financial asset that could be passed down in their families. With limited access to this opportunity for securing generational wealth, we still feel the affects of redlining today - even though racially-motivated redlining was prohibited by the Fair Housing Act in 1968.\nIn order to monitor for fair lending practices, in 1975, the Home Mortgage Disclosure Act was passed, requiring lending institutions to publicly disclose data about their lending - reporting each loan application they receive, whether the loan was approved or denied, and demographic information on the borrowers. This data is currently published annually by the Consumer Federal Protection Bureau, and a number of organizations monitor it to determine if there are continued forms of racial discrimination in who has access to home loans.\nIn this lab, we are going to examine Home Mortgage Disclosure Act data from 2024 in Mississippi. Recently, a study by Lending Tree showed that Black homebuyers in Mississippi face some of the highest loan denial rates in the country:\n\n\nEach row in this dataset is one mortgage application, and variables describing the demographics of the applicant, details about the loan, and whether or not the loan was approved are included in the data. When denied, the reasons for denial are also included. For consistency in comparisons, I’ve filtered this dataset down to only include 30-year conventional, first-lien, single-family, non-commercial loans that are either for a home purchase or a home improvement. The data documentation for this dataset is quite thick, so I will provide you with a data dictionary for today.\n\n\n\n\n\n\n\nVARIABLE NAME\nDESCRIPTION\n\n\n\n\nderived_ethnicity\nSingle aggregated ethnicity categorization derived from applicant/borrower and co-applicant/co-borrower ethnicity fields\n\n\nderived_race\nSingle aggregated race categorization derived from applicant/borrower and co-applicant/co-borrower race fields\n\n\nderived_sex\nSingle aggregated sex categorization derived from applicant/borrower and co-applicant/co-borrower sex fields\n\n\naction_taken\nThe action taken on the covered loan or application\n\n\nloan_purpose\nThe purpose of covered loan or application\n\n\nloan_amount\nThe amount of the covered loan, or the amount applied for\n\n\nloan_to_value_ratio\nThe ratio of the total amount of debt secured by the property to the value of the property relied on in making the credit decision\n\n\nincome\nThe gross annual income, in thousands of dollars, relied on in making the credit decision, or if a credit decision was not made, the gross annual income relied on in processing the application\n\n\ndebt_to_income_ratio\nThe ratio, as a percentage, of the applicant’s or borrower’s total monthly debt to the total monthly income relied on in making the credit decision\n\n\ntract_minority_population_percent\nPercentage of minority population to total population for tract, rounded to two decimal places\n\n\ndenial_reason\nThe principal reason, or reasons, for denial"
  },
  {
    "objectID": "labs/lab4/index.html#setting-up-your-environment",
    "href": "labs/lab4/index.html#setting-up-your-environment",
    "title": "Lab #4: Visualization Aesthetics (30 pts)",
    "section": "Setting Up Your Environment",
    "text": "Setting Up Your Environment\n\nRun the code below to the import the 2024 Home Mortgage Disclosure Act data for Mississippi into R. It may take a few moments to load. Call me or one of the data assistants over if you get an error.\n\n\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\nhmda_ms_2024 &lt;- read.csv(\"https://ffiec.cfpb.gov/v2/data-browser-api/view/csv?states=MS&years=2024\") |&gt;\n  filter(loan_type == 1 & \n           lien_status == 1 & \n           conforming_loan_limit == 'C' & \n           derived_dwelling_category %in% c(\"Single Family (1-4 Units):Site-Built\", \n                                            \"Single Family (1-4 Units):Manufactured\") & \n           business_or_commercial_purpose == 2 &\n           loan_purpose %in% c(1, 2)) |&gt;\n  select(lei,\n         county_code,\n         derived_ethnicity,\n         derived_race,\n         derived_sex,\n         action_taken,\n         loan_purpose,\n         loan_amount,\n         interest_rate,\n         property_value,\n         loan_to_value_ratio,\n         denial_reason.1,\n         denial_reason.2,\n         denial_reason.3,\n         denial_reason.4,\n         income,\n         debt_to_income_ratio) |&gt;\n  mutate(loan_purpose = recode(loan_purpose, \n                               \"1\" = \"Home Purchase\",\n                               \"2\" = \"Home improvement\",\n                               .default = NA_character_)) |&gt;\n  mutate(action_taken = recode(action_taken, \n                               \"1\" = \"Loan originated\", \n                               \"2\" = \"Application approved but not accepted\",\n                               \"3\" = \"Application denied\",\n                               \"4\" = \"Application withdrawn by applicant\",\n                               \"5\" = \"File closed for incompleteness\",\n                               \"6\" = \"Purchased loan\",\n                               \"7\" = \"Preapproval request denied\",\n                               \"8\" = \"Preapproval request approved but not accepted\",\n                               .default = NA_character_)) |&gt;\n  mutate(denial_reason.1 = recode(denial_reason.1, \n                                  \"1\" = \"Debt-to-income ratio\",\n                                  \"2\" = \"Employment history\",\n                                  \"3\" = \"Credit history\",\n                                  \"4\" = \"Collateral\",\n                                  \"5\" = \"Insufficient cash (downpayment, closing costs)\",\n                                  \"6\" = \"Unverifiable information\",\n                                  \"7\" = \"Credit application incomplete\",\n                                  \"8\" = \"Mortgage insurance denied\",\n                                  \"9\" = \"Other\",\n                                  \"10\" = \"Not applicable\",\n                               .default = NA_character_)) |&gt;\n  rowwise() |&gt;\n  mutate(denial_reason = case_when(any(!is.na(c_across(c(denial_reason.2,\n                                                         denial_reason.3,\n                                                         denial_reason.4)))) ~ \"Multiple\",\n      TRUE ~ denial_reason.1)) |&gt;\n  ungroup() |&gt;\n  mutate(loan_to_value_ratio = as.numeric(loan_to_value_ratio),\n         property_value = as.numeric(property_value)) |&gt;\n  mutate(debt_to_income_ratio = case_when(debt_to_income_ratio %in% c(\"36\", \"37\", \"38\",\"39\",\"40\",\"41\") ~ \"36%-41%\",\n                                          debt_to_income_ratio %in% c(\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\") ~ \"42%-49%\",\n                                          TRUE ~ debt_to_income_ratio)) |&gt;\n  mutate(debt_to_income_ratio = factor(debt_to_income_ratio, levels = c(\"Exempt\",\n                                                                        \"&lt;20%\",\n                                                                        \"20%-&lt;30%\",\n                                                                        \"30%-&lt;36%\",\n                                                                        \"36%-41%\",\n                                                                        \"42%-49%\",\n                                                                        \"50%-60%\",\n                                                                        \"&gt;60%\"))) |&gt;\n  select(-c(denial_reason.1, \n            denial_reason.2, \n            denial_reason.3, \n            denial_reason.4))\n\nWe’re going to start our analysis with univariate plotting. Specifically, we are going to produce data visualizations that count the number of observations in a dataset that fall into specific groupings. When grouping observations by a categorical variable, we will produce a bar plot. Remember when labeling that these plots visualize frequency. They use the height aesthetic to visualize us how many rows in a variable have a certain value.\nLet’s start by comparing how many home loans were for home purchases vs. the number for home improvements.\n\n\n\n\n\n\nImportantQuestion 1 (2.5 pts)\n\n\n\nIn the code below, create a bar plot that visualizes how many home loans were for home purchases vs. the number for home improvements. Determine the variable that should appear on the x-axis, along with the geom function that can be used to create a bar plot. Fill in the blanks to ensure your plot has the appropriate context.\n\nhmda_ms_2024 |&gt;\n  ggplot(aes(x = _____)) +\n  _____() +\n  labs(title = \"Home Mortgage Disclosure Act Applications, [FILL GEOGRAPHY], [FILL YEAR]\",\n       x = \"[FILL X-AXIS VARIABLE]\",\n       y = \"Count of [FILL WHAT's BEING COUNTED?]\") +\n  theme_minimal()\n\n\n\nNow let’s look at the number of applicants of each race.\n\n\n\n\n\n\nImportantQuestion 2 (2.5 pts)\n\n\n\nCreate a plot below that counts the number of applicants of each race. Be sure to give it a descriptive title and labels covering all 5 essential components of data context. You can use the code you wrote above as a template to get you started. You’ll probably notice that the labels of your plot overlap. You can add + coord_flip() to the end of your code to flip the plot so that the bars are horizontal rather than vertical. This should help with legibility.\n\n# Create plot here\n\n\n\nIn the last plot, we visualized the frequency of a categorical variable. When grouping observations into intervals of a numeric variable, we will produce a histogram. For instance, let’s say we want to know the distribution of loan amounts that applicants requested in Mississippi in 2024. With a histogram, I can visualize how many loan applications requested $0-$100000, &gt;$100000-$200000, and so on. Histograms use the height aesthetic to visualize how many rows in a variable fall into each of these numeric bins.\n\n\n\n\n\n\nImportantQuestion 3 (2.5 pts)\n\n\n\nIn the code below, create a histogram that visualizes the distribution of loan amounts. Determine the variable that should appear on the x-axis, along with the geom function that can be used to create a histogram. Set the binwidth to create numeric intervals of 100000. Fill in the blanks to ensure your plot has the appropriate context.\n\nhmda_ms_2024  |&gt; \n  ggplot(aes(x = _____)) +\n  _____(binwidth = _____) +\n  labs(title = \"Home Mortgage Disclosure Act Applications, [FILL GEOGRAPHY], [FILL YEAR]\",\n       x = \"[FILL X-AXIS VARIABLE]\",\n       y = \"Count of [FILL WHAT's BEING COUNTED?]\",\n       caption = str_wrap(\"This histogram displays the distribution of home loan amounts requested by Mississippi applicants in 2024. The plot shows that the majority of applicants requested loans under $250,000. Since the average home loan size in the U.S. in 2024 was $252,505, this indicates that average requested home loan sizes in MS were smaller in comparison to the country as a whole.\", 120)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nA good plot caption does three things. First, it describes what the plot is and the variables displayed on it. Second, it articulates at least one fact from the plot. Third, it interprets the significance of that fact. The caption that I provided for the last plot follows this template:\n(describe) This histogram displays the distribution of home loan amounts requested by Mississippi applicants in 2024. (articulate fact) The plot shows that the majority of applicants requested loans under $250,000. (interpret significance) Since the average home loan size in the U.S. in 2024 was $252,505, this indicates that average requested home loan sizes in MS were smaller in comparison to the country as a whole.\n\n\nLoan to value ratio is a measure that indicates the percentage of a property’s value that a borrower requests of a lending institution. So let’s say I want to buy a property with a value of $100,000; I plan to put down $20,000, and I request a loan for $80,000. The loan to value ratio would be 80. Typically, when borrowers can put more down, it is considered a less risky loan.\n\n\n\n\n\n\nImportantQuestion 4 (2.5 pts)\n\n\n\nCreate a plot below that shows the distribution of loan to value ratios (in intervals of 10). Be sure to give it a descriptive title and labels covering all 5 essential components of data context. Also add a caption to describe the percentage of a loan’s property that borrowers most often request when applying for a loan.\nYou can use the code you wrote above as a template to get you started. Note that there were 20 outlier loans where borrowers requested more than double property’s value. There was even one loan where the applicant requested 14 times the property’s value. All of these loans were denied. Below I’ve given you some code to filter out these outliers in order to make the plot more legible.\n\nhmda_ms_2024 |&gt;\n  filter(loan_to_value_ratio &lt; 200) |&gt;\n# Fill remaining lines here\n\n\n\nLet’s move on to some multivariate plotting. Remember that we can add further variables to a plot via a number of different aesthetics (e.g. color: fill= or col=; size: size=; position: x= or y=, small multiples: + facet_wrap(vars(...)) ). Whenever we add further data to a plot, we should be on the lookout for overplotting.\n\n\n\n\n\n\nImportantQuestion 5 (2.5 pts)\n\n\n\nCreate a stacked barplot below that counts both the race of the applicants and the action taken in regards to the loan. Be sure to give it a descriptive title and labels covering all 5 essential components of data context. I’ve given you some code below to move the legend to the bottom of the plot, to reduce the legend size, and to set the number of rows that appear in the legend.\n\nhmda_ms_2024 |&gt;\n# Fill remaining lines here\n  coord_flip() +\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 6), \n        legend.title = element_text(size = 8),\n        legend.key.size = unit(0.4, \"cm\")) +\n  guides(fill=guide_legend(nrow=4))\n\n\n\nWe learned earlier in this lab that there were more white applicants than applicants of other races applying for loans in Mississippi in 2024. If we only look at counts of approvals or denials then we don’t know if differences in approval numbers are due to disparities in who is getting loans or due to there just being more applicants of a particular race. For this reason, we are more interested in the percentage of approvals for each race and the percentage of denials for each race. This is more comparable across races than counts.\n\n\n\n\n\n\nImportantQuestion 6 (2.5 pts)\n\n\n\nCopy the plot that you created above into the code chunk below, and then adjust the position of the bars to “fill” in order to normalize their height. Add a caption that summarizes your findings.\n\n# Create plot here\n\n\n\nNow let’s move on to comparing how requested loan amounts differ across race. To do so, we are going to create a boxplot that compares summary statistics (i.e. minimum, maximum, median, 1st quartile, 3rd quartile, and outliers) of the loan amounts requested by applicants of each race.\n\n\n\n\n\n\nImportantQuestion 7 (2.5 pts)\n\n\n\nFill in the code below to create a boxplot that visualizes how the distributions of requested loan amounts differed across race. Add a caption that summarizes your findings.\n\nhmda_ms_2024 |&gt;\n  ggplot(aes(x = derived_race, __________)) +\n  __________ +\n  coord_flip() +\n  labs(title = \"Home Mortgage Disclosure Act Applications, Mississippi, 2024\",\n       x = \"Race of Applicant\",\n       y = _________,\n       caption = _________) +\n  theme_minimal() \n\n\n\nIn the past several exercises, we have been creating plots that count the number of rows in a variable have a certain value. …but what if our dataset presents aggregated data - where those counts have already been given to us? For instance, I wrote some code below to create a dataset where the counts of individuals of each race that were denied loans is already calculated, along with the percentage of individuals that were denied loans. I also created a dataset where the counts of individuals of each race and sex that were denied loans is already calculated, along with the percentage. You’ll learn more about these functions in a few weeks. Take a look at these datasets below, and consider how they compare them to the data that we started with.\n\nhmda_denial_by_race &lt;-\n  hmda_ms_2024 |&gt;\n  group_by(derived_race) |&gt;\n  summarize(total_denied = sum(action_taken == \"Application denied\"),\n            percent_denied = sum(action_taken == \"Application denied\")/n())\n\nhmda_denial_by_race_sex &lt;-\n  hmda_ms_2024 |&gt;\n  filter(derived_race != \"Free Form Text Only\") |&gt; #There were only 3 denials with free form text for race in MS in 2024, and they have been removed here for plot legibility\n  group_by(derived_race, derived_sex) |&gt;\n  summarize(total_denied = sum(action_taken == \"Application denied\"),\n            percent_denied = sum(action_taken == \"Application denied\")/n())\n\nhmda_denial_by_race\n\n# A tibble: 9 × 3\n  derived_race                              total_denied percent_denied\n  &lt;chr&gt;                                            &lt;int&gt;          &lt;dbl&gt;\n1 2 or more minority races                            33          0.516\n2 American Indian or Alaska Native                    49          0.476\n3 Asian                                               78          0.162\n4 Black or African American                         4643          0.478\n5 Free Form Text Only                                  3          1    \n6 Joint                                              114          0.317\n7 Native Hawaiian or Other Pacific Islander           10          0.233\n8 Race Not Available                                 615          0.103\n9 White                                             3954          0.225\n\nhmda_denial_by_race_sex\n\n# A tibble: 31 × 4\n# Groups:   derived_race [8]\n   derived_race                     derived_sex      total_denied percent_denied\n   &lt;chr&gt;                            &lt;chr&gt;                   &lt;int&gt;          &lt;dbl&gt;\n 1 2 or more minority races         Female                     15          0.556\n 2 2 or more minority races         Joint                       6          0.429\n 3 2 or more minority races         Male                        8          0.471\n 4 2 or more minority races         Sex Not Availab…            4          0.667\n 5 American Indian or Alaska Native Female                     20          0.476\n 6 American Indian or Alaska Native Joint                       7          0.778\n 7 American Indian or Alaska Native Male                       21          0.429\n 8 American Indian or Alaska Native Sex Not Availab…            1          0.333\n 9 Asian                            Female                     20          0.149\n10 Asian                            Joint                      16          0.139\n# ℹ 21 more rows\n\n\nWhen counts have already been calculated for us, we need to use a different type of plot to visualize these counts. We don’t need the plot function to count the rows with each value; we just need it to set the height of the bar to a numeric value provided in our dataset. We will create column plots below to do this.\n\n\n\n\n\n\nImportantQuestion 8 (2.5 pts)\n\n\n\nIn the code below, fill in the blanks to set the height of each bar to the percent of individuals in a particular race whose mortgage was denied. Select a geom function to create a column chart. Be sure to fill in the correct labels.\n\nhmda_denial_by_race |&gt;\n  ggplot(aes(x = derived_race, _______)) +\n  _______ +\n  labs(title = \"Home Mortgage Disclosure Act Applications, Mississippi, 2024\",\n       x = \"Race of Applicant\",\n       y = \"___________\",\n       caption = str_wrap(\"This column plot visualizes the denial rates of home mortgage applications in MS in 2024. The plot shows that Black or African American applicants, American Indian or Alaska Native applicants, or applicants of 2 or more minority races were all denied mortgage at double the rate of White applicants. This may indicate disparities in lending practices.\", 120)) +\n  theme_minimal() +\n  coord_flip()\n\n\n\nWhile this gives us some insight into disparities in lending practices, we can’t see how multiple aspects of a person’s identity might factor in to these distinctions. The concept of intersectionality - introduced by civil rights scholar Kimberle Crenshaw in the late 1980s - considers how people of certain overlapping social identities may face unique forms of discrimination. Let’s take a look at how this data changes when we also consider sex in relation to denial rates.\n\n\n\n\n\n\nImportantQuestion 9 (2.5 pts)\n\n\n\nCopy your code above, replacing the hmda_denial_by_race data frame with hmda_denial_by_race_sex. Using the fill aesthetic, add the variable for describing the applicants’ sex to the plot. Set the position of the columns to \"dodge\", and be sure to add a label for the fill aesthetic. Adjust the caption to summarize your findings.\n\n# Create plot here\n\n\n\nIn reviewing data like this, some banks have explained the disparities by suggesting that certain groups of applicants are more likely to have lower credit scores, less cash for down payments, or more debt in relation to their income. Let’s take a look at the reasons that Mississippi banks denied mortgage loans in 2024.\n\n\n\n\n\n\nImportantQuestion 10 (2.5 pts)\n\n\n\nCreate a plot below that visualizes how many applicants of each race were denied mortgages for each denial reason. Be sure to give it a descriptive title and labels covering all 5 essential components of data context. You may wish to borrow some of your previous code to adjust the plot for legibility. I’ve given you some code below to filter the data frame to just those mortgage applications that were denied.\n\nhmda_ms_2024 |&gt;\n  filter(action_taken == \"Application denied\") |&gt;\n#Fill remaining lines here\n\n\n\nFrom this plot, you should learn that the top three reasons for denials were: 1) Multiple (meaning some combination of other denial reasons), 2) Credit history, and 3) Debt-to-income ratio. This dataset does not release information about applicants’ credit histories. However, we can take a look at the outcomes of applications from applicants with different debt-to-income ratios compared across races.\nDebt-to-income ratio refers to how much debt a person has in relation to the money they earn in income. A high debt-to-income ratio indicates that someone may not be pulling in enough income to pay off their debts, while a low debt-to-income ratio indicates that their income can reasonably help them pay off their debts. Banks are often hesitant to lend to individuals with high debt-to-income ratios.\n\n\n\n\n\n\nImportantQuestion 11 (2.5 pts)\n\n\n\nBelow I’ve given you some code to produce a plot that visualizes the percent of mortgage applications that resulted in each action (e.g. loan originated, denied, etc.), broken out by the debt-to-income ratio of the applicant. Referring to last week’s lab, add a line to this code to facet this plot by race. For which races was the denial rate higher for applicants with a lower than 50% debt-to-income ratio? Adjust the fact and interpretation presented in the caption with your response.\n\nhmda_ms_2024 |&gt;\n  ggplot(aes(x = debt_to_income_ratio, fill = action_taken)) +\n  geom_bar(position = \"fill\") +\n  coord_flip() +\n  #Add line to facet here\n  labs(title = \"Home Mortgage Disclosure Act Applications, Mississippi, 2024\",\n       x = \"Debt-to-Income Ratio\",\n       y = \"Percent of Mortgage Applications\",\n       fill = \"Action Taken\", \n       caption = str_wrap(\"This bar plot visualizes the percent of mortgage applications that resulted in each action, broken out by the debt-to-income ratio of the applicant. From this plot, we can see that most applicants with a debt-to-income ratio of 50% or higher were denied loans, and most applicants with a debt-to-income ratio of lower than 50% had their loans originated. This shows that banks are less likely to lend to applicants with higher debt-to-income ratios.\",width = 120)) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 8), \n        legend.title = element_text(size = 8),\n        legend.key.size = unit(0.4, \"cm\"),\n        plot.caption = element_text(size = 8)) +\n  guides(fill=guide_legend(nrow = 3))\n\n\n\n\n\n\n\n\n\n\nFinally, let’s take a look at differences in what borrowers owe when their mortgages are approved. A number of factors influence the interest rates that borrowers pay on their loans (including credit history, income, debt-to-income ratio, and loan term). Higher debt-to-income ratios often result in higher interest rates.\n\n\n\n\n\n\nImportantQuestion 12 (2.5 pts)\n\n\n\nBelow I’ve given you some code to produce a plot that visualizes how the distributions of interest rates differed across debt-to-income ratios when loans were approved. Referring to last week’s lab, add a line to this code to facet this plot by race. For which races were the interest rates higher even with lower debt-to-income ratios? Adjust the fact and interpretation presented in the caption with your response.\n\nhmda_ms_2024 |&gt;\n  filter(action_taken == \"Loan originated\") |&gt;\n  ggplot(aes(x = debt_to_income_ratio, y = interest_rate)) +\n  geom_boxplot() +\n  coord_flip() +\n  labs(title = \"Home Mortgage Disclosure Act Applications, Mississippi, 2024\",\n       x = \"Debt-to-Income Ratio\",\n       y = \"Interest Rate\",\n       caption = str_wrap(\"These boxplots visualize the distribution of interest rates for loans originated in MS in 2024, broken out by the debt-to-income ratio of the applicant. From this plot, we can see that the median interest rate for borrowers with a debt-to-income ratio of under 50% was around 7%. Median interest rates increased for borrowers with a debt-to-income ratio of over 50%. This shows that a high debt-to-income ratio may be one factor contributing to higher interest rates.\",width = 120)) +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCautionEthical Considerations\n\n\n\nThis dataset makes loan-level data about individual sensitive financial information available to the public. To reduce the risk that borrowers may be identified in the data, the CFPB removes certain variables before publication, such as the loan’s unique identifier, the property address, the applicant’s credit score, and any free-form text that the applicant writes on the application. Applicants do not have the option to opt-out of their data being disclosed in this dataset. If it were possible to re-identify individual applicants in this dataset, what would be the risks to the public disclosure of their information? Which applicants would be the most vulnerable? How should we think about the balance between the social value of this public data disclosure and the possible risks to those represented in it? Share your ideas on our discussions Slack channel."
  }
]