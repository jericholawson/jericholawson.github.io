[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SDS 192: Introduction to Data Science",
    "section": "",
    "text": "This website is the central hub for all materials related to this iteration of SDS 192. Use the links on the right-side of the page to access particular content.\n\n\nSource: xkcd"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "SDS 192: Introduction to Data Science",
    "section": "",
    "text": "This website is the central hub for all materials related to this iteration of SDS 192. Use the links on the right-side of the page to access particular content.\n\n\nSource: xkcd"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "In this webpage, you will find the syllabus for this course (02)."
  },
  {
    "objectID": "syllabus.html#overview",
    "href": "syllabus.html#overview",
    "title": "Syllabus",
    "section": "Overview",
    "text": "Overview\n\nContactLocation/TimeDescriptionLearning OutcomesMaterials\n\n\n\n\n\n\n\nInstructor: Jericho Lawson\nEmail: jlawson01@smith.edu\nOffice Hours:\n\nMondays, 3-4pm\nFridays, 10am-12pm\nMcConnell 207\n\n\n\n\n\n\n\nMondays, 1:40 - 2:55pm in Sabin-Reed 301\nWednesdays & Fridays, 1:20 - 2:35pm in Sabin-Reed 301\n\n\n\nData science involves applying a set of strategies to transform a recorded set of values into something from which we can glean knowledge and insight. This course will introduce you to concepts and methods from the field of data science, along with how to apply them in R. You will learn how to acquire, clean, wrangle, and visualize data. You will also learn best practices in data science workflows, such as code documentation and version control. Issues in data ethics will be addressed throughout the course.\n\n\nBy the end of this course, students will be able to do the following:\n\nData visualization: Create informative and clean visuals through various types of plots. Appropriate statistics and metrics are displayed. Use of base R and advanced libraries to generate plots (i.e. ggplot2).\nData wrangling: Develop techniques to properly use data in a workflow, which includes the transformation of data, data cleaning, and data joining. Students will also gather data in appropriate and ethical manners.\nWorkflow: Practice common tasks to working through particular data science problems, such as data retrieval, R programming, GitHub, and light statistics.\nData ethics: Identify best practices and ethical dilemmas that stem from data science work. This includes contextual thinking, environmental concerns, and intellectual property. Students will also develop ethical ways to use generative AI.\n\n\n\n\nTextbooks\n\nBaumer, B. S., Kaplan, D. T., & Horton, N. J. (2024). Modern Data Science with R (3rd ed.). CRC Press. https://mdsr-book.github.io/mdsr3e/\n\nOptional:\n\nIsmay, C., Kim A. Y., & Valdivia A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). CRC Press. https://moderndive.com/v2/\nIrizarry, R. A. (2022). Introduction to Data Science: Data Analysis and Prediction Algorithms with R. CRC Press. https://rafalab.dfci.harvard.edu/dsbook-part-1/\n\n\n\nTechnology\n\nFor coding: R, RStudio\n\nFor downloading/installing: Instructions\n\nFor assignment turn-ins: GitHub\nFor discussion assignments: Perusall\n\nFor joining Perusall course: To join\n\nEnrollment code: LAWSON-2BX49\n\n\nFor course management: Moodle, but will be used seldomly\nFor course materials: This website\nFor discussions and announcements: Slack"
  },
  {
    "objectID": "syllabus.html#grading-and-expectations",
    "href": "syllabus.html#grading-and-expectations",
    "title": "Syllabus",
    "section": "Grading and Expectations",
    "text": "Grading and Expectations\n\nBreakdown\n\n\n\n\n\n\n\n\n\n\nFormative\n\n\nSummative\n\n\n\n\n\nReadings, Activities, Problems\n10%\n\nProjects (2)\n30%\n\n\nLabs\n30%\n\nExams (2)\n30%\n\n\n\nA traditional grading system will be used here. Cumulative numerical averages of 90-100 are guaranteed at least an A-, 80-89 at least a B-, and 70-79 at least a C-. The exact ranges for letter grades will ultimately be determined at the end of the course.\n\n\nMW Classes, Readings, Activties, and Exercises (10%)\nPrior to the upcoming week, readings will be assigned through Perusall that prepare you for material that will be explored thereafter. The readings on Perusall will involve:\n\nReading through the material\nWriting 2-4 annotations\nHighlighting one item you learned and one item that seems challenging\n\nThese annotations will allow me to identify which concepts to focus on in more detail during the week. Generally, these items will be due on Sundays at 11:59pm, with no acceptance of late work. Readings will be graded on completion.\nDuring Mondays and Wednesday classes, we will go through mini-lectures, activities, and demos. Classes will be experiential, meaning that you will have the opportunity to apply concepts from class to activities, exercises, and investigations. Students are expected to participate during lecture by asking questions and working with other students. Additionally, it is required that you bring your laptop to class. Class activities will be administered often during lecture, and you will have until the end of lecture to turn them in through your GitHub submission repository. These activities will be graded based on completion and/or correctness.\nOn occasion, a reading exercise may be assigned on Wednesday for you to complete. Similar to the activities, these will be turned in through your GitHub submission repository by Thursdays at 11:59pm. These exercises will be graded based on completion and correctness.\n\n\nFriday Classes and Labs (30%)\nFriday’s classes are dedicated exclusively to labs unless otherwise stated. In these labs, you will have the opportunity to compile (no pun intended) what you’ve learned and work on a experiential assignment that showcases those skills. This will involve strong usage of R and GitHub. In earlier weeks, we will get you all familiar with the technical programs along with the workflow.\nLabs in this course introduce a data science skill by walking you through exploratory analysis of a dataset documenting a socially-relevant issue (such as racial profiling in policing, affordable housing, and pollution). Labs will be started in class on Fridays and completed for homework by Wednesdays at 11:59pm. If you finish a lab early, you are encouraged to help your classmates. Labs will be graded on both completion and correctness. Note that at the end of each lab, there will be a prompt asking you to consider some of the ethical considerations of the data analysis you just completed. You must respond to this prompt in Slack to earn full credit on the lab.\nAll lab assignments will be submitted through your GitHub submission repository. You will submit assignments by pushing changes to template documents to a private GitHub repository. I will provide guidance on how to do this early in the semester.\n\n\nProjects (30% total)\nTwo projects will be assigned throughout the semester. The projects are designed to test your ability to successfully complete course objectives as described earlier. The following two projects, along with their tentative due dates, are seen below:\n\nProject #1: Data Visualizations and GitHub: due Wednesday, 3/4 at 11:59pm\n\nCreate meaningful, informative, and clear visualizations that communicate information from the data and real-world issue.\nConfigure an appropriate pipeline that funnels all relevant information, files, and summaries into a GitHub repository.\n\nProject #2: Workflow and Real-World Investigation: due Monday, 4/27 at 11:59pm\n\nComplete a detailed, attentive workflow of an investigation related to a real-world issue with appropriate data and context.\nPresent relevant information and code to various audiences in multiple formats, including a report, presentation, and demonstration.\n\n\nMore details to come in later weeks.\n\n\nExams (30% total)\nTwo exams will be administered during the course of the semester, which will include written and oral parts. The first exam will be administered in-class on Friday, 3/13, while the second exam will be administered during finals week as a self-scheduled exam. More details to come in later weeks."
  },
  {
    "objectID": "syllabus.html#policies",
    "href": "syllabus.html#policies",
    "title": "Syllabus",
    "section": "Policies",
    "text": "Policies\n\nPreparation and Attendance\nAs a four-credit course that meets 4.5 hours per week, Smith expects students to dedicate at least 7.5 hours per week towards the course outside of class. The assignments, readings, and assessments are designed with this target in mind. Expect to read through lecture notes, examples, articles, and forums outside of class along with the assignments.\nAttending class is imperative to your learning and taking part in an active community. Attendance will be taken for each class period. However, things come up and you may not have the capacity to attend. As such, you will be able to miss 3 classes with no penalty. After the third unexcused absence, your overall grade will drop by 1% for each class missed. Additional absences may be excused due to family/personal difficulties, sickness, or school or career-related activities; however, I will require some form of documentation for these absences. Please speak with your class dean or the Accessibility Resource Center so that we can get documentation of your need.\nDo make every effort to arrive to class on time. If you happen/plan to arrive more than 10 minutes late, please inform me ahead of time. Any unexplained tardiness will result in a marked absence. If you must miss a class entirely, you should contact a peer to discuss what was missed.\n\n\nExtensions\nYou will be granted 2 free late days to use for lab assignments, with a maximum of one day used on each lab assignment. Additionally, you will be granted 2 late days to use for final project submissions, with a maximum of two days used at a single time. No need to inform me that you intend to take these late days. Beyond this, late assignments will not be accepted without an accommodation from a class dean or from the ARC.\nNote that this policy does not apply to Perusall annotations, reading exercises, exams, or project checkpoints/proposals/presentations.\n\n\nAcademic Honesty\nAs a student at Smith College, the college expects all students to be honest and committed to the principles of academic and intellectual integrity in preparation and submission of all course work and examinations, as outlined by the Academic Integrity Board (AIB). The AIB provides an Academic Integrity Statement, which all students are expected to abide by. Any cases of academic dishonesty or plagiarism will be reported to the Academic Honor Board. Examples of these behaviors include:\n\nSubmitting work completed by another student as your own.\nCopying and pasting words from sources without quoting and citing the author.\nParaphrasing material from another source without citing the author.\nFailing to cite your sources correctly.\nFalsifying or misrepresenting information in submitted work.\nPaying another student or service to complete assignments for you.\nSubmitting work generated by artificially intelligent tools such as ChatGPT without permission or instruction to do so.\n\nYou are encouraged to discuss course material, including assignments, with your classmates. All work you turn in, however, must be your own. This includes both writing and code. Copying from other students, from books, or from websites (1) does nothing to help you learn how to program, (2) is easy for us to detect, and (3) has serious negative consequences.\n\n\nGenerative AI\nAs mentioned in the Academic Integrity Board, the professor for each course decides whether and how students are allowed to use generative AI in a given course. For this specific course, any use of generative AI to complete assignments or produce content for this course is prohibited, unless otherwise stated in the assignment itself.\nAs a foundational course, it is critical that you are able to think like a data scientist, which includes producing meaningful code, developing logical solutions to problem, and critiquing good results from the bad ones. While the use of generative AI can be beneficial at producing base-level code and providing insights, it comes at the detriment of your own critical thinking. The human element will be critical in succeeding in data science. If you don’t develop the skills to understand how the underlying code is composed/works, then you will not be prepared for this kind of work.\nProhibited forms of generative AI usage include but are not limited to:\n\nSummarizing course readings.\nDrafting, editing, and proofreading responses to written prompts on any assignment.\nComposing and/or formatting code and comments.\nAnswering lab, quiz, or exam questions.\nConducting analysis of any plots, methods, and results for any assignment.\n\nAny unauthorized use of generative artificial intelligence in this course will be considered a case of academic dishonesty/plagiarism and will be reported to the Academic Honor Board.\nCaveat: While the policy here is strict, do note that there will be assignments and lectures that go through the ethical and effective use of generative AI in data science as part of a unit. In these assignments, further directions will be given to showcase the use of generative AI. However, unless otherwise stated, generative AI should not be used in any assignment."
  },
  {
    "objectID": "syllabus.html#community-support",
    "href": "syllabus.html#community-support",
    "title": "Syllabus",
    "section": "Community & Support",
    "text": "Community & Support\n\nCode of Conduct\nAs the instructor for this course, I am committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor I have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students and the instructor are expected to adhere to this Code of Conduct in all settings for this course: seminars, office hours, and over Slack. This Code of Conduct is adapted from the Contributor Covenant, version 1.0.0, available here.\n\n\nPrinciples of Community\nWhether in a class, college, or neighborhood setting, achieving a warm community is essential to your well-being. In this class, I hope we can foster a collaborative and welcoming environment: one that celebrates successes, respects individual strengths and weaknesses, demonstrates compassion for each other’s struggles, and affirms diverse identities.\nTo establish this, consider the following:\n\nCheck-in with colleagues before starting collaborative work.\nConsider when to step up and when to step back in class discussions, creating space for others to contribute. Listening is just as important to community-building as speaking.\nAcknowledge what we do and don’t know, as well as how our colleagues experience the world.\nSupport colleagues that may be stepping outside of their comfort zone (i.e. presentations).\nAsk questions often in our Slack workspace. Help each other out by answering questions when you can.\nAdmit mistakes. They happen, and I will certainly make mistakes in class.\nUse pronouns. This provides a foundation to a safe, respectful classroom environment that creates a sense of trust. For information on pronouns and usage, please see the Office of Equity and Inclusion link here: Pronouns\n\n\n\nAccommodations\nIt is my goal for everyone to succeed in this course. If you have personal circumstances that may impact your experience of our classroom, I encourage you to contact the Accessibility Resource Center in College Hall 104 or at arc@smith.edu. The Center will generate a letter that indicates to me what kind of support you need and how I can make your classroom experience more accommodating. Once you have this letter, you are welcome to visit my office hours or email me to discuss ideas about how we can tailor the course accordingly. While you can request accommodations at any time, the sooner we start this conversation, the better. If you have concerns about the course that are not addressed through ARC, please contact me. At no point will I ask you to divulge details about your personal circumstances to me.\n\n\nStudent Well-Being\nCollege life is stressful, and life outside of college can be overwhelming. It is my position that attending to your physical and mental health and well-being should be a top priority. I will remind you of this often throughout the semester. I encourage you to schedule a time to talk with me if you are struggling with this course. If you, or anyone you know, is experiencing distress, there are numerous campus resources that can provide support via the Schacht Center.\nAdditional resources and support offered by the college are listed below:\n\nAccessibility Resource Center (ARC)\nSpinelli Center: Support for students doing quantitative work. Includes tutoring and resources.\n\nFor this class: Sun-Thurs, 7-9pm in Sabin-Reed 301.\nEmail qlctutor@smith.edu for specific request for help.\n\nCrisis Resources\nCounseling Services\nWellness Resources\nGender Identity and Expression\nDiscriminatory Harassment"
  },
  {
    "objectID": "syllabus.html#course-outline",
    "href": "syllabus.html#course-outline",
    "title": "Syllabus",
    "section": "Course Outline",
    "text": "Course Outline\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nCh.\nAssignments / Notes\n\n\n\n\n1\n1/26-30\nIntroduction to Data\n1\n\n\n\n2\n2/2-6\nIntro to R and Workflows\n1, B\n\n\n\n3\n2/9-13\nData Visualization\n2\n\n\n\n4\n2/16-20\nggplot2\n3\n\n\n\n5\n2/23-2/27\nData Wrangling\n4\n\n\n\n6\n3/2-3/6\nData Joining\n5\nProject #1 due: Wed, 3/4\n\n\n7\n3/9-13\nStatistics, Exam #1\n9\nExam #1: Fri, 3/13\n\n\n8\n3/16-20\nSpring Break!\n\nNo class all week long\n\n\n9\n3/23-27\nData Tidying\n6\n\n\n\n10\n3/30-4/3\nProgramming\n7\n\n\n\n11\n4/6-10\nEthics and Programming\n8, C\n\n\n\n12\n4/13-17\nSpatial Thinking\n17\n\n\n\n13\n4/20-24\nSpatial Thinking\n17\n\n\n\n14\n4/27-5/1\nAPIs and Review\n18\nProject #2 due: Mon, 4/27 \n\n\nFinals\n5/2-9\nFinals\nNA\nExam #2: self-scheduled (5/6-9) \n\n\n\n\nNote that the assignments and topics covered are tentatively scheduled and may be altered slightly as the quarter progresses. The instructor has the right to modify the syllabus if needed. If this occurs, students will be notified before the change occurs."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28Friday, 1/30\n\n\nLecture #1: Introduction\n\nSlides + Activity\n\n\n\nLecture #2: Intro to Data\n\nSlides\nActivity\n\n\n\nLab #1:  - \n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due"
  },
  {
    "objectID": "schedule.html#week-1-introduction-126---130",
    "href": "schedule.html#week-1-introduction-126---130",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28\n\n\nLecture #1: Introduction\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nPre-Course Survey (due Tuesday, 1/27 at 8:59pm)\n\n\n\n\n\nLecture #2: Names and Values\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #1 (due Sunday, 2/1 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-2-data-structures-22---26",
    "href": "schedule.html#week-2-data-structures-22---26",
    "title": "Schedule",
    "section": "Week 2: Data Structures (2/2 - 2/6)",
    "text": "Week 2: Data Structures (2/2 - 2/6)\n\nMonday, 2/2Wednesday, 2/4\n\n\nLecture #3: Vectors\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\nLecture #4: Multi-Dimensional Data Structures\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #2 (due Sunday, 2/8 at 8:59pm)\nHW #1 (due Tuesday, 2/10 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-3-project-workflow-29---213",
    "href": "schedule.html#week-3-project-workflow-29---213",
    "title": "Schedule",
    "section": "Week 3: Project Workflow (2/9 - 2/13)",
    "text": "Week 3: Project Workflow (2/9 - 2/13)\n\nMonday, 2/9Wednesday, 2/11\n\n\nLecture #5: Projects\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\n\n\n\n\n\n\nImportantQuiz #1\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture #6: GitHub\n\n\n\n\nSlides\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #3 (due Sunday, 2/15 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-4-subsetting-and-control-flow-216---220",
    "href": "schedule.html#week-4-subsetting-and-control-flow-216---220",
    "title": "Schedule",
    "section": "Week 4: Subsetting and Control Flow (2/16 - 2/20)",
    "text": "Week 4: Subsetting and Control Flow (2/16 - 2/20)\n\nMonday, 2/16Wednesday, 2/18\n\n\nLecture #7: Subsetting\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #8: Control Flow\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #4 (due Sunday, 2/22 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-5-functions-and-apply-223---227",
    "href": "schedule.html#week-5-functions-and-apply-223---227",
    "title": "Schedule",
    "section": "Week 5: Functions and Apply (2/23 - 2/27)",
    "text": "Week 5: Functions and Apply (2/23 - 2/27)\n\nMonday, 2/23Wednesday, 2/25\n\n\nQuiz #2: Subsetting and Control Flow\nLecture #9: Functions\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #10: Apply and Map\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #5 (due Sunday, 3/1 at 8:59pm)\nHW #3 (due Tuesday, 3/3 at 8:59pm)"
  },
  {
    "objectID": "schedule.html#week-6-packages-32---36",
    "href": "schedule.html#week-6-packages-32---36",
    "title": "Schedule",
    "section": "Week 6: Packages (3/2 - 3/6)",
    "text": "Week 6: Packages (3/2 - 3/6)\n\nMonday, 3/2Wednesday, 3/4\n\n\nLecture #11: Packages\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #12: Build a Package\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)"
  },
  {
    "objectID": "lectures/w1l1_intro.html#welcome",
    "href": "lectures/w1l1_intro.html#welcome",
    "title": "Introductions",
    "section": "Welcome!",
    "text": "Welcome!\n\n\n\n\n\n\n\n\n\nCourse: SDS 192, Sect. 02\nTimes:\n\nM, 1:40-2:55pm\nW/F, 1:20-2:35pm"
  },
  {
    "objectID": "lectures/w1l1_intro.html#welcome-1",
    "href": "lectures/w1l1_intro.html#welcome-1",
    "title": "Introductions",
    "section": "Welcome!",
    "text": "Welcome!\n\n\n\nInstructor: Jericho Lawson\n\nLocation: McConnell 207\n\nOffice Hours:\n\nM, 3-4pm\nF, 10am-12pm\n\nEmail: jlawson01@smith.edu"
  },
  {
    "objectID": "lectures/w1l1_intro.html#activity-data-science",
    "href": "lectures/w1l1_intro.html#activity-data-science",
    "title": "Lecture #1: Introductions",
    "section": "Activity: Data Science",
    "text": "Activity: Data Science\nForm groups of 2-3 with your peers near you. Complete the following tasks:\n\nIntroduce yourselves to each other! Mention your name, major, and one cool thing you did over the summer.\nOn a piece of paper, write the names of all group members.\nWrite down words, phrases, and ideas that come to mind when you hear “data science”."
  },
  {
    "objectID": "lectures/w1l1_intro.html#what-is-data-science-common-view",
    "href": "lectures/w1l1_intro.html#what-is-data-science-common-view",
    "title": "Introductions",
    "section": "What is data science? Common view:",
    "text": "What is data science? Common view:\n\n\n\nInterdisciplinary field combining computer science, mathematics/statistics, and domain expertise to extract meaningful information from unstructured data points"
  },
  {
    "objectID": "lectures/w1l1_intro.html#what-is-data-science-my-view",
    "href": "lectures/w1l1_intro.html#what-is-data-science-my-view",
    "title": "Introductions",
    "section": "What is data science? My view:",
    "text": "What is data science? My view:\n\n\n\nInterdisciplinary field combining computer science, mathematics/statistics, and domain expertise to extract meaningful information from unstructured data points\n Includes the human aspect: use of aesthetics, situational context, and communication to explain the data to the world"
  },
  {
    "objectID": "lectures/w1l1_intro.html#case-study-1-aclu-fights-discriminatory-housing",
    "href": "lectures/w1l1_intro.html#case-study-1-aclu-fights-discriminatory-housing",
    "title": "Introductions",
    "section": "Case Study 1: ACLU Fights Discriminatory Housing",
    "text": "Case Study 1: ACLU Fights Discriminatory Housing\n\n\n\nAmerican Civil Liberties Union employs data scientists to produce insights regarding discriminatory laws and practices\nFindings are presented in courts, legislatures, and public reports\nIn this study, they use public data to show that excluding people with criminal records from housing can be viewed as a violation of the US Fair Housing Act."
  },
  {
    "objectID": "lectures/w1l1_intro.html#case-study-2-epa-tracks-environmental-injustice",
    "href": "lectures/w1l1_intro.html#case-study-2-epa-tracks-environmental-injustice",
    "title": "Introductions",
    "section": "Case Study 2: EPA Tracks Environmental Injustice",
    "text": "Case Study 2: EPA Tracks Environmental Injustice\n\n\n\nEnvironmental Protection Agency hires data scientists to produce insights regarding environmental health risks\nFindings implicate environmental policies, funding allocations, and legal actions against states and industries\nThis tool, visualizes environmental and demographic indicators to highlight communities experiencing environmental injustices."
  },
  {
    "objectID": "lectures/w1l1_intro.html#case-study-3-geena-davis-institute-studies-gender-biases-in-films",
    "href": "lectures/w1l1_intro.html#case-study-3-geena-davis-institute-studies-gender-biases-in-films",
    "title": "Introductions",
    "section": "Case Study 3: Geena Davis Institute Studies Gender Biases in Films",
    "text": "Case Study 3: Geena Davis Institute Studies Gender Biases in Films\n\n\n\nGeena Davis Institute collaborated with University of Southern California’s Signal Analysis and Interpretation Laboratory (SAIL)\nDeveloped a machine learning tool to measure representation of diverse groups in films by studying screen time and speaking"
  },
  {
    "objectID": "lectures/w1l1_intro.html#topics-covered-in-this-course",
    "href": "lectures/w1l1_intro.html#topics-covered-in-this-course",
    "title": "Introductions",
    "section": "Topics covered in this course",
    "text": "Topics covered in this course\n\n\n\nData visualization\nData wrangling\nProgramming with data (via R)\nData retrieval\nData science infrastructures and workflows\nData science ethics\nMapping"
  },
  {
    "objectID": "lectures/w1l1_intro.html#learning-objectives",
    "href": "lectures/w1l1_intro.html#learning-objectives",
    "title": "Introductions",
    "section": "Learning objectives",
    "text": "Learning objectives\nData visualization\n\nCreate informative and clean visuals via base R, advanced libraries\nShow appropriate statistics and metrics for support\n\nData wrangling\n\nDevelop proper wrangling techniques, including data transformation, cleaning, and joining\nGather data in appropriate and ethical manners"
  },
  {
    "objectID": "lectures/w1l1_intro.html#learning-objectives-1",
    "href": "lectures/w1l1_intro.html#learning-objectives-1",
    "title": "Introductions",
    "section": "Learning objectives",
    "text": "Learning objectives\nWorkflow\n\nPractice retrieval, R programming, GitHub, and light statistics\n\nData ethics\n\nIdentify best practices and ethical dilemmas, including contextual thinking, environmental concerns, and intellectual property\nDevelop ethical ways to use generative AI"
  },
  {
    "objectID": "lectures/w1l1_intro.html#who-am-i",
    "href": "lectures/w1l1_intro.html#who-am-i",
    "title": "Introductions",
    "section": "Who am I?",
    "text": "Who am I?\nCall me Jericho, but if you prefer, Professor Lawson or Dr. Lawson is okay!\n\n\n\n\n\n\n\n\n\nLecturer of Statistical and Data Sciences\nResearch interests: variable selection, imaging, machine learning\nMy college journey:\n\nPh.D. in Applied Statistics from UC Riverside\nM.S. in Statistics from UC Riverside\nB.S. in Applied Mathematics; Statistics and Data Science from University of Arizona"
  },
  {
    "objectID": "lectures/w1l1_intro.html#who-am-i-1",
    "href": "lectures/w1l1_intro.html#who-am-i-1",
    "title": "Introductions",
    "section": "Who am I?",
    "text": "Who am I?\n\n\n\n\n\n\n\n\n\nFrom Arizona!!\n\nWill either hear me talk about the state or the Suns\n\nHiker, foodie, and explorer!"
  },
  {
    "objectID": "lectures/w1l1_intro.html#exercise",
    "href": "lectures/w1l1_intro.html#exercise",
    "title": "Introductions",
    "section": "Exercise",
    "text": "Exercise\nOn your feet! I’ll ask three questions about light-hearted pieces of information. For each question,\n\nGroup or order yourselves.\nPonder about what characteristics you see with the groupings/orderings."
  },
  {
    "objectID": "lectures/w1l1_intro.html#workflow",
    "href": "lectures/w1l1_intro.html#workflow",
    "title": "Introductions",
    "section": "Workflow",
    "text": "Workflow\n\nDetermine problem/issue\nCollect data\nExplore and clean the data\nModel the data\nCommunicate results\n\nQuestion? How was this done? Discuss amongst yourselves."
  },
  {
    "objectID": "lectures/w1l1_intro.html#tools",
    "href": "lectures/w1l1_intro.html#tools",
    "title": "Introductions",
    "section": "Tools",
    "text": "Tools\n\nDetermine problem/issue: Exploration of issues\nCollect data: From online source (e.g. scraping, csv file)\nExplore and clean the data: Use of R, wrangling\nModel the data: Statistics, regression\nCommunicate results: Plots, tables, writing, presentations"
  },
  {
    "objectID": "lectures/w1l1_intro.html#coding-agonizing-when-it-doesnt-work-satisfying-when-it-does",
    "href": "lectures/w1l1_intro.html#coding-agonizing-when-it-doesnt-work-satisfying-when-it-does",
    "title": "Introductions",
    "section": "Coding: agonizing when it doesn’t work, satisfying when it does",
    "text": "Coding: agonizing when it doesn’t work, satisfying when it does\n\nThink of code like a language.\nCoding can be incredibly frustrating.\nCoding has been exclusionary."
  },
  {
    "objectID": "lectures/w1l1_intro.html#prepping-for-this-class",
    "href": "lectures/w1l1_intro.html#prepping-for-this-class",
    "title": "Introductions",
    "section": "Prepping for this class",
    "text": "Prepping for this class\n\nNavigate the Moodle course website\nRead through the syllabus\nPerusall\nSlack"
  },
  {
    "objectID": "lectures/w1l1_intro.html#for-monday",
    "href": "lectures/w1l1_intro.html#for-monday",
    "title": "Introductions",
    "section": "For Monday",
    "text": "For Monday\n\nInstall Slack desktop and set notifications\nRead through article and make annotations on Perusall\nRead through Ch. 1-2 of textbook and syllabus\nTake reading/syllabus quiz on Moodle\nComplete the pre-course survey on Moodle\nBring charged laptop to class on Monday"
  },
  {
    "objectID": "lectures/w1l1_intro.html#section",
    "href": "lectures/w1l1_intro.html#section",
    "title": "Introductions",
    "section": "",
    "text": "Sources: NYT, Compadre DB, The Atlantic"
  },
  {
    "objectID": "lectures/w1l1_intro.html#warm-up-activity-data-science",
    "href": "lectures/w1l1_intro.html#warm-up-activity-data-science",
    "title": "Introductions",
    "section": "Warm-Up Activity: Data Science",
    "text": "Warm-Up Activity: Data Science\nForm groups of 2-3 with your peers near you. Complete the following tasks:\n\nIntroduce yourselves to each other! Mention your name, major, and one cool thing you did over winter break.\nOn a piece of paper, write the names of all group members.\nWrite down words, phrases, and ideas that come to mind when you hear “data science”."
  },
  {
    "objectID": "schedule.html#week-1-what-is-data-science-126---130",
    "href": "schedule.html#week-1-what-is-data-science-126---130",
    "title": "Schedule",
    "section": "",
    "text": "Monday, 1/26Wednesday, 1/28Friday, 1/30\n\n\nLecture #1: Introduction\n\nSlides + Activity\n\n\n\nLecture #2: Intro to Data\n\nSlides\nActivity\n\n\n\nLab #1:  - \n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due"
  },
  {
    "objectID": "schedule.html#week-2-what-is-r-and-github-22---26",
    "href": "schedule.html#week-2-what-is-r-and-github-22---26",
    "title": "Schedule",
    "section": "Week 2: What is R and GitHub? (2/2 - 2/6)",
    "text": "Week 2: What is R and GitHub? (2/2 - 2/6)\n\nMonday, 2/2Wednesday, 2/4Friday, 2/6\n\n\nLecture #3: Intro to R\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\nLecture #4: Coding with R and GitHub\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #2 (due Sunday, 2/8 at 8:59pm)\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\nLab #2: R and GitHub"
  },
  {
    "objectID": "schedule.html#week-3-data-visualization-the-basics-29---213",
    "href": "schedule.html#week-3-data-visualization-the-basics-29---213",
    "title": "Schedule",
    "section": "Week 3: Data Visualization, The Basics (2/9 - 2/13)",
    "text": "Week 3: Data Visualization, The Basics (2/9 - 2/13)\n\nMonday, 2/9Wednesday, 2/11Friday, 2/13\n\n\nLecture #5: Data Visualization\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #1 (due Tuesday, 2/10 at 8:59pm)\n\n\n\n\n\n\n\n\n\n\n\nImportantQuiz #1\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLecture #6: Types of Data Visualizations\n\n\n\n\nSlides\n\n\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #3 (due Sunday, 2/15 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLab #3: Visualization Aesthetics"
  },
  {
    "objectID": "schedule.html#week-4-data-visualizations-ggplot-216---220",
    "href": "schedule.html#week-4-data-visualizations-ggplot-216---220",
    "title": "Schedule",
    "section": "Week 4: Data Visualizations, ggplot (2/16 - 2/20)",
    "text": "Week 4: Data Visualizations, ggplot (2/16 - 2/20)\n\nMonday, 2/16Wednesday, 2/18Friday, 2/20\n\n\nLecture #7: Intro to ggplot\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #8: Advanced ggplot2\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #4 (due Sunday, 2/22 at 8:59pm)\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLab #4: Plotting Frequencies and Distributions"
  },
  {
    "objectID": "schedule.html#week-5-data-wrangling-223---227",
    "href": "schedule.html#week-5-data-wrangling-223---227",
    "title": "Schedule",
    "section": "Week 5: Data Wrangling (2/23 - 2/27)",
    "text": "Week 5: Data Wrangling (2/23 - 2/27)\n\nMonday, 2/23Wednesday, 2/25Friday, 2/27\n\n\nQuiz #2: Subsetting and Control Flow\nLecture #9: Intro to Data Wrangling\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #2 (due Sunday, 2/22 at 8:59pm)\n\n\n\n\n\nLecture #10: Data Wrangling\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #5 (due Sunday, 3/1 at 8:59pm)\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nProject Time"
  },
  {
    "objectID": "schedule.html#week-6-data-joining-32---36",
    "href": "schedule.html#week-6-data-joining-32---36",
    "title": "Schedule",
    "section": "Week 6: Data Joining (3/2 - 3/6)",
    "text": "Week 6: Data Joining (3/2 - 3/6)\n\nMonday, 3/2Wednesday, 3/4Friday, 3/6\n\n\nLecture #11: Data Joining\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #12: Problem Solving\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #5: Data Wrangling (and Joining)"
  },
  {
    "objectID": "schedule.html#week-7-statistics-and-exam-1-39---313",
    "href": "schedule.html#week-7-statistics-and-exam-1-39---313",
    "title": "Schedule",
    "section": "Week 7: Statistics and Exam #1 (3/9 - 3/13)",
    "text": "Week 7: Statistics and Exam #1 (3/9 - 3/13)\n\nMonday, 3/9Wednesday, 3/11Friday, 3/13\n\n\nLecture #13: Statistics\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #14: Review\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nExam #1: In-Class"
  },
  {
    "objectID": "schedule.html#week-8-spring-break-316---319",
    "href": "schedule.html#week-8-spring-break-316---319",
    "title": "Schedule",
    "section": "Week 8: Spring Break! (3/16 - 3/19)",
    "text": "Week 8: Spring Break! (3/16 - 3/19)\n\nMonday, 3/16Wednesday, 3/18Friday, 3/20\n\n\nNo Class!\n\n\nNo Class!\n\n\nNo Class!"
  },
  {
    "objectID": "schedule.html#week-9-data-tidying-323---327",
    "href": "schedule.html#week-9-data-tidying-323---327",
    "title": "Schedule",
    "section": "Week 9: Data Tidying (3/23 - 3/27)",
    "text": "Week 9: Data Tidying (3/23 - 3/27)\n\nMonday, 3/23Wednesday, 3/25Friday, 3/27\n\n\nLecture #15: Data Tidying\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #16: Data Tidying, Part II\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #6: Data Tidying"
  },
  {
    "objectID": "schedule.html#week-10-programming-330---43",
    "href": "schedule.html#week-10-programming-330---43",
    "title": "Schedule",
    "section": "Week 10: Programming (3/30 - 4/3)",
    "text": "Week 10: Programming (3/30 - 4/3)\n\nMonday, 3/30Wednesday, 4/1Friday, 4/3\n\n\nLecture #17: Functions\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #18: Iteration and Functionals\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #7: Programming with Data"
  },
  {
    "objectID": "schedule.html#week-11-ethics-and-programming-46---410",
    "href": "schedule.html#week-11-ethics-and-programming-46---410",
    "title": "Schedule",
    "section": "Week 11: Ethics and Programming (4/6 - 4/10)",
    "text": "Week 11: Ethics and Programming (4/6 - 4/10)\n\nMonday, 4/6Wednesday, 4/8Friday, 4/10\n\n\nLecture #19: Data Ethics\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #20: Testing, Debugging, and AI\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #8: Algorithms"
  },
  {
    "objectID": "schedule.html#week-12-spatial-thinking-413---417",
    "href": "schedule.html#week-12-spatial-thinking-413---417",
    "title": "Schedule",
    "section": "Week 12: Spatial Thinking (4/13 - 4/17)",
    "text": "Week 12: Spatial Thinking (4/13 - 4/17)\n\nMonday, 4/13Wednesday, 4/15Friday, 4/17\n\n\nLecture #21: Spatial Thinking\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #22: Lying with Maps\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #9: Point Mapping"
  },
  {
    "objectID": "schedule.html#week-13-spatial-thinking-420---424",
    "href": "schedule.html#week-13-spatial-thinking-420---424",
    "title": "Schedule",
    "section": "Week 13: Spatial Thinking (4/20 - 4/24)",
    "text": "Week 13: Spatial Thinking (4/20 - 4/24)\n\nMonday, 4/20Wednesday, 4/22Friday, 4/24\n\n\nLecture #23: Project Time\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #24: Polygon Mapping\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLab #10: Polygon Mapping"
  },
  {
    "objectID": "schedule.html#week-14-presentations-apis-review-427---51",
    "href": "schedule.html#week-14-presentations-apis-review-427---51",
    "title": "Schedule",
    "section": "Week 14: Presentations, APIs, Review (4/27 - 5/1)",
    "text": "Week 14: Presentations, APIs, Review (4/27 - 5/1)\n\nMonday, 4/27Wednesday, 4/29Friday, 5/1\n\n\nProject #2 Presentations\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nHW #3 (due Tuesday, 3/3 at 8:59pm)\n\n\n\n\n\nQuiz #3: Functions and Apply\nLecture #25: APIs and Review\n\nSlides\n\n\n\n\n\n\n\nWarningTo-Do/Due\n\n\n\n\nReadings #6 (due Sunday, 3/8 at 8:59pm)\n\n\n\n\n\nLecture #26: Review"
  },
  {
    "objectID": "schedule.html#finals-52---59",
    "href": "schedule.html#finals-52---59",
    "title": "Schedule",
    "section": "Finals: (5/2 - 5/9)",
    "text": "Finals: (5/2 - 5/9)\n\nFinals Week\n\n\nGo do the final!"
  },
  {
    "objectID": "lectures/w1l1_intro.html#for-wednesday-and-beyond",
    "href": "lectures/w1l1_intro.html#for-wednesday-and-beyond",
    "title": "Introductions",
    "section": "For Wednesday and beyond",
    "text": "For Wednesday and beyond\n\nNavigate the course website\nRead through the syllabus\nComplete the pre-course survey and quiz\n\nDue Wednesday at 11:59pm, link on website under Week 1\n\nJoin the Slack, Perusall, and GitHub classroom sites\nRun through the tech setup\n\nR and RStudio"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Below you will find all resources from this course in a list format. This webpage will be updated throughout the entirety of the semester.\n\nSlidesLabsSupplemental MaterialResources\n\n\n\n\n\n\n1: R and Understanding Datasets\n2: R and GitHub\n3: Visualization Aesthetics\n4: Plotting Frequencies and Distributions\n5: Data Wrangling and Joining\n6: Data Tidying\n7: Progamming with Data\n8: Generative AI\n9: Point Mapping\n10: Polygon Mapping"
  },
  {
    "objectID": "syllabus-pdf.html",
    "href": "syllabus-pdf.html",
    "title": "Syllabus",
    "section": "",
    "text": "ContactLocation/TimeDescriptionLearning OutcomesMaterials\n\n\n\nInstructor: Jericho Lawson\nEmail: jlawson01@smith.edu\nOffice Hours:\n\nMondays, 3-4pm\nFridays, 10am-12pm\nMcConnell 207\n\n\n\n\n\nMondays, 1:40 - 2:55pm in Sabin-Reed 301\nWednesdays & Fridays, 1:20 - 2:35pm in Sabin-Reed 301\n\n\n\nData science involves applying a set of strategies to transform a recorded set of values into something from which we can glean knowledge and insight. This course will introduce you to concepts and methods from the field of data science, along with how to apply them in R. You will learn how to acquire, clean, wrangle, and visualize data. You will also learn best practices in data science workflows, such as code documentation and version control. Issues in data ethics will be addressed throughout the course.\n\n\nBy the end of this course, students will be able to do the following:\n\nData visualization: Create informative and clean visuals through various types of plots. Appropriate statistics and metrics are displayed. Use of base R and advanced libraries to generate plots (i.e. ggplot2).\nData wrangling: Develop techniques to properly use data in a workflow, which includes the transformation of data, data cleaning, and data joining. Students will also gather data in appropriate and ethical manners.\nWorkflow: Practice common tasks to working through particular data science problems, such as data retrieval, R programming, GitHub, and light statistics.\nData ethics: Identify best practices and ethical dilemmas that stem from data science work. This includes contextual thinking, environmental concerns, and intellectual property. Students will also develop ethical ways to use generative AI.\n\n\n\n\n\n\nBaumer, B. S., Kaplan, D. T., & Horton, N. J. (2024). Modern Data Science with R (3rd ed.). CRC Press. https://mdsr-book.github.io/mdsr3e/\n\nOptional:\n\nIsmay, C., Kim A. Y., & Valdivia A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). CRC Press. https://moderndive.com/v2/\nIrizarry, R. A. (2022). Introduction to Data Science: Data Analysis and Prediction Algorithms with R. CRC Press. https://rafalab.dfci.harvard.edu/dsbook-part-1/\n\n\n\n\n\nFor coding: R, RStudio\n\nFor downloading/installing: Instructions\n\nFor assignment turn-ins: GitHub\nFor discussion assignments: Perusall\n\nFor joining Perusall course: To join\n\nEnrollment code: LAWSON-2BX49\n\n\nFor course management: Moodle, but will be used seldomly\nFor course materials: This website\nFor discussions and announcements: Slack"
  },
  {
    "objectID": "syllabus-pdf.html#overview",
    "href": "syllabus-pdf.html#overview",
    "title": "Syllabus",
    "section": "",
    "text": "ContactLocation/TimeDescriptionLearning OutcomesMaterials\n\n\n\nInstructor: Jericho Lawson\nEmail: jlawson01@smith.edu\nOffice Hours:\n\nMondays, 3-4pm\nFridays, 10am-12pm\nMcConnell 207\n\n\n\n\n\nMondays, 1:40 - 2:55pm in Sabin-Reed 301\nWednesdays & Fridays, 1:20 - 2:35pm in Sabin-Reed 301\n\n\n\nData science involves applying a set of strategies to transform a recorded set of values into something from which we can glean knowledge and insight. This course will introduce you to concepts and methods from the field of data science, along with how to apply them in R. You will learn how to acquire, clean, wrangle, and visualize data. You will also learn best practices in data science workflows, such as code documentation and version control. Issues in data ethics will be addressed throughout the course.\n\n\nBy the end of this course, students will be able to do the following:\n\nData visualization: Create informative and clean visuals through various types of plots. Appropriate statistics and metrics are displayed. Use of base R and advanced libraries to generate plots (i.e. ggplot2).\nData wrangling: Develop techniques to properly use data in a workflow, which includes the transformation of data, data cleaning, and data joining. Students will also gather data in appropriate and ethical manners.\nWorkflow: Practice common tasks to working through particular data science problems, such as data retrieval, R programming, GitHub, and light statistics.\nData ethics: Identify best practices and ethical dilemmas that stem from data science work. This includes contextual thinking, environmental concerns, and intellectual property. Students will also develop ethical ways to use generative AI.\n\n\n\n\n\n\nBaumer, B. S., Kaplan, D. T., & Horton, N. J. (2024). Modern Data Science with R (3rd ed.). CRC Press. https://mdsr-book.github.io/mdsr3e/\n\nOptional:\n\nIsmay, C., Kim A. Y., & Valdivia A. (2025). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (2nd ed.). CRC Press. https://moderndive.com/v2/\nIrizarry, R. A. (2022). Introduction to Data Science: Data Analysis and Prediction Algorithms with R. CRC Press. https://rafalab.dfci.harvard.edu/dsbook-part-1/\n\n\n\n\n\nFor coding: R, RStudio\n\nFor downloading/installing: Instructions\n\nFor assignment turn-ins: GitHub\nFor discussion assignments: Perusall\n\nFor joining Perusall course: To join\n\nEnrollment code: LAWSON-2BX49\n\n\nFor course management: Moodle, but will be used seldomly\nFor course materials: This website\nFor discussions and announcements: Slack"
  },
  {
    "objectID": "syllabus-pdf.html#grading-and-expectations",
    "href": "syllabus-pdf.html#grading-and-expectations",
    "title": "Syllabus",
    "section": "Grading and Expectations",
    "text": "Grading and Expectations\n\nBreakdown\n\n\n\n\n\n\n\n\n\n\nFormative\n\n\nSummative\n\n\n\n\n\nReadings, Activities, Problems\n10%\n\nProjects (2)\n30%\n\n\nLabs\n30%\n\nExams (2)\n30%\n\n\n\nA traditional grading system will be used here. Cumulative numerical averages of 90-100 are guaranteed at least an A-, 80-89 at least a B-, and 70-79 at least a C-. The exact ranges for letter grades will ultimately be determined at the end of the course.\n\n\nMW Classes, Readings, Activties, and Exercises (10%)\nPrior to the upcoming week, readings will be assigned through Perusall that prepare you for material that will be explored thereafter. The readings on Perusall will involve:\n\nReading through the material\nWriting 2-4 annotations\nHighlighting one item you learned and one item that seems challenging\n\nThese annotations will allow me to identify which concepts to focus on in more detail during the week. Generally, these items will be due on Sundays at 11:59pm, with no acceptance of late work. Readings will be graded on completion.\nDuring Mondays and Wednesday classes, we will go through mini-lectures, activities, and demos. Classes will be experiential, meaning that you will have the opportunity to apply concepts from class to activities, exercises, and investigations. Students are expected to participate during lecture by asking questions and working with other students. Additionally, it is required that you bring your laptop to class. Class activities will be administered often during lecture, and you will have until the end of lecture to turn them in through your GitHub submission repository. These activities will be graded based on completion and/or correctness.\nOn occasion, a reading exercise may be assigned on Wednesday for you to complete. Similar to the activities, these will be turned in through your GitHub submission repository by Thursdays at 11:59pm. These exercises will be graded based on completion and correctness.\n\n\nFriday Classes and Labs (30%)\nFriday’s classes are dedicated exclusively to labs unless otherwise stated. In these labs, you will have the opportunity to compile (no pun intended) what you’ve learned and work on a experiential assignment that showcases those skills. This will involve strong usage of R and GitHub. In earlier weeks, we will get you all familiar with the technical programs along with the workflow.\nLabs in this course introduce a data science skill by walking you through exploratory analysis of a dataset documenting a socially-relevant issue (such as racial profiling in policing, affordable housing, and pollution). Labs will be started in class on Fridays and completed for homework by Wednesdays at 11:59pm. If you finish a lab early, you are encouraged to help your classmates. Labs will be graded on both completion and correctness. Note that at the end of each lab, there will be a prompt asking you to consider some of the ethical considerations of the data analysis you just completed. You must respond to this prompt in Slack to earn full credit on the lab.\nAll lab assignments will be submitted through your GitHub submission repository. You will submit assignments by pushing changes to template documents to a private GitHub repository. I will provide guidance on how to do this early in the semester.\n\n\nProjects (30% total)\nTwo projects will be assigned throughout the semester. The projects are designed to test your ability to successfully complete course objectives as described earlier. The following two projects, along with their tentative due dates, are seen below:\n\nProject #1: Data Visualizations and GitHub: due Wednesday, 3/4 at 11:59pm\n\nCreate meaningful, informative, and clear visualizations that communicate information from the data and real-world issue.\nConfigure an appropriate pipeline that funnels all relevant information, files, and summaries into a GitHub repository.\n\nProject #2: Workflow and Real-World Investigation: due Monday, 4/27 at 11:59pm\n\nComplete a detailed, attentive workflow of an investigation related to a real-world issue with appropriate data and context.\nPresent relevant information and code to various audiences in multiple formats, including a report, presentation, and demonstration.\n\n\nMore details to come in later weeks.\n\n\nExams (30% total)\nTwo exams will be administered during the course of the semester, which will include written and oral parts. The first exam will be administered in-class on Friday, 3/13, while the second exam will be administered during finals week as a self-scheduled exam. More details to come in later weeks."
  },
  {
    "objectID": "syllabus-pdf.html#policies",
    "href": "syllabus-pdf.html#policies",
    "title": "Syllabus",
    "section": "Policies",
    "text": "Policies\n\nPreparation and Attendance\nAs a four-credit course that meets 4.5 hours per week, Smith expects students to dedicate at least 7.5 hours per week towards the course outside of class. The assignments, readings, and assessments are designed with this target in mind. Expect to read through lecture notes, examples, articles, and forums outside of class along with the assignments.\nAttending class is imperative to your learning and taking part in an active community. Attendance will be taken for each class period. However, things come up and you may not have the capacity to attend. As such, you will be able to miss 3 classes with no penalty. After the third unexcused absence, your overall grade will drop by 1% for each class missed. Additional absences may be excused due to family/personal difficulties, sickness, or school or career-related activities; however, I will require some form of documentation for these absences. Please speak with your class dean or the Accessibility Resource Center so that we can get documentation of your need.\nDo make every effort to arrive to class on time. If you happen/plan to arrive more than 10 minutes late, please inform me ahead of time. Any unexplained tardiness will result in a marked absence. If you must miss a class entirely, you should contact a peer to discuss what was missed.\n\n\nExtensions\nYou will be granted 2 free late days to use for lab assignments, with a maximum of one day used on each lab assignment. Additionally, you will be granted 2 late days to use for final project submissions, with a maximum of two days used at a single time. No need to inform me that you intend to take these late days. Beyond this, late assignments will not be accepted without an accommodation from a class dean or from the ARC.\nNote that this policy does not apply to Perusall annotations, reading exercises, exams, or project checkpoints/proposals/presentations.\n\n\nAcademic Honesty\nAs a student at Smith College, the college expects all students to be honest and committed to the principles of academic and intellectual integrity in preparation and submission of all course work and examinations, as outlined by the Academic Integrity Board (AIB). The AIB provides an Academic Integrity Statement, which all students are expected to abide by. Any cases of academic dishonesty or plagiarism will be reported to the Academic Honor Board. Examples of these behaviors include:\n\nSubmitting work completed by another student as your own.\nCopying and pasting words from sources without quoting and citing the author.\nParaphrasing material from another source without citing the author.\nFailing to cite your sources correctly.\nFalsifying or misrepresenting information in submitted work.\nPaying another student or service to complete assignments for you.\nSubmitting work generated by artificially intelligent tools such as ChatGPT without permission or instruction to do so.\n\nYou are encouraged to discuss course material, including assignments, with your classmates. All work you turn in, however, must be your own. This includes both writing and code. Copying from other students, from books, or from websites (1) does nothing to help you learn how to program, (2) is easy for us to detect, and (3) has serious negative consequences.\n\n\nGenerative AI\nAs mentioned in the Academic Integrity Board, the professor for each course decides whether and how students are allowed to use generative AI in a given course. For this specific course, any use of generative AI to complete assignments or produce content for this course is prohibited, unless otherwise stated in the assignment itself.\nAs a foundational course, it is critical that you are able to think like a data scientist, which includes producing meaningful code, developing logical solutions to problem, and critiquing good results from the bad ones. While the use of generative AI can be beneficial at producing base-level code and providing insights, it comes at the detriment of your own critical thinking. The human element will be critical in succeeding in data science. If you don’t develop the skills to understand how the underlying code is composed/works, then you will not be prepared for this kind of work.\nProhibited forms of generative AI usage include but are not limited to:\n\nSummarizing course readings.\nDrafting, editing, and proofreading responses to written prompts on any assignment.\nComposing and/or formatting code and comments.\nAnswering lab, quiz, or exam questions.\nConducting analysis of any plots, methods, and results for any assignment.\n\nAny unauthorized use of generative artificial intelligence in this course will be considered a case of academic dishonesty/plagiarism and will be reported to the Academic Honor Board.\nCaveat: While the policy here is strict, do note that there will be assignments and lectures that go through the ethical and effective use of generative AI in data science as part of a unit. In these assignments, further directions will be given to showcase the use of generative AI. However, unless otherwise stated, generative AI should not be used in any assignment."
  },
  {
    "objectID": "syllabus-pdf.html#community-support",
    "href": "syllabus-pdf.html#community-support",
    "title": "Syllabus",
    "section": "Community & Support",
    "text": "Community & Support\n\nCode of Conduct\nAs the instructor for this course, I am committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor I have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students and the instructor are expected to adhere to this Code of Conduct in all settings for this course: seminars, office hours, and over Slack. This Code of Conduct is adapted from the Contributor Covenant, version 1.0.0, available here.\n\n\nPrinciples of Community\nWhether in a class, college, or neighborhood setting, achieving a warm community is essential to your well-being. In this class, I hope we can foster a collaborative and welcoming environment: one that celebrates successes, respects individual strengths and weaknesses, demonstrates compassion for each other’s struggles, and affirms diverse identities.\nTo establish this, consider the following:\n\nCheck-in with colleagues before starting collaborative work.\nConsider when to step up and when to step back in class discussions, creating space for others to contribute. Listening is just as important to community-building as speaking.\nAcknowledge what we do and don’t know, as well as how our colleagues experience the world.\nSupport colleagues that may be stepping outside of their comfort zone (i.e. presentations).\nAsk questions often in our Slack workspace. Help each other out by answering questions when you can.\nAdmit mistakes. They happen, and I will certainly make mistakes in class.\nUse pronouns. This provides a foundation to a safe, respectful classroom environment that creates a sense of trust. For information on pronouns and usage, please see the Office of Equity and Inclusion link here: Pronouns\n\n\n\nAccommodations\nIt is my goal for everyone to succeed in this course. If you have personal circumstances that may impact your experience of our classroom, I encourage you to contact the Accessibility Resource Center in College Hall 104 or at arc@smith.edu. The Center will generate a letter that indicates to me what kind of support you need and how I can make your classroom experience more accommodating. Once you have this letter, you are welcome to visit my office hours or email me to discuss ideas about how we can tailor the course accordingly. While you can request accommodations at any time, the sooner we start this conversation, the better. If you have concerns about the course that are not addressed through ARC, please contact me. At no point will I ask you to divulge details about your personal circumstances to me.\n\n\nStudent Well-Being\nCollege life is stressful, and life outside of college can be overwhelming. It is my position that attending to your physical and mental health and well-being should be a top priority. I will remind you of this often throughout the semester. I encourage you to schedule a time to talk with me if you are struggling with this course. If you, or anyone you know, is experiencing distress, there are numerous campus resources that can provide support via the Schacht Center.\nAdditional resources and support offered by the college are listed below:\n\nAccessibility Resource Center (ARC)\nSpinelli Center: Support for students doing quantitative work. Includes tutoring and resources.\n\nFor this class: Sun-Thurs, 7-9pm in Sabin-Reed 301.\nEmail qlctutor@smith.edu for specific request for help.\n\nCrisis Resources\nCounseling Services\nWellness Resources\nGender Identity and Expression\nDiscriminatory Harassment"
  },
  {
    "objectID": "syllabus-pdf.html#course-outline",
    "href": "syllabus-pdf.html#course-outline",
    "title": "Syllabus",
    "section": "Course Outline",
    "text": "Course Outline\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nCh.\nAssignments / Notes\n\n\n\n\n1\n1/26-30\nIntroduction to Data\n1\n\n\n\n2\n2/2-6\nIntro to R and Workflows\n1, B\n\n\n\n3\n2/9-13\nData Visualization\n2\n\n\n\n4\n2/16-20\nggplot2\n3\n\n\n\n5\n2/23-2/27\nData Wrangling\n4\n\n\n\n6\n3/2-3/6\nData Joining\n5\nProject #1 due: Wed, 3/4\n\n\n7\n3/9-13\nStatistics, Exam #1\n9\nExam #1: Fri, 3/13\n\n\n8\n3/16-20\nSpring Break!\n\nNo class all week long\n\n\n9\n3/23-27\nData Tidying\n6\n\n\n\n10\n3/30-4/3\nProgramming\n7\n\n\n\n11\n4/6-10\nEthics and Programming\n8, C\n\n\n\n12\n4/13-17\nSpatial Thinking\n17\n\n\n\n13\n4/20-24\nSpatial Thinking\n17\n\n\n\n14\n4/27-5/1\nAPIs and Review\n18\n Project #2 due: Mon, 4/27 \n\n\nFinals\n5/2-9\nFinals\nNA\nExam #2: self-scheduled (5/6-9) \n\n\n\n\nNote that the assignments and topics covered are tentatively scheduled and may be altered slightly as the quarter progresses. The instructor has the right to modify the syllabus if needed. If this occurs, students will be notified before the change occurs."
  },
  {
    "objectID": "resources/tech-setup.html",
    "href": "resources/tech-setup.html",
    "title": "Tech Setup (2 pts)",
    "section": "",
    "text": "WarningWarning\n\n\n\nUpdates to this document are indicated in red."
  },
  {
    "objectID": "resources/tech-setup.html#introduction",
    "href": "resources/tech-setup.html#introduction",
    "title": "Tech Setup (2 pts)",
    "section": "Introduction",
    "text": "Introduction\nYou will be setting up all software and applications that are needed to complete and submit assignments of various forms in SDS 192. We will set up the following tools in this setup:\n\nSlack\nPerusall\nR/RStudio\nGitHub Classroom\n\n\n\n\n\n\n\nTip\n\n\n\nAs you get everything set up, if you run into any hiccups along the way, there are many ways to get help:\n\nAsk questions in Slack. There will be a #techissues channel dedicated for this purpose.\n\nMake sure to be specific in your issue. Indicate which step you are stuck on and include any screenshots.\n\nFeel free to DM me on Slack or via email. With some more complex issues, I can provide some guidance.\nAsk about these issues in student hours or at the Spinelli Center."
  },
  {
    "objectID": "resources/tech-setup.html#slack",
    "href": "resources/tech-setup.html#slack",
    "title": "Tech Setup (2 pts)",
    "section": "Slack",
    "text": "Slack\nSlack will be used as a discussion forum, in which you can ask and answer clarifying questions to the whole class, provide perspectives on situations discussed in lab assignments, and find out announcements about the class on a day-to-day basis.\nIf you run into hiccups with this part, Smith’s ITS department has some quick hints here.\nNonetheless, to set up Slack, you will do the following:\n\nAccept the Slack invitation via email from this course. Follow the directions in order to get into the course.\nYou will see some of the following channels below. Go to the #general channel, go to my “Welcome” post, and reply to the thread with a random fact of your choice.\n\n\n\n\n\n\n\nOptional, but recommended: Turn on notifications from this workspace (this should already be toggled, but double-check to be sure.) Also, you may be encouraged to download and install Slack on your laptops and phones."
  },
  {
    "objectID": "resources/tech-setup.html#perusall",
    "href": "resources/tech-setup.html#perusall",
    "title": "Tech Setup (2 pts)",
    "section": "Perusall",
    "text": "Perusall\nPerusall will be used for all reading assignments, in which you will annotate and comment on particular items from weekly readings.\nTo set up Perusall, you will do the following:\n\nUse the following link to join the Perusall course: link\nCreate a new account. You can do so by signing-in through Google with your smith.edu email address or creating a traditional account with your smith.edu email address.\nGo to Assignments and go to the Test Assignment. You will create one annotation in this assignment. Once you’ve done so, you’re good to go.\n\nNote: Let me know if you are having difficulties accessing Perusall throughout the semester."
  },
  {
    "objectID": "resources/tech-setup.html#r-and-rstudio",
    "href": "resources/tech-setup.html#r-and-rstudio",
    "title": "Tech Setup (2 pts)",
    "section": "R and RStudio",
    "text": "R and RStudio\nR and RStudio will collectively make up the coding tools we will use to run through data science examples and assignments. R is the coding language that many statisticians and data scientists use to generate data visualizations, complete data wrangling, and run analyses. RStudio is the application that we use to interact with R, formally known as an IDE (i.e. Integrated Development Environment). We will use RStudio particularly when writing R code and walking through problems.\nWe will need to download and install R and RStudio onto our laptops. If you are running a web-based operating system (e.g. ChromeOS), you will have to use Posit Cloud to run R. Instructions to use Posit Cloud can be seen at the bottom of this section.\nFor everyone else (e.g. Windows, Mac, Linux), you will download and install R and RStudio using these instructions:\n\nGo to the following link here.\nInstall R first by clicking on “Download and Install R”, which can be found on the left side of the page.\nYou will be redirected to https://cran.rstudio.com/.\n\nWindows: Click on the link to “Download R for Windows”, choose “install R for the first time”, then choose “Download R 4.5.2 for Windows”.\nMacOS: Click “Download R for (Mac) OS X”. Download the install package for version R-4.5.2. Read the information carefully to determine which of the two versions to download.\nLinux: Click on the link to “Download R for Linux”. You will need to choose the version of Linux that corresponds to your installation. Versions are available for Debian, RedHat, SUSE, and Ubuntu.\n\nOnce the R file has been downloaded, please install R by opening the file. Follow all prompts as necessary, keeping things as defaulted as possible.\nGo back to the Posit webpage and follow step 2 on the page by clicking “Download RStudio Desktop for ____”. Once downloaded, install RStudio by opening the file. Follow all prompts as necessary.\n\nFor those using Posit Cloud:\n\nClick the Login button located at the top-right corner of the screen.\nSign-in using either Google or GitHub.\n\nIf you have trouble installing and downloading R/RStudio, we will have some time at the beginning of the first lab to walk through any issues you all have."
  },
  {
    "objectID": "resources/tech-setup.html#git-github-and-github-classroom",
    "href": "resources/tech-setup.html#git-github-and-github-classroom",
    "title": "Tech Setup (2 pts)",
    "section": "git, GitHub, and GitHub Classroom",
    "text": "git, GitHub, and GitHub Classroom\nWe will be using git commands, GitHub, and GitHub classroom to collaborate with others on coding and projects, submit coding-relative activities and assignments, and get familiar with data science workflows.\nTo differentiate between the terms, when referring to “git”, this refers to the software and commands associated with tracking changes in files during software development. The actions “push”, “pull”, “commit”, and others will pop up and we will discuss these in detail throughout the semester. GitHub refers to the application that utilizes the git system to aid in these processes. GitHub Classroom is a special use of GitHub that will allow for specific repositories to be linked to our classroom.\nA few actions need to happen to set these items up, which you’ll see in the subsections below.\n\nSetting Up Your R Environment\nIf you have any troubles, you can use the Happy Git with R textbook for assistance.\n\nGo to GitHub and create a GitHub account, preferably with your smith.edu account. Setup account details.\nOpen RStudio on your laptop.\nCheck to ensure you have git installed by opening RStudio and clicking on Tools &gt; Global Options &gt; Git/SVN tab. Check the top of the pane for a field for the Git executable. It should say something like: “/usr/bin/git” or “C:/Program Files/Git/”. If it says “(Not Found)” git is not installed.\nIn the R console (bottom-left corner), you will input and hit Enter for each of these lines of code (replace what it is in the quotations with your info):\n\n\ninstall.packages(\"usethis\")\nlibrary(usethis)\nuse_git_config(user.name = \"PUT GITHUB USERNAME HERE\", user.email = \"PUT GITHUB EMAIL HERE\")\n\n\nPut the following line of code in the console:\n\n\ncreate_github_token()\n\nDefine a name for the token and set the expiration date to be 150 days from today’s date. Leave all other settings the same and generate the token.\nOnce done, please save the token in some fashion. You will not see this token again once you leave the webpage.\n\nReturn to RStudio and run the following lines of code in the console:\n\n\nlibrary(gitcreds)\ngitcreds_set()\n\nWhen prompted for the token, paste the token you created into the console and hit Enter.\nIf you are needing additional assistance, please use the following videos:\n\nConfiguring git\nPersonal Access Token (PAT)\nStoring PAT\n\n\n\nSetting Up GitHub Classroom and Future Repositories\nYour current and future RStudio environments are now linked to your GitHub account, providing you access to repositories on GitHub itself. With this in mind, we can now replicate repositories from GitHub in a process called cloning.\n\nUse the following link below to access the test repository from GitHub Classroom:\n\nhttps://classroom.github.com/a/_arMNRWC\n\n\nYou will go through all necessary prompts. Feel free to use this video as a resource: https://www.youtube.com/watch?v=lsQ48kn-uD0\n\nCopy the URL for your SDS 192 Lab GitHub repo. It should look like the following link:\n\nhttps://github.com/sds192lawson/tech-setup-repository-YOUR_USERNAME\n\nGo back to RStudio. At the top-left corner, click on File &gt; New Project &gt; Version Control &gt; git.\n\nPaste the URL into the first field, type a simple name for the folder in the second field, and choose an appropriate directory on your computer to house the repository. Then, click Create Project.\n\nInstall the rmarkdown package in RStudio by entering the following lines of code in the console.\n\n\ninstall.packages(\"rmarkdown\")\nlibrary(rmarkdown)\n\n\nOn the initial install, the Files tab will be in the lower right hand corner of RStudio. Open practice.qmd, and then follow the prompts in that file. Click Save.\nWe will now pull, commit, and push changes to the remote repository on GitHub. To do so, go to the Git tab on the top-right corner. From there,\n\nClick on the blue downward arrow, which pulls updates from the remote repository. This ensures we have the most recent updates.\nClick on the stacked checkmark in the same area, which will allow you to commit changes to the remote repository. Stage each file in the left column by clicking on the checkbox and add a message in the right column that briefly specifies what changes you’ve made to the repository. Click Commit thereafter.\nClick on the green upward area, which pushes updates to the remote repository. A window will pop up, showing the status of the push. If successful, you should see those updated files in your GitHub repository. You can use the URL from step 8 to verify.\n\nRepeat steps 7-9 twice, each for the following two repositories you will use for lecture activities and lab assignments respectively:\n\nActivities Repo: https://classroom.github.com/a/V5LWa0K6\nLab Repo: https://classroom.github.com/a/vO0Mut-V\n\n\nIf you are needing additional assistance, please use the following videos:\n\nConfiguring RStudio Projects\nCommitting Files\nPushing Files"
  },
  {
    "objectID": "labs/lab1/index.html",
    "href": "labs/lab1/index.html",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "",
    "text": "This lab is two-fold: to get familiar with R and RStudio and to understand the context and parts of a dataset by referencing and interpreting data dictionaries and technical data documentation.\n\n\n\nNavigate through the main functionality of RStudio, including scripts, the environment, and using the help tab\nRead a data dictionary\nReference data documentation\nIdentify unique observations in a dataset\nUnderstand different variable types\nLook up value codes and recode a variable\nDetermine the number of missing values in a variable and why they are missing\n\n\n\n\n\nRectangular Datasets\n\ndatasets in which all rows are the same length, and all columns are the same length\n\nObservations\n\nrows in a dataset; represent discrete entities we observe in the world\n\nVariables\n\ncolumns in a dataset; describe something about an observation\n\nVector\n\none-dimensional set of values that are all of the same type\n\nData Frame\n\na list of vectors of equal lengths; typically organizes data into a two-dimensional table composed of columns (the vectors) and rows\n\nUnique Key\n\nvariable (column) in the dataset that can be used to uniquely identify each row\n\nNominal categorical variables\n\nvariables that identify something else; sometimes, numbers are considered nominal categorical variables (e.g. zip code)\n\nOrdinal categorical variables\n\ncategorical variables that can be ranked or placed in a particular order (e.g. High, Medium, Low)\n\nDiscrete numeric variables\n\nnumeric variables that represent something that is countable (e.g. the number of students in a classroom, the number pages in a book)\n\nContinuous numeric variables are variables\n\nvariables in which it is always possible to measure the value more precisely (e.g. time can be measured with infinite amount of specificity - hours &gt; minutes &gt; seconds &gt; milliseconds &gt; microseconds &gt; nanoseconds …)"
  },
  {
    "objectID": "labs/lab1/index.html#introduction",
    "href": "labs/lab1/index.html#introduction",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "",
    "text": "This lab is two-fold: to get familiar with R and RStudio and to understand the context and parts of a dataset by referencing and interpreting data dictionaries and technical data documentation.\n\n\n\nNavigate through the main functionality of RStudio, including scripts, the environment, and using the help tab\nRead a data dictionary\nReference data documentation\nIdentify unique observations in a dataset\nUnderstand different variable types\nLook up value codes and recode a variable\nDetermine the number of missing values in a variable and why they are missing\n\n\n\n\n\nRectangular Datasets\n\ndatasets in which all rows are the same length, and all columns are the same length\n\nObservations\n\nrows in a dataset; represent discrete entities we observe in the world\n\nVariables\n\ncolumns in a dataset; describe something about an observation\n\nVector\n\none-dimensional set of values that are all of the same type\n\nData Frame\n\na list of vectors of equal lengths; typically organizes data into a two-dimensional table composed of columns (the vectors) and rows\n\nUnique Key\n\nvariable (column) in the dataset that can be used to uniquely identify each row\n\nNominal categorical variables\n\nvariables that identify something else; sometimes, numbers are considered nominal categorical variables (e.g. zip code)\n\nOrdinal categorical variables\n\ncategorical variables that can be ranked or placed in a particular order (e.g. High, Medium, Low)\n\nDiscrete numeric variables\n\nnumeric variables that represent something that is countable (e.g. the number of students in a classroom, the number pages in a book)\n\nContinuous numeric variables are variables\n\nvariables in which it is always possible to measure the value more precisely (e.g. time can be measured with infinite amount of specificity - hours &gt; minutes &gt; seconds &gt; milliseconds &gt; microseconds &gt; nanoseconds …)"
  },
  {
    "objectID": "labs/lab1/index.html#getting-familiar-with-r-and-rstudio",
    "href": "labs/lab1/index.html#getting-familiar-with-r-and-rstudio",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Getting Familiar with R and RStudio",
    "text": "Getting Familiar with R and RStudio\nAs discussed in the Tech Setup assignment, R is the coding language we will be using to generate plots, data wrangle, and accomplish other data science tasks. The interface we will use is RStudio.\nFor each and every lab, we will be using the lab repository you created when completing the Tech Setup assignment. On the SDS 192 website, you will find the following for each lab:\n\nLab instructions (via web)\nLab template (via .qmd)\n\nDownload the .qmd file and place that file into your lab repository. From there, open RStudio, open the lab repository project by going to File &gt; Recent Projects &gt; lab-repo. Then, open this template file up in RStudio by going to File &gt; Open File and locating the file in your repository.\nYou will see the file open up in the top-left corner of the RStudio window. You will edit the code in this file particularly.\nLet’s talk about each of the four sections you’re seeing in the RStudio window. Approximately, you will see the following:\n\n\nTop-left: This will show any files you are working on. You will use this section primarily to add code and prose to the lab templates. The templates are .qmd files, meaning you will see gray chunks that contain R code and white space that contains prose. R code should only go in gray chunks, while any written text should be in whitespace. We’ll expand upon this in later labs. Some things to note:\n\nTo create new gray chunks: Ctrl + Opt + I on keyboard\nTo run whole chunks: Hit the green “Play” button at the top-right corner of the gray chunk\nAll copy/paste and save commands are similar to what’d you see in something like Word.\n\nBottom-left: This area houses the console and terminal. I tend to use the console for single-line commands to test out code. We will not use this area too much.\nTop-right: This area houses various features, including our Environment and Git. The environment shows you which items are stored on your computer when using R and RStudio. The Git tab will be where you update items in your repository, which was mentioned in the Tech Setup assignment.\nBottom-left: This area house other features, most importantly the Files, Plots, and Help tabs. I encourage you to play around with these tabs to see their functionality. In the image above, I have it set to the Help tab; this is useful when trying to learn certain functionality of commands in R, such as the min() function.\n\nIt’s a lot to comprehend initially, so take it in stride as you work through lecture activities and lab assignments."
  },
  {
    "objectID": "labs/lab1/index.html#scorecard-dataset",
    "href": "labs/lab1/index.html#scorecard-dataset",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Scorecard Dataset",
    "text": "Scorecard Dataset\nIn his 2013 State of the Union Address, President Barack Obama announced his plans to create a “college scorecard” that would allow prospective students and parents to compare schools in terms of cost, offerings, diversity, completion rates, and post-graduate earnings. This data was first published in 2015 and since has undergone several improvements and revisions.\nThe College Scorecard dataset is massive. It includes information about over 6500 institutions in the U.S., and has more than 3000 columns documenting information about those institutions. I chose this dataset for this lab because, if you can learn to read this data dictionary, you will be leaps and bounds ahead of the game in learning to read other data dictionaries. (It’s also just a super cool dataset, and hint, hint: you will get a chance to dive into it in much more detail in a few weeks). While the full data is available online, we are only going to work with a small subset of the data today."
  },
  {
    "objectID": "labs/lab1/index.html#setting-up-your-environment",
    "href": "labs/lab1/index.html#setting-up-your-environment",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Setting Up Your Environment",
    "text": "Setting Up Your Environment\n\nInstall the RScorecard package by entering the following into your Console: install.packages(\"rscorecard\")\nCreate a Scorecard API Key at this link. Shortly after you fill out the form, you will be emailed a key. Copy that key into the code chunk below, replacing “Sys.getenv(”SCORECARD_KEY”)” in sc_key(Sys.getenv(\"SCORECARD_KEY\")). Be sure to wrap the key in quotation marks.\nDownload the Scorecard Data Dictionary and Technical Documentation for Institution-Level Data Files here.\nRun the code below to the import 2022 Scorecard data for Massachusetts into R. Call me over if you get an error.\n\n\nlibrary(tidyverse)\nlibrary(rscorecard)\nsc_key(\"O3j1bLwY61hWtl6y3krgWpWhBQufxaIRw7tHIJOu\") # Replace with your own token!!\n\nscorecard &lt;- sc_init() |&gt;\n  sc_year(2022) |&gt;                 #Note how we are looking at only 2024 data here!\n  sc_filter(stabbr == \"MA\") |&gt;     #Note how we are looking at only Massachusetts data here!\n  sc_select(unitid, instnm, city, highdeg, control, ugds, adm_rate, costt4_a, costt4_p, pcip27, pctfloan, admcon7, wdraw_orig_yr2_rt, cdr3) |&gt;\n  sc_get()"
  },
  {
    "objectID": "labs/lab1/index.html#glimpsing-the-data",
    "href": "labs/lab1/index.html#glimpsing-the-data",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Glimpsing the Data",
    "text": "Glimpsing the Data\nWhen working with very large datasets, we need tools to help us get a sense of the dataset without having to load the entire data frame. For instance, we can view the first 6 rows of the dataset by calling head().\n\nhead(scorecard)\n\n# A tibble: 6 × 15\n  unitid instnm    city  highdeg control  ugds adm_rate costt4_a costt4_p pcip27\n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 164368 Hult Int… Camb…       4       2   682   0.477     74000       NA  0    \n2 164447 American… Spri…       4       2  1142   0.894     53236       NA  0    \n3 164465 Amherst … Amhe…       3       2  1898   0.0726    80060       NA  0.095\n4 164492 Anna Mar… Paxt…       4       2   991   0.947     55594       NA  0    \n5 164535 Assabet … Marl…       1       1    54   0.474        NA    42983  0    \n6 164562 Assumpti… Worc…       4       2  1676   0.823     60262       NA  0.015\n# ℹ 5 more variables: pctfloan &lt;dbl&gt;, admcon7 &lt;int&gt;, wdraw_orig_yr2_rt &lt;lgl&gt;,\n#   cdr3 &lt;dbl&gt;, year &lt;dbl&gt;\n\n\nstr() provides a great deal of information about the observations in the data frame, including the number of variables, the number of observations, the column names, their data types, and a list of observations.\n\nstr(scorecard)\n\ntibble [147 × 15] (S3: tbl_df/tbl/data.frame)\n $ unitid           : int [1:147] 164368 164447 164465 164492 164535 164562 164580 164599 164614 164632 ...\n $ instnm           : chr [1:147] \"Hult International Business School\" \"American International College\" \"Amherst College\" \"Anna Maria College\" ...\n $ city             : chr [1:147] \"Cambridge\" \"Springfield\" \"Amherst\" \"Paxton\" ...\n $ highdeg          : int [1:147] 4 4 3 4 1 4 4 1 3 4 ...\n $ control          : int [1:147] 2 2 2 2 1 2 2 3 2 2 ...\n $ ugds             : int [1:147] 682 1142 1898 991 54 1676 2709 26 39 1263 ...\n $ adm_rate         : num [1:147] 0.4774 0.8936 0.0726 0.9466 0.4737 ...\n $ costt4_a         : int [1:147] 74000 53236 80060 55594 NA 60262 76360 NA 26691 46775 ...\n $ costt4_p         : int [1:147] NA NA NA NA 42983 NA NA NA NA NA ...\n $ pcip27           : num [1:147] 0 0 0.095 0 0 0.015 0 0 0 0 ...\n $ pctfloan         : num [1:147] 0.0956 0.8012 0.1123 0.6997 0.54 ...\n $ admcon7          : int [1:147] 3 5 5 3 3 5 5 NA 5 5 ...\n $ wdraw_orig_yr2_rt: logi [1:147] NA NA NA NA NA NA ...\n $ cdr3             : num [1:147] 0 0 0 0 0 0 0 0.029 0.017 0 ...\n $ year             : num [1:147] 2022 2022 2022 2022 2022 ...\n\n\nYou can also click on the name of your data frame in your Environment panel in RStudio, and it will open a new tab in RStudio that displays the data in a tabular format. Try clicking on scorecard in your Environment panel.\n\n\n\n\n\n\nTipTip\n\n\n\nThis is the same as calling View(scorecard) in your Console."
  },
  {
    "objectID": "labs/lab1/index.html#getting-to-know-the-dataset",
    "href": "labs/lab1/index.html#getting-to-know-the-dataset",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Getting to Know the Dataset",
    "text": "Getting to Know the Dataset\n\nObservations (Rows)\nIn starting our data analysis, we need to have a good sense of what each observation in our dataset refers to - or its observational unit. Think of it this way. If you were to count the number rows in your dataset, what would that number refer to? A unique key is a variable (or set of variables) that uniquely identifies an observation in the dataset. Think of a unique key as a unique way to identify a row and all of the values in it. There should never be more than one row in the dataset with the same unique key. A unique key tells us what each row in the dataset refers to.\n\n\n\n\n\n\nImportantQuestion 1 (5 pts)\n\n\n\nSee if you can identify a unique key for this dataset. Write some lines of code to determine whether the column you’ve identified can act as unique key for the data. Hint: You need to check whether the values in the column ever repeat.\n\n# Write code to calculate number of rows in scorecard\n\n# Write code to calculate the number of unique values in the column you've identified as a unique key \n\n# Do these numbers match?\n\n\n\nAnytime we count something in the world, we are not only engaging in a process of tabulation; we are also engaging in a process of defining. If I count the number of students in a class, I first have to define what counts as a student. If someone is auditing the class, do they count? If I, as the instructor, am learning from my students, do I count myself as a student? As I make decisions about how I’m going to define “student,” those decisions impact the numbers that I produce. When I change my definition of “student,” how I go about tabulating students also changes. Thus, as we prepare to count observations in a dataset, it is important to know how those observations are defined.\n\n\n\n\n\n\nImportantQuestion 2 (5 pts)\n\n\n\nAt this point, you’ve probably figured out that each row in this dataset is a higher education institution. However, there are many different ways that we can define higher education institutions, and that will impact what gets included and excluded in our data. Referencing the Technical Documentation, locate a definition for the unit of observation in this dataset. What institutions are included, and what institutions are excluded? Summarize a definition below.\n\n\n\n\nVariables (Columns)\nNote the column names for this dataframe, and the kinds of values that appear in those columns. Some of them (like city and year) might make sense to you immediately. Others (like pcip27 and highdeg) might be much more confusing. To figure out what we are looking at, we are going to need to refer to the dataset’s data dictionary.\nOpen the data dictionary you downloaded in an earlier step. It will open as an Excel file. Click on the tab labeled “Institution_Data_Dictionary”. There are thousands of variables in this dataset, falling into the broader categories of school, completion, admissions, cost, etc. Note how the file is organized, and specifically draw your attention to:\n\nColumn 1 (NAME OF DATA ELEMENT): This is a long description of the variable and gives you clues as to what is represented in it.\nColumn 6 (VARIABLE NAME): This is the column name for the variable. This is how you will reference the variable in R.\nColumn 7 (VALUE): These are the possible values for that variable. Note that for many categorical variables, the values are numbers. We are going to have to associate the numbers with their corresponding labels.\nColumn 8 (LABEL): These are the labels associated with the values recorded for the variable.\nColumn 11 (NOTES): This provides notes about the variable, including whether it is currently in use and what missing values indicate.\n\n\n\n\n\n\n\nImportantQuestion 3 (5 pts)\n\n\n\nFor each of the variable names in the scorecard data frame, look up the associated name in the data dictionary. You will need to search for the variable name in the sixth column of the data dictionary (I recommend using Ctrl-F to quickly locate the variable name in the spreadsheet.) Once you’ve found the variable name, reference column 1 to determine what this variable means, and reference columns 7 and 8 to see what possible values will appear in that column.\nIdentify one nominal variable, one ordinal variable, one discrete variable, and one continuous variable in scorecard and list their variable names below. Then uncomment the lines below and use the typeof() function to see how R determined their data types. Did any surprise you?\n\n#typeof(scorecard$_____)\n#typeof(scorecard$_____)\n#typeof(scorecard$_____)\n#typeof(scorecard$_____)\n\n\n\n\n\nValues (Cells)\nYou may have noticed that several categorical variables are coded as numbers in the imported dataset. For instance, look at the column control which designates the institution’s ownership. Running the code below, we see that the distinct values in that column are 1, 2, and 3.\n\nunique(scorecard$control)\n\n[1] 2 1 3\n\n\nWhen we reference that column in the data dictionary (row 27), we see that a 1 in that column designates that the institution is Public, a 2 that the institution is Private nonprofit, and a 3 that the institution is Private for-profit. While I can always look that up, sometimes it is helpful to have that information in our dataset. For instance, let’s say I create a bar plot that’s supposed to show how many higher education institutions have each type of ownership in MA (which you will learn how to do soon!). The plot can be confusing when control is a series of numbers.\n\nggplot(scorecard, aes(x = control)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWith this in mind, sometimes it can be helpful to recode the values in a column. Recoding data involves replacing the values in a vector according to criteria that we provide. Remember how all columns in a data frame are technically vectors? We can use the recode() function to recode all of the values in the control vector. We are going to store the recoded values in a new column in our dataset called control_text. Check out the code below to see how we do this. Reference the help pages for recode (i.e. ?recode) to help you interpret the code.\n\nscorecard$control_text &lt;-\n  recode(\n    scorecard$control, \n    \"1\" = \"Public\", \n    \"2\" = \"Private nonprofit\", \n    \"3\" = \"Private for-profit\",\n    .default = NA_character_\n  )\n\nCheck out our barplot now!\n\nggplot(scorecard, aes(x = control_text)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantQuestion 4 (5 pts)\n\n\n\nWrite code below to recode the admcon7 variable and store the results in a new variable in scorecard called admcon7_text. You’ll need to look up the values in the data dictionary. If you’ve done this correctly, running this code should produce a barplot that displays multiple bars.\n\nscorecard$admcon7_text &lt;-\n  recode(\n    scorecard$admcon7, \n    #Fill replacements here\n    .default = NA_character_\n  )\n\nggplot(scorecard, aes(x = admcon7_text)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\nMissing Values\nWhen we have missing values in a rectangular dataset, we have to provide a placeholder for the missing value in order for the dataset to remain rectangular. If we just skipped the value, then our dataset wouldn’t necessarily have rows of all equal lengths and columns of all equal lengths. In R, NA serves as that placeholder. Before we start analyzing data, it can be important to note how many NA values we have in a column so that we can determine if the data is representative.\nThe function is.na() checks whether a value is an NA value and returns TRUE if it is and FALSE if it isn’t. Providing a vector to is.na() will check this for every value in the vector and return a logical vector indicating TRUE/FALSE for every original value in the vector.\n\nis.na(scorecard$wdraw_orig_yr2_rt)\n\n  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [76] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [91] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[106] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[121] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[136] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nWhen we sum() across a logical vector, R will calculate the number of TRUE values in the vector.\n\nsum(is.na(scorecard$wdraw_orig_yr2_rt))\n\n[1] 147\n\n# Note that this is the same as:\n\nscorecard$wdraw_orig_yr2_rt |&gt; is.na() |&gt; sum()\n\n[1] 147\n\n\n\n\n\n\n\n\nImportantQuestion 5 (5 pts)\n\n\n\nIn a code chunk below, calculate the number of missing values in both the costt4_a and the costt4_p columns. Reference the NOTES column in the data dictionary to determine why there are so many NA values in these columns. Add a comment to the code chunk below, explaining the reason for missing values in these columns.\n\n# Write code here\n\n# Add comment here\n\n\n\n\n\n\n\n\n\nImportantQuestion 6 (5 pts)\n\n\n\nReferencing the College Scorecard data documentation, see if you can determine which students are included in calculations of earnings and debt. How might the data’s coverage bias the values that get reported? What might be the social consequences of these biases? Share your ideas on our discussions Slack channel."
  },
  {
    "objectID": "labs/lab1/index.html#submission",
    "href": "labs/lab1/index.html#submission",
    "title": "Lab #1: R and Understanding Datasets (30 pts)",
    "section": "Submission",
    "text": "Submission\n\nWhen you are done, save your .qmd file in RStudio in your lab-repo project.\nStage, commit, and push your file in the Git pane. Refer to steps from the Tech Setup assignment for assistance.\nNavigate back to GitHub and click on the .qmd files to make sure you see your changes to the files there. If you don’t see the changes there, I won’t see them either!"
  },
  {
    "objectID": "lectures/w1l2_data.html#reminders",
    "href": "lectures/w1l2_data.html#reminders",
    "title": "Datasets",
    "section": "Reminders",
    "text": "Reminders\n\nTech setup\n\nComponents due tonight at 11:59pm\nImportant to do before Friday’s first lab"
  },
  {
    "objectID": "lectures/w1l2_data.html#from-survey",
    "href": "lectures/w1l2_data.html#from-survey",
    "title": "Datasets",
    "section": "From survey",
    "text": "From survey\n\nLots of practice in RStudio in class\n\nDemos and time in class to work with R\n\nBetter familiarity with git commands\n\nTech setup will be a warmup\n\nLooking forward to…\n\nRStudio, AI, working with big/complex data\n\nNot looking forward to…\n\nCoding, readings, workload"
  },
  {
    "objectID": "lectures/w1l2_data.html#from-survey-1",
    "href": "lectures/w1l2_data.html#from-survey-1",
    "title": "Datasets",
    "section": "From survey",
    "text": "From survey\n\nHoping to get out of this class…\n\nR, data analysis skills, datasets\n\nQuestions to me…\n\nWhy stats/data science?\nFootball team?\nMy initial struggles with R?"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset",
    "href": "lectures/w1l2_data.html#what-is-a-dataset",
    "title": "Datasets",
    "section": "What is a dataset?",
    "text": "What is a dataset?\n\nSource: CA Housing Data"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset-1",
    "href": "lectures/w1l2_data.html#what-is-a-dataset-1",
    "title": "Datasets",
    "section": "What is a dataset?",
    "text": "What is a dataset?\n\nCollection of data points organized into a structured format\nIn this course, we will mainly work with datasets that are structured in a two-dimensional format\n\nThese are referred to as rectangular datasets\n\nRectangular datasets are organized into a series of rows and columns; ideally:\n\nWe refer to rows as observations\nWe refer to columns as variables"
  },
  {
    "objectID": "lectures/w1l2_data.html#what-is-a-dataset-cont.",
    "href": "lectures/w1l2_data.html#what-is-a-dataset-cont.",
    "title": "Datasets",
    "section": "What is a dataset? (cont.)",
    "text": "What is a dataset? (cont.)\n\nGrolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "lectures/w1l2_data.html#collecting-and-organizing-data",
    "href": "lectures/w1l2_data.html#collecting-and-organizing-data",
    "title": "Datasets",
    "section": "Collecting and organizing data",
    "text": "Collecting and organizing data\n\nInvolves a research question we’re trying to answer\n\ne.g. What factors are contributing to a decrease in a bird species?\nExperimental vs. observational\n\nDetermine a sample, observation units, and variables to gather\nIn most cases: can be formed into a rectangular format\n\nRows represent the observations\nColumns represent the variables"
  },
  {
    "objectID": "lectures/w1l2_data.html#observations-vs.-variables-vs.-values",
    "href": "lectures/w1l2_data.html#observations-vs.-variables-vs.-values",
    "title": "Datasets",
    "section": "Observations vs. Variables vs. Values",
    "text": "Observations vs. Variables vs. Values\n\nGrolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/.\nObservationsVariablesValues\n\n\n\nObservations refer to individual units or cases of the data being collected.\n\nIf I was collecting data about each student in this course, one student would be an observation.\nIf I was collecting census data and aggregating it at the county level, one county would be an observation.\n\n\n\n\n\nVariables describe something about an observation.\n\nIf I was collecting data about each student in this course, ‘major’ might be one variable.\nIf I was collecting county-level census data, ‘population’ might be one variable.\nCan be categorical or numerical\n\n\n\n\n\nValues refer to the actual value associated with a variable for a given observation.\n\nIf I was collecting data about each student’s major in this course, one value might be SDS."
  },
  {
    "objectID": "lectures/w1l2_data.html#key-considerations-for-rectangular-datasets",
    "href": "lectures/w1l2_data.html#key-considerations-for-rectangular-datasets",
    "title": "Datasets",
    "section": "Key Considerations for Rectangular Datasets",
    "text": "Key Considerations for Rectangular Datasets\n\n\n\nAll rows in a rectangular dataset are of equal length.\nAll columns in a rectangular dataset are of equal length.\n\n\n\n\n\n\n\nUnderstanding Check\n\n\nLet’s say I have a rectangular dataset documenting student names and majors, and I was missing major information for one student. What would this look like in a rectangular dataset?\n\n\n\n\n\nGrolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "lectures/w1l2_data.html#how-do-i-find-out-more-information-about-a-dataset",
    "href": "lectures/w1l2_data.html#how-do-i-find-out-more-information-about-a-dataset",
    "title": "Datasets",
    "section": "How do I find out more information about a dataset?",
    "text": "How do I find out more information about a dataset?\n\nMetadata can be referred to as “data about data”\nMetadata provides important contextual information to help us interpret a dataset.\nThere are two types of metadata associated with datasets:\n\n\nAdministrativeDescriptive\n\n\n\nAdministrative metadata tells us how a dataset is managed and its provenance, or the history of how it came to be in its current form:\n\nWho created it?\nWhen was it created?\nWhen was it last updated?\nWho is permitted to use it?\n\n\n\n\n\nDescriptive metadata tells us information about the contents of a dataset:\n\nWhat does each row refer to?\nWhat does each column refer to?\nWhat values might appear in each cell?"
  },
  {
    "objectID": "lectures/w1l2_data.html#where-do-i-find-metadata-for-a-dataset",
    "href": "lectures/w1l2_data.html#where-do-i-find-metadata-for-a-dataset",
    "title": "Datasets",
    "section": "Where do I find metadata for a dataset?",
    "text": "Where do I find metadata for a dataset?\n\nOften times, metadata is recorded in a dataset codebook or data dictionary.\nThese documents provide definitions for the observations and variables in a dataset and tell you the accepted values for each variable.\nLet’s say that I have a dataset of student names, majors, and class years. A codebook or data dictionary might tell me that:\n\nEach row in the dataset refers to one student.\nThe ‘Class Year’ variable refers to “the year the student is expected to graduate.”\nPossible values for the ‘Major’ variable are Political Science, SDS, and Sociology."
  },
  {
    "objectID": "lectures/w1l2_data.html#types-of-variables",
    "href": "lectures/w1l2_data.html#types-of-variables",
    "title": "Datasets",
    "section": "Types of variables",
    "text": "Types of variables\nVariables can fall into one of two different types:\n\nCategorical: variable can be split into discrete groups/factors\n\nNominal: named or classified labels with no inherent order\nOrdinal: ordered labels\n\nNumerical: variable defined by a set of numbers\n\nDiscrete: countable\nContinuous: measured"
  },
  {
    "objectID": "lectures/w1l2_data.html#types-of-variables-cont.",
    "href": "lectures/w1l2_data.html#types-of-variables-cont.",
    "title": "Datasets",
    "section": "Types of variables (cont.)",
    "text": "Types of variables (cont.)\n\nQuestion: Provide examples of each of the four sub-types of different variables."
  },
  {
    "objectID": "lectures/w1l2_data.html#group-activity-to-turn-in",
    "href": "lectures/w1l2_data.html#group-activity-to-turn-in",
    "title": "Datasets",
    "section": "Group activity (to turn-in)",
    "text": "Group activity (to turn-in)\n\nNavigate to the “Class #2: Activity” on the website\nWork in groups to answer the questions on a sheet of paper"
  },
  {
    "objectID": "lectures/w1l2_data.html#for-wednesday",
    "href": "lectures/w1l2_data.html#for-wednesday",
    "title": "Datasets",
    "section": "For Wednesday",
    "text": "For Wednesday\n\nWork on Tech Setup\nWork on Problem Solving lab (optional)\nWednesday’s class: Basics of R"
  },
  {
    "objectID": "lectures/w1l2_data.html#for-friday",
    "href": "lectures/w1l2_data.html#for-friday",
    "title": "Datasets",
    "section": "For Friday",
    "text": "For Friday\n\nWork on Tech Setup\nFriday’s class: Lab on R and Datasets"
  },
  {
    "objectID": "lectures/w1l2_act.html",
    "href": "lectures/w1l2_act.html",
    "title": "Class #2: Datasets",
    "section": "",
    "text": "Today, we are going to work with a dataset that documents cases where NYC Urban Park Rangers respond to requests for animal assistance, relocation, and/or rescue. If you are unfamiliar with what an Urban Park Ranger does, you may want to check out this video!\n\n\n\nNavigate to the NYC Urban Park Ranger Animal Condition Response dataset.\nNote the information listed in the “About this Dataset” section. This is administrative metadata.\nNote the attachment in this section with the file name: UrbanParkRangerAnimalConditionResponse_DataDictionary_20181107.xlsx. This contains descriptive metadata for this dataset.\nClick on the ‘Data’ tab at the top of the page. You can now see the data as a rectangular dataset.\nAnswer the following questions on a sheet of paper in groups of 3-4:\n\n\nWhat is the unit of observation in this dataset? In other words, what does each row signify? How do you know?\nHow frequently is this dataset updated? How do you know?\nWhat are the possible values for the Species Status variable in this dataset? How do you know?\nWhat is the value at index [3, 3] in this dataset? How do you know?\nIdentify the index of one missing value in this dataset. How do you know?\nIdentify one nominal variable, one ordinal variable, one discrete variable, and one continuous variable.\n\n\nAs a preview of what you will be able to do in a few weeks, here is a visualization of the most commons species for which services are requested in NYC!\n\n\nlibrary(tidyverse)\nnyc_urban_ranger &lt;- \n  read_csv(\"https://data.cityofnewyork.us/api/views/fuhs-xmg2/rows.csv\",\n           name_repair = make.names)\n\nnyc_urban_ranger %&gt;%\n  group_by(Species.Description) %&gt;%\n  summarize(Count = sum(X..of.Animals)) %&gt;%\n  top_n(10, Count) %&gt;%\n  ggplot(aes(x = reorder(Species.Description, Count), y = Count)) +\n  geom_col() +\n  coord_flip() +\n  labs(title=\"Top 10 Most Common Species for which NYC Urban Park Rangers Assistance is Requested, 2018-2021\", x = \"Species\", y = \"Count\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size=8))"
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "SDS 192: Introduction to Data Science",
    "section": "Announcements",
    "text": "Announcements\nTBD"
  }
]